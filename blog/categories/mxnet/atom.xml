<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MXNet | Squid's Blog]]></title>
  <link href="http://gigasquid.github.io/blog/categories/mxnet/atom.xml" rel="self"/>
  <link href="http://gigasquid.github.io/"/>
  <updated>2019-08-18T16:22:12-04:00</updated>
  <id>http://gigasquid.github.io/</id>
  <author>
    <name><![CDATA[Carin Meier]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Simple Autoencoder]]></title>
    <link href="http://gigasquid.github.io/blog/2019/08/16/simple-autoencoder/"/>
    <updated>2019-08-16T16:16:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/08/16/simple-autoencoder</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/horlik/2901925672/in/photolist-5qr8pf-qkv3m8-32RwmC-dZBC2B-ja8ch-48vDg-f56TGS-oUfNKn-652ZqG-QnCrbX-y3C828-jeGkmu-dxwE9L-jKaGtZ-haQ6j3-61w8UJ-WmitYz-tLymA-dZCHC4-CGvx3R-CC3GPE-BSxzda-eu625R-vHAgnk-cR7WAE-jZiLgu-BsZwLP-fhfvPT-dN1Rf9-o8Mkby-8zDocw-5DvC7S-CEij58-oaw922-akUgeW-ayQiGU-aay1vS-2fVFske-2eoRpCe-rqwa4o-9VJPtv-opgEcq-MDfFe-9yzUaK-4is9Z9-cutXnm-f9U23-L7hpoe-3i3H-enSJKf" title="Perfect mirror"><img src="https://live.staticflickr.com/3274/2901925672_325f5faeb8.jpg" width="500" height="364" alt="Perfect mirror"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>If you look long enough into the autoencoder, it looks back at you.</em></p>

<p>The Autoencoder is a fun deep learning model to look into. Its goal is simple: given an input image, we would like to have the same output image.</p>

<p>It&rsquo;s sort of an identity function for deep learning models, but it is composed of two parts: an encoder and decoder, with the encoder translating the images to a <em>latent space representation</em> and the encoder translating that back to a regular images that we can view.</p>

<p><img src="https://camo.githubusercontent.com/1ab40362a922059fa3686914cf5cff803ba7dd43/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4c53594e57356d33544e377852583631425a686f5a412e706e67" alt="" /></p>

<p>We are going to make a simple autoencoder with Clojure MXNet for handwritten digits using the MNIST dataset.</p>

<h3>The Dataset</h3>

<p>We first load up the training data into an iterator that will allow us to cycle through all the images.</p>

<p>```clojure
(def train-data (mx-io/mnist-iter {:image (str data-dir &ldquo;train-images-idx3-ubyte&rdquo;)</p>

<pre><code>                               :label (str data-dir "train-labels-idx1-ubyte")
                               :input-shape [784]
                               :flat true
                               :batch-size batch-size
                               :shuffle true}))
</code></pre>

<p>```</p>

<p>Notice there the the input shape is 784. We are purposely flattening out our 28x28 image of a number to just be a one dimensional flat array. The reason is so that we can use a simpler model for the autoencoder.</p>

<p>We also load up the corresponding test data.</p>

<p>```clojure
(def test-data (mx-io/mnist-iter {:image (str data-dir &ldquo;t10k-images-idx3-ubyte&rdquo;)</p>

<pre><code>                              :label (str data-dir "t10k-labels-idx1-ubyte")
                              :input-shape [784]
                              :batch-size batch-size
                              :flat true
                              :shuffle true}))
</code></pre>

<p>```</p>

<p>When we are working with deep learning models we keep the training and the test data separate. When we train the model, we won&rsquo;t use the test data. That way we can evaluate it later on the unseen test data.</p>

<h3>The Model</h3>

<p>Now we need to define the layers of the model. We know we are going to have an input and an output. The input will be the array that represents the image of the digit and the output will also be an array which is reconstruction of that image.</p>

<p>```clojure
(def input (sym/variable &ldquo;input&rdquo;))
(def output (sym/variable &ldquo;input_&rdquo;))</p>

<p>(defn get-symbol []
  (as-> input data</p>

<pre><code>;; encode
(sym/fully-connected "encode1" {:data data :num-hidden 100})
(sym/activation "sigmoid1" {:data data :act-type "sigmoid"})

;; encode
(sym/fully-connected "encode2" {:data data :num-hidden 50})
(sym/activation "sigmoid2" {:data data :act-type "sigmoid"})

;; decode
(sym/fully-connected "decode1" {:data data :num-hidden 50})
(sym/activation "sigmoid3" {:data data :act-type "sigmoid"})

;; decode
(sym/fully-connected "decode2" {:data data :num-hidden 100})
(sym/activation "sigmoid4" {:data data :act-type "sigmoid"})

;;output
(sym/fully-connected "result" {:data data :num-hidden 784})
(sym/activation "sigmoid5" {:data data :act-type "sigmoid"})

(sym/linear-regression-output {:data data :label output})))
</code></pre>

<p>```</p>

<p>From the model above we can see the input (image) being passed through simple layers of encoder to its latent representation, and then boosted back up from the decoder back into an output (image). It goes through the pleasingly symmetric transformation of:</p>

<p>784 (image) &ndash;> 100 &ndash;> 50 &ndash;> 100 &ndash;> 784 (output)</p>

<p>We can now construct the full model with the <em>module</em> api from clojure-mxnet.</p>

<p>```clojure
(def data-desc (first (mx-io/provide-data-desc train-data)))</p>

<p>(def model (&ndash;> (m/module (get-symbol) {:data-names [&ldquo;input&rdquo;] :label-names [&ldquo;input_&rdquo;]})</p>

<pre><code>           (m/bind {:data-shapes [(assoc data-desc :name "input")]
                    :label-shapes [(assoc data-desc :name "input_")]})
           (m/init-params {:initializer  (initializer/uniform 1)})
           (m/init-optimizer {:optimizer (optimizer/adam {:learning-rage 0.001})})))
</code></pre>

<p>```</p>

<p>Notice that when we are binding the <code>data-shapes</code> and <code>label-shapes</code> we are using only the <code>data</code> from our handwritten digit dataset, (the images), and not the labels. This will ensure that as it trains it will seek to recreate the input image for the output image.</p>

<h3>Before Training</h3>

<p>Before we start our training, let&rsquo;s get a baseline of what the original images look like and what the output of the untrained model is.</p>

<p>To look at the original images we can take the first training batch of 100 images and visualize them. Since we are initially using the flattened <code>[784]</code> image representation. We need to reshape it to the 28x28 image that we can recognize.</p>

<p><code>clojure
(def my-batch (mx-io/next train-data))
(def images (mx-io/batch-data my-batch))
(ndarray/shape (ndarray/reshape (first images) [100 1 28 28]))
(viz/im-sav {:title "originals" :output-path "results/" :x (ndarray/reshape (first images) [100 1 28 28])})
</code></p>

<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567560737/in/dateposted-public/" title="originals"><img src="https://live.staticflickr.com/65535/48567560737_672d065ac2.jpg" width="420" height="420" alt="originals"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>We can also do the same visualization with the test batch of data images by putting them into the <code>predict-batch</code> and using our model.</p>

<p><code>clojure
;;; before training
 (def my-test-batch (mx-io/next test-data))
 (def test-images (mx-io/batch-data my-test-batch))
 (def preds (m/predict-batch model {:data test-images} ))
 (viz/im-sav {:title "before-training-preds" :output-path "results/" :x (ndarray/reshape (first preds) [100 1 28 28])})
</code></p>

<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567589067/in/dateposted-public/" title="before-training-preds"><img src="https://live.staticflickr.com/65535/48567589067_e44eeda1a9.jpg" width="420" height="420" alt="before-training-preds"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>They are not anything close to recognizable as numbers.</p>

<h3>Training</h3>

<p>The next step is to train the model on the data. We set up a training function to step through all the batches of data.</p>

<p>```clojure
(def my-metric (eval-metric/mse))</p>

<p>(defn train [num-epochs]
  (doseq [epoch-num (range 0 num-epochs)]</p>

<pre><code>(println "starting epoch " epoch-num)
(mx-io/do-batches
 train-data
 (fn [batch]
   (-&gt; model
       (m/forward {:data (mx-io/batch-data batch) :label (mx-io/batch-data batch)})
       (m/update-metric my-metric (mx-io/batch-data batch))
       (m/backward)
       (m/update))))
(println "result for epoch " epoch-num " is " (eval-metric/get-and-reset my-metric))))
</code></pre>

<p>```</p>

<p>For each batch of 100 images it is doing the following:</p>

<ul>
<li>Run the forward pass of the model with both the data and label being the image</li>
<li>Update the accuracy of the model with the <code>mse</code> (mean squared error metric)</li>
<li>Do the backward computation</li>
<li>Update the model according to the optimizer and the forward/backward computation.</li>
</ul>


<p>Let&rsquo;s train it for 3 epochs.</p>

<p><code>
starting epoch  0
result for epoch  0  is  [mse 0.06460866]
starting epoch  1
result for epoch  1  is  [mse 0.033874355]
starting epoch  2
result for epoch  2  is  [mse 0.027255038]
</code></p>

<h3>After training</h3>

<p>We can check the test images again and see if they look better.</p>

<p><code>clojure
;;; after training
(def my-test-batch (mx-io/next test-data))
(def test-images (mx-io/batch-data my-test-batch))
(def preds (m/predict-batch model {:data test-images} ))
(viz/im-sav {:title "after-training-preds" :output-path "results/" :x (ndarray/reshape (first preds) [100 1 28 28])})
</code>
<a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567523206/in/dateposted-public/" title="after-training-preds"><img src="https://live.staticflickr.com/65535/48567523206_d78480012f.jpg" width="420" height="420" alt="after-training-preds"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>Much improved! They definitely look like numbers.</p>

<h3>Wrap up</h3>

<p>We&rsquo;ve made a simple autoencoder that can take images of digits and compress them down to a latent space representation the can later be decoded into the same image.</p>

<p>If you want to check out the full code for this example, you can find it <a href="https://github.com/gigasquid/clojure-mxnet-autoencoder">here</a>.</p>

<p>Stay tuned. We&rsquo;ll take this example and build on it in future posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet April Update]]></title>
    <link href="http://gigasquid.github.io/blog/2019/04/26/clojure-mxnet-april-update/"/>
    <updated>2019-04-26T15:51:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/04/26/clojure-mxnet-april-update</id>
    <content type="html"><![CDATA[<p>Spring is bringing some beautiful new things to the  <a href="http://mxnet.incubator.apache.org/">Clojure MXNet</a>. Here are some highlights for the month of April.</p>

<h2>Shipped</h2>

<p>We&rsquo;ve merged <a href="https://github.com/apache/incubator-mxnet/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Aclosed+clojure">10 PRs</a> over the last month. Many of them focus on core improvements to documentation and usability which is very important.</p>

<p>The MXNet project is also preparing a new release <code>1.4.1</code>, so keep on the lookout for that to hit in the near future.</p>

<h2>Clojure MXNet Made Simple Article Series</h2>

<p><a href="https://arthurcaillau.com/about/">Arthur Caillau</a> added another post to his fantastic series &ndash; <a href="https://arthurcaillau.com/mxnet-made-simple-pretrained-models/">MXNet made simple: Pretrained Models for image classification &ndash; Inception and VGG</a></p>

<h2>Cool Stuff in Development</h2>

<h3>New APIs</h3>

<p>Great progress was made on the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092678">new version of the API for the Clojure NDArray and Symbol APIs</a> by <a href="https://github.com/kedarbellare">Kedar Bellare</a>. We now have an experimental new version of the apis that are generated more directly from the C code so that we can have more control over the output.</p>

<p>For example the new version of the generated api for NDArray looks like:</p>

<p>```clojure
(defn
 activation
 &ldquo;Applies an activation function element-wise to the input.</p>

<p>  The following activation functions are supported:</p>

<ul>
<li><code>relu</code>: Rectified Linear Unit, :math:<code>y = max(x, 0)</code></li>
<li><code>sigmoid</code>: :math:<code>y = \\frac{1}{1 + exp(-x)}</code></li>
<li><code>tanh</code>: Hyperbolic tangent, :math:<code>y = \\frac{exp(x) - exp(-x)}{exp(x) + exp(-x)}</code></li>
<li><code>softrelu</code>: Soft ReLU, or SoftPlus, :math:<code>y = log(1 + exp(x))</code></li>
<li><code>softsign</code>: :math:<code>y = \\frac{x}{1 + abs(x)}</code></li>
</ul>


<p>  Defined in src/operator/nn/activation.cc:L167</p>

<p>  <code>data</code>: The input array.
  <code>act-type</code>: Activation function to be applied.
  <code>out</code>: Output array. (optional)&ldquo;
 ([data act-type] (activation {:data data, :act-type act-type}))
 ([{:keys [data act-type out], :or {out nil}, :as opts}]
  (util/coerce-return
   (NDArrayAPI/Activation data act-type (util/&ndash;>option out)))))
```</p>

<p>as opposed to:</p>

<p>```clojure
(defn
 activation
 ([&amp; nd-array-and-params]
  (util/coerce-return
   (NDArray/Activation</p>

<pre><code>(util/coerce-param
 nd-array-and-params
 #{"scala.collection.Seq"})))))
</code></pre>

<p>```</p>

<p>So much nicer!!!</p>

<h3>BERT (State of the Art for NLP)</h3>

<p>We also have some really exciting examples for BERT in a <a href="https://github.com/apache/incubator-mxnet/pull/14769">PR</a> that will be merged soon. If you are not familiar with BERT, this <a href="http://jalammar.github.io/illustrated-bert/">blog post</a> is a good overview. Basically, it&rsquo;s the state of the art in NLP right now. With the help of exported models from <a href="https://github.com/dmlc/gluon-nlp">GluonNLP</a>, we can do both inference and fine tuning of BERT models in MXNet with Clojure! This is an excellent example of cross fertilization across the GluonNLP, Scala, and Clojure MXNet projects.</p>

<p>There are two examples.</p>

<p>1) BERT question and answer inference based off of a fine tuned model of the <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD Dataset</a> in GluonNLP which is then exported. It allows one to actually do some natural language question and answering like:</p>

<p>```
Question Answer Data
{:input-answer
 &ldquo;Rich Hickey is the creator of the Clojure language. Before Clojure, he developed dotLisp, a similar project based on the .NET platform, and three earlier attempts to provide interoperability between Lisp and Java: a Java foreign language interface for Common Lisp, A Foreign Object Interface for Lisp, and a Lisp-friendly interface to Java Servlets.&rdquo;,
 :input-question &ldquo;Who created Clojure?&rdquo;,
 :ground-truth-answers [&ldquo;rich&rdquo; &ldquo;hickey&rdquo;]}</p>

<p>  Predicted Answer:  [rich hickey]
```</p>

<p>2) The second example is using the exported BERT base model and then fine tuning it in Clojure to do a task with sentence pair classification to see if two sentences are equivalent or not.</p>

<p>The nice thing about this is that we were able to convert the existing <a href="https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html">tutorial in GluonNLP</a> over to a Clojure Jupyter notebook with the <code>lein-jupyter</code> plugin. I didn&rsquo;t realize that there is a nifty <code>save-as</code> command in Jupyter that can generate a markdown file, which makes for very handy documentation. Take a peek at the tutorial <a href="https://github.com/apache/incubator-mxnet/blob/d062d46f1c351dc9b70a038511b564dab5c43266/contrib/clojure-package/examples/bert/fine-tune-bert.md">here</a>. It might make its way into a blog post on its own in the next week or two.</p>

<h2>Upcoming Events</h2>

<ul>
<li><p>I&rsquo;ll be speaking about Clojure MXNet at the next <a href="https://twitter.com/scicloj">Scicloj Event</a> on May 15th at 10PM UTC. Please join us and get involved in making Clojure a great place for Data Science.</p></li>
<li><p>I&rsquo;m also really excited to attend <a href="https://iclr.cc/">ICLR</a> in a couple weeks. It is a <em>huge conference</em> that I&rsquo;m sure will melt my mind with the latest research in Deep Learning. If anyone else is planning to attend, please say hi :)</p></li>
</ul>


<h2>Get Involved</h2>

<p>As always, we welcome involvement in the true Apache tradition. If you have questions or want to say hi, head on over the the closest #mxnet room on your preferred server. We are on Clojurian&rsquo;s slack and Zulip</p>

<h2>Cat Picture of the Month</h2>

<p>To close out, let&rsquo;s take a lesson from my cats Otto and Pi and don&rsquo;t forget the importance of naps.</p>

<p><img class="<a" src="href="https://live.staticflickr.com/65535/47707608431_5c5d0c73f8_c.jpg">https://live.staticflickr.com/65535/47707608431_5c5d0c73f8_c.jpg</a>"></p>

<p>Have a great rest of April!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet March Update]]></title>
    <link href="http://gigasquid.github.io/blog/2019/03/22/clojure-mxnet-march-update/"/>
    <updated>2019-03-22T10:42:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/03/22/clojure-mxnet-march-update</id>
    <content type="html"><![CDATA[<p>I&rsquo;m starting a monthly update for <a href="http://mxnet.incubator.apache.org/">Clojure MXNet</a>. The goal is to share the progress and exciting things that are happening in the project and our community.</p>

<p>Here&rsquo;s some highlights for the month of March.</p>

<h2>Shipped</h2>

<p>Under the shipped heading, the 1.4.0 release of MXNet has been released, along with the <a href="https://search.maven.org/search?q=clojure%20mxnet">Clojure MXNet Jars</a>. There have been improvements to the JVM memory management and an Image API addition. You can see the full list of changes <a href="https://github.com/apache/incubator-mxnet/releases/tag/1.4.0#clojure">here</a></p>

<h2>Clojure MXNet Made Simple Article Series</h2>

<p><a href="https://arthurcaillau.com/about/">Arthur Caillau</a> authored a really nice series of blog posts to help get people started with Clojure MXNet.</p>

<ul>
<li><a href="https://arthurcaillau.com/mxnet-clojure-aws/">Getting started with Clojure and MXNet on AWS</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-ndarrays-api/">MXNet made simple: Clojure NDArray API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-symbol-api/">MXNet made simple: Clojure Symbol API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-module-api/">MXNet made simple: Clojure Module API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-symbol-visualization/">MXNet made simple: Clojure Symbol Visualization API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-image-manipulation/">MXNet made simple: Image Manipulation with OpenCV and MXNet</a></li>
</ul>


<h2>Lein Template &amp; Docker file</h2>

<p><a href="https://github.com/hellonico/">Nicolas Modrzyk</a> created a Leiningen template that allows you to easily get a MXNet project started &ndash; with a notebook too! It&rsquo;s a great way to take Clojure MXNet for a spin</p>

<p>```</p>

<h1>create project</h1>

<p>lein new clj-mxnet hello</p>

<h1>run included sample</h1>

<p>lein run</p>

<h1>start notebook engine</h1>

<p>lein notebook</p>

<h1>open notebook</h1>

<p><a href="http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj">http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj</a></p>

<h1>open empty notebook with all namespaces</h1>

<p><a href="http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj">http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj</a>
```</p>

<p>There also is a docker file as well</p>

<p>```
docker run -it -p 10000:10000 hellonico/mxnet</p>

<p>After starting the container, you can open the same notebooks as above:</p>

<h1>open notebook</h1>

<p><a href="http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj">http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj</a></p>

<h1>open empty notebook with all namespaces</h1>

<p><a href="http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj">http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj</a>
```</p>

<h2>Cool Stuff in Development</h2>

<p>There are a few really interesting things cooking for the future.</p>

<p>One is a <a href="https://github.com/apache/incubator-mxnet/pull/14372">PR for memory fixes</a> from the Scala team that is getting really close to merging. This will be a solution to some the the memory problems that were encountered by early adopters of the Module API.</p>

<p>Another, is the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092678">new version of the API for the Clojure NDArray and Symbol APIs</a> that is being spearheaded by Kedar Bellare</p>

<p>Finally, work is being started to create a <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103089990">Gluon API for the Clojure package</a> which is quite exciting.</p>

<h2>Get Involved</h2>

<p>As always, we welcome involvement in the true Apache tradition. If you have questions or want to say hi, head on over the the closest #mxnet room on your preferred server. We are on Clojurian&rsquo;s slack and Zulip.</p>

<h2>Cat Picture of the Month</h2>

<p>There is no better way to close out an update than a cat picture, so here is a picture of my family cat, Otto, watching birds at the window.</p>

<p><img class="<a" src="href="https://farm8.staticflickr.com/7862/46718997174_13bf6e88ea_z.jpg">https://farm8.staticflickr.com/7862/46718997174_13bf6e88ea_z.jpg</a>"></p>

<p>Have a great rest of March!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Object Detection With Clojure MXNet]]></title>
    <link href="http://gigasquid.github.io/blog/2019/01/19/object-detection-with-clojure-mxnet/"/>
    <updated>2019-01-19T13:34:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2019/01/19/object-detection-with-clojure-mxnet</id>
    <content type="html"><![CDATA[<p><img src="https://c1.staticflickr.com/8/7837/32928474208_4960caafb3.jpg" alt="" /></p>

<p>Object detection just landed in MXNet thanks to the work of contributors <a href="https://github.com/kedarbellare">Kedar Bellare</a> and <a href="https://github.com/hellonico/">Nicolas Modrzyk</a>. Kedar ported over the <code>infer</code> package to Clojure, making inference and prediction much easier for users and Nicolas integrated in his <a href="https://github.com/hellonico/origami">Origami</a> OpenCV library into the the examples to make the visualizations happen.</p>

<p>We&rsquo;ll walk through the main steps to use the <code>infer</code> object detection which include creating the detector with a model and then loading the image and running the inference on it.</p>

<h3>Creating the Detector</h3>

<p>To create the detector you need to define a couple of things:</p>

<ul>
<li>How big is your image?</li>
<li>What model are you going to be using for object detection?</li>
</ul>


<p>In the code below, we are going to be giving it an color image of size 512 x 512.</p>

<p>```clojure
(defn create-detector []
  (let [descriptors [{:name &ldquo;data&rdquo;</p>

<pre><code>                  :shape [1 3 512 512]
                  :layout layout/NCHW
                  :dtype dtype/FLOAT32}]
    factory (infer/model-factory model-path-prefix descriptors)]
(infer/create-object-detector factory)))
</code></pre>

<p>```</p>

<ul>
<li>The shape is going to be <code>[1 3 512 512]</code>.

<ul>
<li>The <code>1</code> is for the batch size which in our case is a single image.</li>
<li>The <code>3</code> is for the channels in the image which for a RGB image is <code>3</code></li>
<li>The <code>512</code> is for the image height and width.</li>
</ul>
</li>
<li>The <code>layout</code> specifies that the shape given is in terms of <code>NCHW</code> which is batch size, channel size, height, and width.</li>
<li>The <code>dtype</code> is the image data type which will be the standard <code>FLOAT32</code></li>
<li>The <code>model-path-prefix</code> points to the place where the trained model we are using for object detection lives.</li>
</ul>


<p>The model we are going to use is the <a href="https://arxiv.org/abs/1512.02325">Single Shot Multiple Box Object Detector (SSD)</a>. You can download the model yourself using this <a href="https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/examples/infer/objectdetector/scripts/get_ssd_data.sh">script</a>.</p>

<h3>How to Load an Image and Run the Detector</h3>

<p>Now that we have a model and a detector, we can load an image up and run the object detection.</p>

<p>To load the image use <code>load-image</code> which will load the image from the path.</p>

<p><code>clojure
(infer/load-image-from-file input-image)
</code></p>

<p>Then run the detection using <code>infer/detect-objects</code> which will give you the top five predictions by default.</p>

<p><code>clojure
(infer/detect-objects detector image)
</code></p>

<p>It will give an output something like this:</p>

<p><code>clojure
[[{:class "person",
   :prob 0.9657765,
   :x-min 0.021868259,
   :y-min 0.049295247,
   :x-max 0.9975169,
   :y-max 0.9734151}
  {:class "dog",
   :prob 0.17513266,
   :x-min 0.16772352,
   :y-min 0.45792937,
   :x-max 0.55409217,
   :y-max 0.72507095}
   ...
]]
</code></p>

<p>which you can then use to draw bounding boxes on the image.</p>

<h3>Try Running the Example</h3>

<p><img src="https://c1.staticflickr.com/8/7804/31862638207_61be3a6e3c_b.jpg" alt="" /></p>

<p>One of the best ways to explore using it is with the <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package/examples/infer/objectdetector">object detection example</a> in the MXNet repo. It will be coming out officially in the <code>1.5.0</code> release, but you can get an early peek at it by building the project and running the example with the nightly snapshot.</p>

<p>You can do this by cloning the <a href="https://github.com/apache/incubator-mxnet">MXNet Repo</a> and changing directory to <code>contrib/clojure-package</code>.</p>

<p>Next, edit the <code>project.clj</code> to look like this:</p>

<p>```clojure
(defproject org.apache.mxnet.contrib.clojure/clojure-mxnet &ldquo;1.5.0-SNAPSHOT&rdquo;
  :description &ldquo;Clojure package for MXNet&rdquo;
  :url &ldquo;<a href="https://github.com/apache/incubator-mxnet">https://github.com/apache/incubator-mxnet</a>&rdquo;
  :license {:name &ldquo;Apache License&rdquo;</p>

<pre><code>        :url "http://www.apache.org/licenses/LICENSE-2.0"}
</code></pre>

<p>  :dependencies [[org.clojure/clojure &ldquo;1.9.0&rdquo;]</p>

<pre><code>             [t6/from-scala "0.3.0"]

             ;; To use with nightly snapshot
             ;[org.apache.mxnet/mxnet-full_2.11-osx-x86_64-cpu "&lt;insert-snapshot-version&gt;"]
             ;[org.apache.mxnet/mxnet-full_2.11-linux-x86_64-cpu "&lt;insert-snapshot-version&gt;"]
             ;[org.apache.mxnet/mxnet-full_2.11-linux-x86_64-gpu "&lt;insert-snapshot-version"]

             [org.apache.mxnet/mxnet-full_2.11-osx-x86_64-cpu "1.5.0-SNAPSHOT"]

             ;;; CI
             #_[org.apache.mxnet/mxnet-full_2.11 "INTERNAL"]

             [org.clojure/tools.logging "0.4.0"]
             [org.apache.logging.log4j/log4j-core "2.8.1"]
             [org.apache.logging.log4j/log4j-api "2.8.1"]
             [org.slf4j/slf4j-log4j12 "1.7.25" :exclusions [org.slf4j/slf4j-api]]]
</code></pre>

<p>  :pedantic? :skip
  :plugins [[lein-codox &ldquo;0.10.3&rdquo; :exclusions [org.clojure/clojure]]</p>

<pre><code>        [lein-cloverage "1.0.10" :exclusions [org.clojure/clojure]]
        [lein-cljfmt "0.5.7"]]
</code></pre>

<p>  :codox {:namespaces [#&ldquo;^org.apache.clojure-mxnet.(?!gen).*&rdquo;]}
  :aot [dev.generator]
  :repositories [[&ldquo;staging&rdquo; {:url &ldquo;<a href="https://repository.apache.org/content/repositories/staging">https://repository.apache.org/content/repositories/staging</a>&rdquo;                  :snapshots true</p>

<pre><code>                         :update :always}]
             ["snapshots" {:url "https://repository.apache.org/content/repositories/snapshots"               :snapshots true
                          :update :always}]])
</code></pre>

<p><code>``
If you are running on linux, you should change the</code>mxnet-full_2.11-osx-x86_64-cpu<code>to</code>mxnet-full_2.11-linux-x86_64-cpu`.</p>

<p>Next, go ahead and do <code>lein test</code> to make sure that everything builds ok. If you run into any trouble please refer to <a href="https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/README.md">README</a> for any missing dependencies.</p>

<p>After that do a <code>lein install</code> to install the <code>clojure-mxnet</code> jar to your local maven. Now you are ready to <code>cd examples/infer/object-detection</code> to try it out. Refer to the README for more details.</p>

<p>If you run into any problems getting started, feel free to reach out in the Clojurian #mxnet slack room or open an issue at the MXNet project. We are a friendly group and happy to help out.</p>

<p>Thanks again to the community for the contributions to make this possible. It&rsquo;s great seeing new things coming to life.</p>

<p>Happy Object Detecting!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to GAN a Flan]]></title>
    <link href="http://gigasquid.github.io/blog/2018/12/18/how-to-gan-a-flan/"/>
    <updated>2018-12-18T16:34:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2018/12/18/how-to-gan-a-flan</id>
    <content type="html"><![CDATA[<p>It&rsquo;s holiday time and that means parties and getting together with friends. Bringing a baked good or dessert to a gathering is a time honored tradition. But what if this year, you could take it to the next level? Everyone brings actual food. But with the help of Deep Learning, you can bring something completely different &ndash;  you can bring the <em>image</em> of baked good! I&rsquo;m not talking about just any old image that someone captured with a camera or created with a pen and paper. I&rsquo;m talking about the computer itself <strong>creating</strong>. This image would be never before seen, totally unique, and crafted by the creative process of the machine.</p>

<p>That is exactly what we are going to do. We are going to create a <em>flan</em></p>

<p><img src="https://c1.staticflickr.com/5/4065/4339500429_aa9c55f246_n.jpg" alt="Photo by Lucia Sanchez on Flickr" /></p>

<p>If you&rsquo;ve never had a flan before, it&rsquo;s a yummy dessert made of a baked custard with caramel sauce on it.</p>

<p>&ldquo;Why a flan?&rdquo;, you may ask. There are quite a few reasons:</p>

<ul>
<li>It&rsquo;s tasty in real life.</li>
<li>Flan rhymes with GAN, <em>(unless you pronounce it &ldquo;Gaaahn&rdquo;)</em>.</li>
<li>Why not?</li>
</ul>


<p>Onto the recipe. How are we actually going to make this work? We need some ingredients:</p>

<ul>
<li><a href="https://clojure.org/">Clojure</a> &ndash; the most advanced programming language to create generative desserts.</li>
<li><a href="https://mxnet.apache.org">Apache MXNet</a> &ndash; a flexible and efficient deep learning library that has a Clojure package.</li>
<li>1000-5000 pictures of flans &ndash; for Deep Learning you need data!</li>
</ul>


<h2>Gather Flan Pictures</h2>

<p>The first thing you want to do is gather your 1000 or more images with a <a href="https://github.com/montoyamoraga/scrapers">scraper</a>. The scraper will crawl google, bing, or instagram and download pictures of <em>mostly</em> flans to your computer. You may have to eyeball and remove any clearly wrong ones from your stash.</p>

<p>Next, you need to gather all these images in a directory and run a tool called <a href="https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py">im2rec.py</a> on them to turn them into an <a href="https://mxnet.incubator.apache.org/tutorials/basic/data.html#loading-data-using-image-iterators">image record iterator</a> for use with MXNet. This will produce an optimized format that will allow our deep learning program to efficiently cycle through them.</p>

<p>Run:</p>

<pre><code>python3 im2rec.py --resize 28 root flan
</code></pre>

<p>to produce a <code>flan.rec</code> file with images resized to 28x28 that we can use next.</p>

<h2>Load Flan Pictures into MXNet</h2>

<p>The next step is to import the image record iterator into the MXNet with the <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package">Clojure API</a>. We can do this with the <code>io</code> namespace.</p>

<p>Add this to your require:</p>

<pre><code>[org.apache.clojure-mxnet.io :as mx-io]
</code></pre>

<p>Now, we can load our images:</p>

<p>```clojure
(def flan-iter (mx-io/image-record-iter {:path-imgrec &ldquo;flan.rec&rdquo;</p>

<pre><code>                                     :data-shape [3 28 28]
                                     :batch-size batch-size}))
</code></pre>

<p>```</p>

<p>Now, that we have the images, we need to create our <code>model</code>. This is what is actually going to do the learning and creating of images.</p>

<h2>Creating a GAN model.</h2>

<p>GAN stands for <em>Generative Adversarial Network</em>. This is a incredibly cool deep learning technique that has two different models pitted against each, yet both learning and getting better at the same time. The two models are a generator and a discriminator. The generator model creates a new image from a random noise vector. The discriminator then tries to tell whether the image is a real image or a fake image. We need to create both of these models for our network.</p>

<p>First, the discriminator model. We are going to use the <code>symbol</code> namespace for the clojure package:</p>

<p>```clojure
(defn discriminator []
  (as-> (sym/variable &ldquo;data&rdquo;) data</p>

<pre><code>(sym/convolution "d1" {:data data
                       :kernel [4 4]
                       :pad [3 3]
                       :stride [2 2]
                       :num-filter ndf
                       :no-bias true})
(sym/batch-norm "dbn1" {:data data :fix-gamma true :eps eps})
(sym/leaky-re-lu "dact1" {:data data :act-type "leaky" :slope 0.2})

...
</code></pre>

<p>```</p>

<p>There is a variable for the <code>data</code> coming in, (which is the picture of the flan), it then flows through the other layers which consist of convolutions, normalization, and activation layers. The last three layers actually repeat another two times before ending in the output, which tells whether it thinks the image was a fake or not.</p>

<p>The generator model looks similar:</p>

<p>```clojure
(defn generator []
  (as-> (sym/variable &ldquo;rand&rdquo;) data</p>

<pre><code>(sym/deconvolution "g1" {:data data
                         :kernel [4 4]
                         :pad [0 0]
                         :stride [1 1]
                         :num-filter
                         (* 4 ndf) :no-bias true})
(sym/batch-norm "gbn1" {:data data :fix-gamma true :eps eps})
(sym/activation "gact1" {:data data :act-type "relu"})

...
</code></pre>

<p>```</p>

<p>There is a variable for the <code>data</code> coming in, but this time it is a random noise vector. Another interesting point that is is using a <code>deconvolution</code> layer instead of a <code>convolution</code> layer. The generator is basically the inverse of the discriminator. It starts with a random noise vector, but that is translated up through the layers until it is expanded to a image output.</p>

<p>Next, we iterate through all of our training images in our <code>flan-iter</code> with <code>reduce-batches</code>. Here is just an excerpt where we get a random noise vector and have the generator run the data through and produce the output image:</p>

<p>```clojure
(mx-io/reduce-batches</p>

<pre><code>   flan-iter
   (fn [n batch]
     (let [rbatch (mx-io/next rand-noise-iter)
           dbatch (mapv normalize-rgb-ndarray (mx-io/batch-data batch))
           out-g (-&gt; mod-g
                     (m/forward rbatch)
                     (m/outputs))
</code></pre>

<p>```</p>

<p>The whole code is <a href="https://github.com/gigasquid/mxnet-gan-flan">here</a> for reference, but let&rsquo;s skip forward and run it and see what happens.</p>

<p><img src="/images/gout-96-0.jpg" alt="" /></p>

<p>FLANS!! Well, they could be flans if you squint a bit.</p>

<p>Now that we have them kinda working for a small image size 28x28, let&rsquo;s biggerize it.</p>

<h2>Turn on the Oven and Bake</h2>

<p>Turning up the size to 128x128 requires some alterations in the layers' parameters to make sure that it processes and generates the correct size, but other than that we are good to go.</p>

<p>Here comes the fun part, watching it train and learn:</p>

<h3>Epoch 0</h3>

<p><img src="/images/flan-random-128-0-0.jpg" alt="" /></p>

<p>In the beginning there was nothing but random noise.</p>

<h3>Epoch 10</h3>

<p><img src="/images/flan-random-128-10-0.jpg" alt="" /></p>

<p>It&rsquo;s beginning to learn colors! Red, yellow, brown seem to be important to flans.</p>

<h3>Epoch 23</h3>

<p><img src="/images/flan-random-128-23-0.jpg" alt="" /></p>

<p>It&rsquo;s learning shapes! It has learned that flans seem to be blob shaped.</p>

<h3>Epoch 33</h3>

<p><img src="/images/flan-random-128-33-0.jpg" alt="" /></p>

<p>It is moving into its surreal phase. Salvidor Dali would be proud of these flans.</p>

<h3>Epoch 45</h3>

<p><img src="/images/flan-random-128-45.jpg" alt="" /></p>

<p>Things take a weird turn. Does that flan have eyes?</p>

<h3>Epoch 68</h3>

<p><img src="/images/flan-random-128-68-0.jpg" alt="" /></p>

<p>Even worse. Are those demonic flans? Should we even continue down this path?</p>

<p>Answer: Yes &ndash; <strong>the training must go on..</strong></p>

<h3>Epoch 161</h3>

<p><img src="/images/flan-random-161-0.jpg" alt="" /></p>

<p>Big moment here. It looks like something that could possibly be edible.</p>

<h3>Epoch 170</h3>

<p><img src="/images/flan-random-170-0.jpg" alt="" /></p>

<p>Ick! Green Flans! No one is going to want that.</p>

<h3>Epoch 195</h3>

<p><img src="/images/explore-195.jpg" alt="" /></p>

<p>We&rsquo;ve achieved maximum flan, (for the time being).</p>

<h2>Explore</h2>

<p>If you are interested in playing around with the pretrained model, you can check it out <a href="https://github.com/gigasquid/mxnet-gan-flan/blob/master/src/mxnet_gan_flan/gan.clj#L355">here with the pretrained function</a>.
It will load up the trained model and generate flans for you to explore and bring to your dinner parties.</p>

<p>Wrapping up, training GANs is a <em>lot</em> of fun. With MXNet, you can bring the fun with you to Clojure.</p>

<p>Want more, check out this Clojure Conj video &ndash;  <a href="https://www.youtube.com/watch?v=yzfnlcHtwiY">Can You GAN?</a>.</p>
]]></content>
  </entry>
  
</feed>
