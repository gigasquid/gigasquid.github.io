<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine Learning | Squid's Blog]]></title>
  <link href="http://gigasquid.github.io/blog/categories/machine-learning/atom.xml" rel="self"/>
  <link href="http://gigasquid.github.io/"/>
  <updated>2020-01-24T17:10:51-05:00</updated>
  <id>http://gigasquid.github.io/</id>
  <author>
    <name><![CDATA[Carin Meier]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cats and Dogs With Cortex Redux]]></title>
    <link href="http://gigasquid.github.io/blog/2017/11/07/cats-and-dogs-with-cortex-redux/"/>
    <updated>2017-11-07T18:51:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2017/11/07/cats-and-dogs-with-cortex-redux</id>
    <content type="html"><![CDATA[<p>I wrote a <a href="http://gigasquidsoftware.com/blog/2016/12/27/deep-learning-in-clojure-with-cortex/">blog post</a> a while back about using a Clojure machine learning library called <a href="https://github.com/thinktopic/cortex">Cortex</a> to do the Kaggle Cats and Dogs classification challenge.</p>

<p>I wanted to revisit it for a few reasons. The first one is that the Cortex library has progressed and improved considerably over the last year. It&rsquo;s still not at version 1.0, but it my eyes, it&rsquo;s really starting to shine. The second reason is that they recently published an <a href="https://github.com/thinktopic/cortex/tree/master/examples/resnet-retrain">example</a> of using the RESNET50 model, (I&rsquo;ll explain later on), to do fine-tuning or transfer learning. The third reason, is that there is a great new plugin for leiningen the supports using <a href="https://github.com/didiercrunch/lein-jupyter">Jupyter notebooks with Clojure projects</a>. These notebooks are a great way of doing walkthroughs and tutorials.</p>

<p>Putting all these things together, I felt like I was finally at a stage where I could somewhat replicate the first lesson in the <a href="https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogs_cats_redux.ipynb">Practical Deep Learning Course for Coders</a> with Cats and Dogs &ndash; although this time all in Clojure!</p>

<h2>Where to Start?</h2>

<p><img class="<a" src="href="http://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg">http://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg</a>"></p>

<p>In the last blog post, we created our deep learning network and trained the data on scaled down images (like 50x50) from scratch. This time we are much smarter.</p>

<p>We are still of course going to have to get a hold of all the training data from <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data">Kaggle Cats vs Dogs Challenge</a>. The big difference is this time, we are just going to have to train our model for <em>1 epoch</em>. What&rsquo;s more, the results will be way better than before.</p>

<p>How is this possible? We are going to use an already trained model, RESNET50. This model has already been painstakingly trained with a gigantic network that is 50 layers deep on the ImageNet challenge. That&rsquo;s a challenge that has models try to classify a 1000 different categories. The theory is that the inner layers of the network have already learned about the features that make up cats and dogs, all we would need to do is peel off the final layer of the network and graft on a new layers that just learns the final classification for our 2 categories of cats and dogs. This is called <em>transfer learning</em> or <em>retraining</em>.</p>

<h2>Plan of Action</h2>

<ul>
<li>Get all the cats and dogs pictures in the right directory format for training</li>
<li>Train the model with all but the last layer in the RESNET model. The last layer we are going to replace with our own layer that will finetune it to classify only cats and dogs</li>
<li>Run the test data and come up with a spreadsheet of results to submit to Kaggle.</li>
</ul>


<h3>Getting all the data pictures in the right format</h3>

<p>This is the generally the most time consuming step of most deep learning. I&rsquo;ll spare you the gritty details but we want to get all the pictures from the <code>train.zip</code> into the format</p>

<p>```
-data
  -cats-dogs-training</p>

<pre><code>  -cat
      1110.png
      ...
  -dog
      12416.png
      ...
</code></pre>

<p>  -cats-dogs-testing</p>

<pre><code>  -cat
      11.png
      ...
  -dog
      12.png
      ...
</code></pre>

<p>```</p>

<p>The image sizes must also all be resized to match the input of the RESNET50. That means they all have to be 224x224.</p>

<h3>Train the model</h3>

<p>The cortex functions allow you to load the resnet50 model, remove the last layer, freeze all the other layers so that they will not be retrained, and add new layers.</p>

<p>I was surprised that I could actually train the model with all the images at 224x244 with the huge RESNET50 model. I built the uberjar and ran it which helped the performance.</p>

<p><code>lein uberjar</code></p>

<p><code>java -jar target/cats-dogs-cortex-redux.jar</code></p>

<p>Training one epoch took me approximately 6 minutes. Not bad, especially considering that&rsquo;s all the training I really needed to do.</p>

<p><code>
Loss for epoch 1: (current) 0.05875186542016347 (best) null
Saving network to trained-network.nippy
</code></p>

<p>The key point is that it saved the fine tuned network to trained-network.nippy</p>

<h3>Run the Kaggle test results and submit the results</h3>

<p>You will need to do a bit more setup for this. First, you need to get the Kaggle test images for classification. There are 12500 of these in the test.zip file from the site. Under the data directory, create a new directory called kaggle-test. Now unzip the contents of test.zip inside that folder. The full directory with all the test images should now be:</p>

<p><code>data/kaggle-test/test</code></p>

<p>This step takes a long time and you might have to tweak the batch size again depending on your memory. There are 12500 predications to be made. The main logic for this is in function called <code>(kaggle-results batch-size)</code>. It will take a long time to run. It will print the results as it goes along to the kaggle-results.csv file. If you want to check progress you can do wc -l kaggle-results.csv</p>

<p>For me locally, with <code>(cats-dogs/kaggle-results 100)</code> it took me 28 minutes locally.</p>

<h3>Compare the results</h3>

<p><img class="<a" src="href="http://c1.staticflickr.com/5/4518/26477015609_1af781b8da_b.jpg">http://c1.staticflickr.com/5/4518/26477015609_1af781b8da_b.jpg</a>"></p>

<p>My one epoch of fine tuning beat my best results of going through the Practical Deep Learning exercise with the fine tuning the VGG16 model. Not bad at all.</p>

<h2>Summary</h2>

<p>For those of you that are interested in checking out the code, it&rsquo;s out there on <a href="https://github.com/gigasquid/cats-dogs-cortex-redux">github</a></p>

<p>Even more exciting, there is a <a href="https://github.com/gigasquid/cats-dogs-cortex-redux/blob/master/Cats%20and%20Dogs%20in%20Cortex%20(Redux).ipynb">walkthrough in a jupyter notebook</a> with a lein-jupyter plugin.</p>

<p>The Deep Learning world in Clojure is an exciting place to be and gaining tools and traction more and more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deep Learning in Clojure With Cortex]]></title>
    <link href="http://gigasquid.github.io/blog/2016/12/27/deep-learning-in-clojure-with-cortex/"/>
    <updated>2016-12-27T10:44:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2016/12/27/deep-learning-in-clojure-with-cortex</id>
    <content type="html"><![CDATA[<p><strong>Update: Cortex has moved along since I first wrote this blog post, so if you are looking to run the examples, please go and clone the <a href="https://github.com/thinktopic/cortex">Cortex</a> repo and look for the cats and dogs code in the examples directory.</strong></p>

<p>There is an awesome new <em>Clojure-first</em> machine learning library called <a href="https://github.com/thinktopic/cortex">Cortex</a> that was open sourced recently. I&rsquo;ve been exploring it lately and wanted to share my discoveries so far in this post. In our exploration, we are going to tackle one of the classic classification problems of the internet. How do you tell the difference between a cat and dog pic?</p>

<h2>Where to Start?</h2>

<p><img class="<a" src="href="http://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg">http://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg</a>"></p>

<p>For any machine learning problem, we&rsquo;re going to need data. For this, we can use Kaggle&rsquo;s data for the <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data">Cats vs Dogs Challenge</a>.  The training data consists of 25,000 images of cats and dogs. That should be more than enough to train our computer to recognize cats from doggies.</p>

<p>We also need some idea of how to train against the data. Luckily, the Cortex project has a very nice set of examples to help you get started. In particular there is a <a href="https://github.com/thinktopic/cortex/tree/master/examples/suite-classification">suite classification example</a> using MNIST, (hand written digit), corpus. This example contains a number cutting edge features that we&rsquo;ll want to use:</p>

<ul>
<li>Uses GPU for <em>fast</em> computation.</li>
<li>Uses a deep, multi-layered, convolutional layered network for feature recognition.</li>
<li>Has &ldquo;forever&rdquo; training by image augmentation.</li>
<li>Saves the network configuration as it trains to an external nippy file so that it can be imported later.</li>
<li>Has a really nice ClojureScript front end to visualize the training progress with a confusion matrix.</li>
<li>Has a way to import the saved nippy network configuration and perform inference on it to classify a new image.</li>
</ul>


<p>Basically, it has everything we need to hit the ground running.</p>

<h2>Data Wrangling</h2>

<p>To use the example&rsquo;s <em>forever</em> training, we need to get the data in the right form. We need all the images to be the same size as well as in a directory structure that is split up into the training and test images. Furthermore, we want all the dog images to be under a &ldquo;dog&rdquo; directory and the cat images under the &ldquo;cat&rdquo; directory so that the all the indexed images under them have the correct &ldquo;label&rdquo;.  It will look like this:</p>

<p>```
&ndash; training
  &ndash; cat</p>

<pre><code>- 1.png
- 2.png
</code></pre>

<ul>
<li>dog

<ul>
<li>1.png</li>
<li>2.png
```</li>
</ul>
</li>
</ul>


<p>For this task, we are going to use a couple image libraries to help us out:</p>

<p><code>clojure
 [mikera.image.core :as imagez]
 [think.image.image :as image]
</code></p>

<p>We can resize and rewrite the original images into the form we want. For a image size, we&rsquo;re going to go with 52x52. The choice is arbitrary in that I wanted it bigger than the MNIST dataset which is 28x28 so it will be easier to see, but not so big that it kills my CPU. This is even more important since we want to use RGB colors which is 3 channels as opposed to the MNIST grey scale of 1.</p>

<p>```clojure
(def dataset-image-size 52)
(def dataset-num-classes 2)
(def dataset-num-channels 3)
(def dataset-datatype :float)</p>

<p>(defn resize-and-write-data
  [output-dir [idx [file label]]]
  (let [img-path (str output-dir &ldquo;/&rdquo; label &ldquo;/&rdquo; idx &ldquo;.png&rdquo; )]</p>

<pre><code>(when-not (.exists (io/file img-path))
  (io/make-parents img-path)
  (-&gt; (imagez/load-image file)
      (image/resize dataset-image-size dataset-image-size)
      (imagez/save img-path)))
nil))
</code></pre>

<p>```</p>

<p>As far as the split between training images and testing images, we are going the go for an simple even split between testing and training data.</p>

<h2>Network Configuration</h2>

<p>The Network layer configuration is the meat of the whole thing. We are going to go with the exact same network description as the MNIST example:</p>

<p><code>clojure
(defn create-basic-network-description
  []
  [(desc/input dataset-image-size dataset-image-size dataset-num-channels)
   (desc/convolutional 5 0 1 20)
   (desc/max-pooling 2 0 2)
   (desc/relu)
   (desc/convolutional 5 0 1 50)
   (desc/max-pooling 2 0 2)
   (desc/relu)
   (desc/convolutional 1 0 1 50)
   (desc/relu)
   (desc/linear-&gt;relu 1000)
   (desc/dropout 0.5)
   (desc/linear-&gt;softmax dataset-num-classes)])
</code></p>

<p>It uses a series of convolutional layers with max pooling for feature recognition. We&rsquo;ll see if it works for color versions of cats and dogs as well as street numbers.</p>

<p>We&rsquo;ll also keep the image augmentation the same as in the example.</p>

<p>```clojure
(def max-image-rotation-degrees 25)</p>

<p>(defn img-aug-pipeline
  [img]
  (&ndash;> img</p>

<pre><code>  (image-aug/rotate (- (rand-int (* 2 max-image-rotation-degrees))
                       max-image-rotation-degrees)
                    false)
  (image-aug/inject-noise (* 0.25 (rand)))))
</code></pre>

<p>(def ^:dynamic <em>num-augmented-images-per-file</em> 1)
```</p>

<p>It injects one augmented image into our training data by slightly rotating it and adding noise.</p>

<h3>Running it!</h3>

<p>It&rsquo;s time to test it out. Using <code>lein run</code>, we&rsquo;ll launch the <code>train-forever</code> function:</p>

<p>```clojure
(defn train-forever
  []
  (let [dataset (create-dataset)</p>

<pre><code>    initial-description (create-basic-network-description)
    confusion-matrix-atom (display-dataset-and-model dataset initial-description)]
(classification/train-forever dataset observation-&gt;image
                              initial-description
                              :confusion-matrix-atom confusion-matrix-atom)))
</code></pre>

<p>```</p>

<p>This opens a port to a localhost webpage where we can view the progress <code>http://localhost:8091/</code></p>

<p><img class="<a" src="href="http://c3.staticflickr.com/1/599/31877481106_ab49402b71_b.jpg">http://c3.staticflickr.com/1/599/31877481106_ab49402b71_b.jpg</a>"></p>

<p>Below the confusion matrix is shown. This tracks the progress of the training in the classification. In particular, how many times it thought a cat was really a cat and how many times it got it wrong.</p>

<p><img class="<a" src="href="http://c7.staticflickr.com/1/371/31541533750_69d80cc7fa.jpg">http://c7.staticflickr.com/1/371/31541533750_69d80cc7fa.jpg</a>"></p>

<p>As we are training the data, the loss for each epoch is shown on the console as well as when it saves the network to the external file.</p>

<p>After only thirty minutes of training on my Mac Book Pro, we get to some pretty good results, with the correct percentage in the 99s :</p>

<p><img class="<a" src="href="http://c1.staticflickr.com/1/707/31541538600_8e61134375.jpg">http://c1.staticflickr.com/1/707/31541538600_8e61134375.jpg</a>"></p>

<p>It&rsquo;s time to do some inference on our trained network.</p>

<h2>Inference</h2>

<p>Firing up a REPL we can connect to our namespace and use the <code>label-one</code> function from the cortex example to spot check our classification. It reads in the external nippy file that contains the trained network description, takes a random image from the testing directory, and classifies it.</p>

<p>```clojure
(defn label-one
  &ldquo;Take an arbitrary image and label it.&rdquo;
  []
  (let [file-label-pairs (shuffle (classification/directory->file-label-seq testing-dir</p>

<pre><code>                                                                        false))
    [test-file test-label] (first file-label-pairs)
    test-img (imagez/load-image test-file)
    observation (png-&gt;observation dataset-datatype false test-img)]
(imagez/show test-img)
(infer/classify-one-observation (:network-description
                                 (suite-io/read-nippy-file "trained-network.nippy"))
                                observation
                                (ds/create-image-shape dataset-num-channels
                                                       dataset-image-size
                                                       dataset-image-size)
                                dataset-datatype
                                (classification/get-class-names-from-directory testing-dir))))
</code></pre>

<p>```</p>

<p>Running <code>(label-one)</code> gives us the picture:</p>

<p><img class="<a" src="href="http://c2.staticflickr.com/1/423/31105658073_b6143b2f00.jpg">http://c2.staticflickr.com/1/423/31105658073_b6143b2f00.jpg</a>"></p>

<p>and classifies it as a cat. Yipee!</p>

<p><code>clojure
{:probability-map {"cat" 0.9995587468147278, "dog" 4.4119369704276323E-4}, :classification "cat"}
</code></p>

<p>Not bad, but let&rsquo;s try it with something harder. Personally, I&rsquo;m not even sure whether this is a cat or a dog.</p>

<p><img class="<a" src="href="http://c6.staticflickr.com/1/596/31105666133_223dc2f04e_c.jpg">http://c6.staticflickr.com/1/596/31105666133_223dc2f04e_c.jpg</a>"></p>

<p>Feeding it through the program &ndash; it says it is a cat.</p>

<p><code>clojure
 {:probability-map {"cat" 0.9942012429237366, "dog" 0.005798777565360069}, :classification "cat"}
</code></p>

<p>After much <a href="http://www.today.com/pets/cat-or-dog-wild-eyed-cutie-has-us-all-confused-t104835">debate on the internet</a>, I think that is the best answer the humans got too :)</p>

<h2>Kaggle it</h2>

<p>So it seems like we have a pretty good model, why don&rsquo;t we submit our results to the Kaggle competition and see how it rates. All they need is to have us run the classification against their test data of 12,500 images and classify them as 1 = dog or 0 = cat in a csv format.</p>

<p>We will take each image and resize it, then feed it into cortex&rsquo;s <code>infer-n-observations</code> function, to do all our classification as a batch.</p>

<p>```clojure
 (infer/infer-n-observations (:network-description</p>

<pre><code>                                         (suite-io/read-nippy-file "trained-network.nippy"))
                                        observations
                                        (ds/create-image-shape dataset-num-channels
                                                               dataset-image-size
                                                               dataset-image-size)
                                        dataset-datatype)
</code></pre>

<p>```</p>

<p>Finally, we just need to format our results to a csv file and export it:</p>

<p>```clojure
(defn write-kaggle-results [results]
  (with-open [out-file (io/writer &ldquo;kaggle-results.csv&rdquo;)]</p>

<pre><code>(csv/write-csv out-file
               (into [["id" "label"]]
                     (-&gt; (mapv (fn [[id class]] [(Integer/parseInt id) (if (= "dog" class) 1 0)]) results)
                         (sort))))))
</code></pre>

<p>```</p>

<p>After uploading the file to the Kaggle, I was pleased that the answer got in the top 91%! It made it on the <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/leaderboard">Leaderboard</a>.</p>

<h2>Conclusion</h2>

<p>Using an example setup from the Cortex project and 30 minutes of processing time on my laptop, we were able to crunch through some significant data and come up with a trained classification model that was good enough to make the charts in the Kaggle competition. On top of it all, it is in pure Clojure.</p>

<p>In my mind, this is truely impressive and even though the Cortex library is in it&rsquo;s early phases, it puts it on track to be as useful a tool as Tensor Flow for Machine Learning.</p>

<p>Earlier this month, I watched an ACM Learning webcast with Peter Norvig speaking on AI. In it, he spoke of one of the next challenges of AI which is to combine <a href="https://twitter.com/gigasquid/status/806916856040689664?lang=en">symbolic with neural</a>. I can think of no better language than Clojure with it&rsquo;s simplicity, power, and rich LISP heritage to take on the challenge for the future. With the Cortex library, it&rsquo;s off to a great start.</p>

<p><em>If want to see all the cats vs dog  Kaggle Code, it&rsquo;s out on github here <a href="https://github.com/gigasquid/kaggle-cats-dogs">https://github.com/gigasquid/kaggle-cats-dogs</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Neural Networks in Clojure With core.matrix]]></title>
    <link href="http://gigasquid.github.io/blog/2013/12/02/neural-networks-in-clojure-with-core-dot-matrix/"/>
    <updated>2013-12-02T19:28:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2013/12/02/neural-networks-in-clojure-with-core-dot-matrix</id>
    <content type="html"><![CDATA[<p>After having spent some time recently looking at top-down AI, I
thought I would spend some time looking at bottom&rsquo;s up AI, machine
learning and neural networks.</p>

<p>I was pleasantly introduced to <a href="https://twitter.com/mikera">@mikea&rsquo;s</a> <a href="https://github.com/mikera/core.matrix">core.matrix</a> at Clojure Conj
this year and wanted to try making my own neural network using the
library. The purpose of this blog is to share my learnings along the
way.</p>

<h2>What is a neural network?</h2>

<p>A neural network is an approach to machine learning that involves
simulating, (in an idealized way), the way our brains work on a
biological level.  There are three layers to neural network: the input
layer, the hidden layers, and the output layer.  Each layer consists
of neurons that have a value.  In each layer, each neuron is connected to
the neuron in the next layer by a connection strength. To get data
into the neural network, you assign values to the input layer, (values
between 0 and 1). These values are then &ldquo;fed forward&rdquo; to the hidden layer neurons though an algorithm that
relies on the input values and the connection strengths. The values
are finally &ldquo;fed forward&rdquo; in a similar fashion to the output layer.
The &ldquo;learning&rdquo; portion of the neural network comes from &ldquo;training&rdquo; the
network data.  The training data consists of a collection of
associated input values and target values. The training process at a
high level looks like this:</p>

<ul>
<li>Feed forward input values to get the output values</li>
<li>How far off are the output values from the target values?</li>
<li>Calculate the error values and adjust the strengths of the network</li>
<li>Repeat until you think it has &ldquo;learned&rdquo; enough, that is when you
feed the input values in the result of the output values are close
enough to the target you are looking for</li>
</ul>


<p>The beauty of this system is that the neural network, (given the right
configuration and the right training), can approximate any function &ndash;
just by exposing it to data.</p>

<h2>Start Small</h2>

<p>I wanted to start with a very small network so that I could understand
the algorithms and actually do the maths for the tests along the way.
The network configuration I chose is one with 1 hidden layer.  The
input layer has 2 neurons, the hidden layer has 3 neurons and the
output layer has 2 neurons.</p>

<p>```clojure
;;Neurons
;;  Input Hidden  Output
;;  A     1       C
;;  B     2       D
;;        3</p>

<p>;; Connection Strengths
;; Input to Hidden => [[A1 A2 A3] [B1 B2 B3]]
;; Hidden to Output => [[1C 1D] [2C 2D] [3C 3D]]
```</p>

<p>In this example we have:</p>

<ul>
<li>Input Neurons: neuronA neuronB</li>
<li>Hidden Neurons: neuron1 neuron2 neuron3</li>
<li>Output Neurons: neuronC neuronD</li>
<li>Connections between the Input and Hidden Layers

<ul>
<li>neuronA-neuron1</li>
<li>neuronA-neuron2</li>
<li>neuronA-neuron3</li>
<li>neuronB-neuron1</li>
<li>neuronB-neuron2</li>
<li>neuronB-neuron3</li>
</ul>
</li>
<li>Connections betwen the Hidden and Output Layers

<ul>
<li>neuron1-nerounC</li>
<li>neuron1-nerounD</li>
<li>neuron2-nerounC</li>
<li>neuron2-nerounD</li>
<li>neuron3-nerounC</li>
<li>neuron3-nerounD</li>
</ul>
</li>
</ul>


<p>To give us a concrete example to work with, let&rsquo;s actually assign all
our neurons and connection strengths to some real values.</p>

<p>```clojure
(def input-neurons [1 0])
(def input-hidden-strengths [ [0.12 0.2 0.13]</p>

<pre><code>                          [0.01 0.02 0.03]])
</code></pre>

<p>(def hidden-neurons [0 0 0])
(def hidden-output-strengths [[0.15 0.16]</p>

<pre><code>                          [0.02 0.03]
                          [0.01 0.02]])
</code></pre>

<p>```</p>

<h2>Feed Forward</h2>

<p>Alright, we have values in the input neuron layer, let&rsquo;s feed them
forward through the network. The new value of neuron in the hidden
layer is the sum of all the inputs of its connections multiplied by
the connection strength.  The neuron can also have its own threshold,
(meaning you would subtract the threshold from the sum of inputs), but
to keep things a simple as possible in this example, the threshold is
0 &ndash; so we will ignore it.  The sum is then feed into an activation
function, that has an output in the range of -1 to 1.  The activation
function is the tanh function.  We will also need the derivative of
the tanh function a little later when we are calculating errors, so we
will define both here.</p>

<p>```clojure
(def activation-fn (fn [x] (Math/tanh x)))
(def dactivation-fn (fn [y] (&ndash; 1.0 (* y y))))</p>

<p>(defn layer-activation [inputs strengths]
  &ldquo;forward propagate the input of a layer&rdquo;
  (mapv activation-fn</p>

<pre><code>  (mapv #(reduce + %)
   (* inputs (transpose strengths)))))
</code></pre>

<p>```
Note how nice core.matrix works on multipling vectors &lt;3.</p>

<p>So now if we calculate the hidden neuron values from the input [1 0],
we get:</p>

<p><code>clojure
(layer-activation input-neurons input-hidden-strengths)
;=&gt;  [0.11942729853438588 0.197375320224904 0.12927258360605834]
</code></p>

<p>Let&rsquo;s just remember those hidden neuron values for our next step</p>

<p><code>clojure
(def new-hidden-neurons
  (layer-activation input-neurons input-hidden-strengths))
</code></p>

<p>Now we do the same thing to calculate the output values</p>

<p>```clojure
(layer-activation new-hidden-neurons hidden-output-strengths)
;=>  [0.02315019005321053 0.027608061500083565]</p>

<p>(def new-output-neurons
  (layer-activation new-hidden-neurons hidden-output-strengths))
```</p>

<p>Alright!  We have our answer
[0.02315019005321053 0.027608061500083565].
Notice that the values are pretty much the same.  This is because we
haven&rsquo;t trained our network to do anything yet.</p>

<h2>Backwards Propagation</h2>

<p>To train our network, we have to let it know what the answer,(or
target), should be, so we can calculate the errors and finally update
our connection strengths. For this simple example, let&rsquo;s just inverse
the data &ndash; so given an input of [1 0] should give us an output of
[0 1].</p>

<p>```clojure
(def targets [0 1])
````</p>

<h3>Calculate the errors of the output layer</h3>

<p>The first errors that we need to calculate are the ones for the output
layer.  This is found by subtracting the target value form the actual
value and then multiplying by the gradient/ derivative of the
activation function</p>

<p>```clojure
(defn output-deltas [targets outputs]
  &ldquo;measures the delta errors for the output layer (Desired value â€“ actual value) and multiplying it by the gradient of the activation function&rdquo;
  (* (mapv dactivation-fn outputs)</p>

<pre><code> (- targets outputs)))
</code></pre>

<p>(output-deltas targets new-output-neurons)
;=> [-0.023137783141771645 0.9716507764442904]
````</p>

<p>Great let&rsquo;s remember this output deltas for later</p>

<p><code>clojure
(def odeltas (output-deltas targets new-output-neurons))
</code></p>

<h3>Calculate the errors of the hidden layer</h3>

<p>The errors of the hidden layer are based off the deltas that we just
found from the output layer.  In fact, for each hidden neuron, the
error delta is the gradient of the activation function multiplied by
the weighted sum of the ouput deltas of connected ouput neurons and
it&rsquo;s connection strength.  This should remind you of the forward
propagation of the inputs &ndash; but this time we are doing it backwards
with the error deltas.</p>

<p>```clojure
(defn hlayer-deltas [odeltas neurons strengths]
  (* (mapv dactivation-fn neurons)</p>

<pre><code> (mapv #(reduce + %)
       (* odeltas strengths))))
</code></pre>

<p>(hlayer-deltas</p>

<pre><code>odeltas
new-hidden-neurons
hidden-output-strengths)
</code></pre>

<p>;=>  [0.14982559238071416 0.027569216735265096 0.018880751432503236]
```</p>

<p>Great let&rsquo;s remember the hidden layer error deltas for later</p>

<p>```clojure
(def hdeltas (hlayer-deltas</p>

<pre><code>          odeltas
          new-hidden-neurons
          hidden-output-strengths))
</code></pre>

<p>```</p>

<h3>Updating the connection strengths</h3>

<p>Great!  We have all the error deltas, now we are ready to go ahead and
update the connection strengths.  In general this is the same process
for both the hidden-output connections and the input-hidden
connections.</p>

<ul>
<li>weight-change = error-delta * neuron-value</li>
<li>new-weight = weight + learning rate * weight-change</li>
</ul>


<p>The learning rate controls how fast the weigths and errors should be
adjusted.  It the learning rate is too high, then there is the danger
that it will converge to fit the solution too fast and not find the
best solution.  If the learning rate is too low, it may never actually
converge to the right solution given the training data that it is
using. For this example, let&rsquo;s use a training rate of 0.2</p>

<p>```clojure
(defn update-strengths [deltas neurons strengths lrate]
  (+ strengths (* lrate</p>

<pre><code>              (mapv #(* deltas %) neurons))))
</code></pre>

<p>```</p>

<h3>Update the hidden-output strengths</h3>

<p>Updating this layer we are going to look at</p>

<ul>
<li>weight-change = odelta * hidden value</li>
<li>new-weight = weight + (learning rate * weight-change)</li>
</ul>


<p>```clojure
(update-strengths</p>

<pre><code>   odeltas
   new-hidden-neurons
   hidden-output-strengths
   learning-rate)
</code></pre>

<p>;=> [[0.14944734341306073 0.18320832546991603]</p>

<pre><code>[0.019086634528619688 0.06835597662949369]
[0.009401783798869296 0.04512156124675721]]
</code></pre>

<p>```</p>

<p>Of course, let&rsquo;s remember these values too</p>

<p>```clojure
(def new-hidden-output-strengths
  (update-strengths</p>

<pre><code>   odeltas
   new-hidden-neurons
   hidden-output-strengths
   learning-rate))
</code></pre>

<p>```</p>

<h3>Update the input-hidden strengths</h3>

<p>We are going to do the same thing with the input-hidden strengths too.</p>

<ul>
<li>weight-change = hdelta * input value</li>
<li>new-weight = weight + (learning rate * weight-change)</li>
</ul>


<p>```clojure
 (update-strengths</p>

<pre><code>       hdeltas
       input-neurons
       input-hidden-strengths
       learning-rate)
</code></pre>

<p>;=>  [[0.14996511847614283 0.20551384334705303 0.13377615028650064]</p>

<pre><code>       [0.01 0.02 0.03]]
</code></pre>

<p>```</p>

<p>These are our new strengths</p>

<p>```clojure
(def new-input-hidden-strengths
  (update-strengths</p>

<pre><code>   hdeltas
   input-neurons
   input-hidden-strengths
   learning-rate))
</code></pre>

<p>```</p>

<h2>Putting the pieces together</h2>

<p>We have done it!  In our simple example we have:</p>

<ul>
<li>Forward propagated the input to get the output</li>
<li>Calculated the errors from the target through backpropogation</li>
<li>Updated the connection strengths/ weights</li>
</ul>


<p>We just need to put all the pieces together. We&rsquo;ll do this with the
values that we got earlier to make sure it is all working.</p>

<h3>Construct a network representation</h3>

<p>It would be nice if we could represent an entire neural network in a
data structure.  That way the whole transformation of feeding forward
and training the network could give us a new network back.
So lets define the data structure as
[input-neurons input-hidden-strengths hidden-neurons hidden-output-strengths output-neurons].</p>

<p>We will start off with all the values of the neurons being zero.</p>

<p><code>clojure
(def nn [ [0 0] input-hidden-strengths hidden-neurons
hidden-output-strengths [0 0]])
</code></p>

<h3>Generalized feed forward</h3>

<p>Now we can make a feed forward function that takes this network and
constructs a new network based on input values and the
layer-activation function that we defined earlier.</p>

<p>```clojure
(defn feed-forward [input network]
  (let [[in i-h-strengths h h-o-strengths out] network</p>

<pre><code>    new-h (layer-activation input i-h-strengths)
    new-o (layer-activation new-h h-o-strengths)]
[input i-h-strengths new-h h-o-strengths new-o]))
</code></pre>

<p>```</p>

<p>This should match up with the values that we got earlier when we were
just working on the individual pieces.</p>

<p>```clojure
(testing &ldquo;feed forward&rdquo;
  (is (== [input-neurons input-hidden-strengths new-hidden-neurons hidden-output-strengths new-output-neurons]</p>

<pre><code>      (feed-forward [1 0] nn))))
</code></pre>

<p>````</p>

<h3>Generalized update weights / connection strengths</h3>

<p>We can make a similiar update-weights function that calculate the
errors and returns back a new network with the updated weights</p>

<p>```clojure
(defn update-weights [network target learning-rate]
  (let [[ in i-h-strengths h h-o-strengths out] network</p>

<pre><code>    o-deltas (output-deltas target out)
    h-deltas (hlayer-deltas o-deltas h h-o-strengths)
    n-h-o-strengths (update-strengths
                     o-deltas
                     h
                     h-o-strengths
                     learning-rate)
    n-i-h-strengths (update-strengths
                     h-deltas
                     in
                     i-h-strengths
                     learning-rate)]
[in n-i-h-strengths h n-h-o-strengths out]))
</code></pre>

<p>```</p>

<p>This too should match up with the pieces from the earlier examples.</p>

<p>```clojure
(testing &ldquo;update-weights&rdquo;
  (is ( == [input-neurons</p>

<pre><code>        new-input-hidden-strengths
        new-hidden-neurons
        new-hidden-output-strengths
        new-output-neurons]
       (update-weights (feed-forward [1 0] nn) [0 1] 0.2))))
</code></pre>

<p>```</p>

<h3>Generalized train network</h3>

<p>Now we can make a function that takes input and a target and feeds the
input forward and then updates the weights.</p>

<p>```clojure
(defn train-network [network input target learning-rate]
  (update-weights (feed-forward input network) target learning-rate))</p>

<p>(testing &ldquo;train-network&rdquo;
  (is (== [input-neurons</p>

<pre><code>        new-input-hidden-strengths
        new-hidden-neurons
        new-hidden-output-strengths
       new-output-neurons]
      (train-network nn [1 0] [0 1] 0.2))))
</code></pre>

<p>```</p>

<h2>Try it out!</h2>

<p>We are ready to try it out!  Let&rsquo;s train our network on a few examples
of inversing the data</p>

<p>```clojure
(def n1 (&ndash;> nn</p>

<pre><code> (train-network [1 0] [0 1] 0.5)
 (train-network [0.5 0] [0 0.5] 0.5)
 (train-network [0.25 0] [0 0.25] 0.5)))
</code></pre>

<p>```</p>

<p>We&rsquo;ll also make a helper function that just returns the output
neurons for the feed-forward function.</p>

<p><code>clojure
(defn ff [input network]
  (last (feed-forward input network)))
</code></p>

<p>Let&rsquo;s look at the results of the untrained and the trained networks</p>

<p><code>clojure
;;untrained
(ff [1 0] nn) ;=&gt; [0.02315019005321053 0.027608061500083565]
;;trained
(ff [1 0] n1) ;=&gt; [0.03765676393050254 0.10552175312900794]
</code></p>

<p>Whoa!  The trained example isn&rsquo;t perfect, but we can see that it is
getting closer to the right answer.  It is learning!</p>

<h2>MOR Training Data</h2>

<p>Well this is really cool and it is working.  But it would be nicer to
be able to present a set of training data for it to learn on.  For
example, it would be nice to have a training data structure look like:</p>

<p><code>clojure
[ [input target] [input target] ... ]
</code></p>

<p>Let&rsquo;s go ahead and define that.</p>

<p>```clojure
(defn train-data [network data learning-rate]
  (if-let [[input target] (first data)]</p>

<pre><code>(recur
 (train-network network input target learning-rate)
 (rest data)
 learning-rate)
network))
</code></pre>

<p>```</p>

<p>Let&rsquo;s try that out on the example earlier</p>

<p>```clojure
(def n2 (train-data nn [</p>

<pre><code>                    [[1 0] [0 1]]
                    [[0.5 0] [0 0.5]]
                    [[0.25 0] [0 0.25] ]
                    ]
                0.5))
</code></pre>

<p>(ff [1 0] n2) ;=> [0.03765676393050254 0.10552175312900794]
```</p>

<p>Cool. We can now train on data sets. That means we can construct data
sets out of infinite lazy sequences too.  Let&rsquo;s make a lazy training
set of inputs and their inverse.</p>

<p>```clojure
(defn inverse-data []
  (let [n (rand 1)]</p>

<pre><code>[[n 0] [0 n]]))
</code></pre>

<p>```</p>

<p>Let&rsquo;s see how well our network is doing after we train it with some
more data</p>

<p>```clojure
(def n3 (train-data nn (repeatedly 400 inverse-data) 0.5))</p>

<p>(ff [1 0] n3) ;=> [-4.958278484025221E-4 0.8211647699205362]
(ff [0.5 0] n3) ;=> [2.1645760787874696E-4 0.5579396715416916]
(ff [0.25 0] n3) ;=> [1.8183385523103048E-4 0.31130601296149013]
```</p>

<p>Wow. The more examples it sees, the better that network is doing at
learning what to do!</p>

<h3>General Construct Network</h3>

<p>The only piece that we are missing now is to have a function that will
create a general neural network for us.  We can choose how many input
nerurons, hidden neurons, and output neurons and have a network
constructed with random weights.</p>

<p>```clojure
(defn gen-strengths [to from]
  (let [l (* to from)]</p>

<pre><code>(map vec (partition from (repeatedly l #(rand (/ 1 l)))))))
</code></pre>

<p>(defn construct-network [num-in num-hidden num-out]
  (vec (map vec [(repeat num-in 0)</p>

<pre><code>         (gen-strengths num-in num-hidden)
         (repeat num-hidden 0)
         (gen-strengths num-hidden num-out)
         (repeat num-out 0)])))
</code></pre>

<p>```</p>

<p>Now we can construct our network from scratch and train it.</p>

<p><code>clojure
(def tnn (construct-network 2 3 2))
(def n5 (train-data tnn (repeatedly 1000 inverse-data) 0.2))
(ff [1 0] n4) ;=&gt; [-4.954958580800465E-4 0.8160149309699489]
</code></p>

<p>And that&rsquo;s it.  We have constucted a neural network with core.matrix</p>

<h2>Want more?</h2>

<p>I put together a github library based on the neural network code in
the posts.  It is called <a href="https://github.com/gigasquid/k9">K9</a>, named
after Dr. Who&rsquo;s best dog friend.  You can find the examples we have
gone through in the tests.  There is also an example program using it
in the examples directory.  It learns what colors are based on thier
RGB value.</p>

<p>There are a couple web resources I would recommend if you want to look
farther as well.</p>

<ul>
<li><a href="http://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/">Basic Network Tutorial</a></li>
<li><a href="http://www.youtube.com/watch?v=QJ1qgCr09j8&amp;feature=player_embedded">Mike Anderson&rsquo;s Clojure Conj talk on Neural Networks</a></li>
</ul>


<p>Go forth and create Neural Networks!</p>
]]></content>
  </entry>
  
</feed>
