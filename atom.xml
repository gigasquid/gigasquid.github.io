<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Squid's Blog]]></title>
  <link href="http://gigasquid.github.io/atom.xml" rel="self"/>
  <link href="http://gigasquid.github.io/"/>
  <updated>2023-07-02T14:14:10-04:00</updated>
  <id>http://gigasquid.github.io/</id>
  <author>
    <name><![CDATA[Carin Meier]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ciphers With Vector Symbolic Architectures]]></title>
    <link href="http://gigasquid.github.io/blog/2023/07/02/ciphers-with-vector-symbolic-architectures/"/>
    <updated>2023-07-02T12:31:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2023/07/02/ciphers-with-vector-symbolic-architectures</id>
    <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/gigasquid/vsa-clj/main/examples/secret-message.png" alt="" /></p>

<p><em>A secret message inside a 10,000 hyperdimensional vector</em></p>

<p>We&rsquo;ve seen in previous posts how we can encode data structures using <a href="http://gigasquidsoftware.com/blog/2022/12/31/vector-symbolic-architectures-in-clojure/">Vector Symbolic Architectures in Clojure</a>. This is an exploration of how we can use this to develop a cipher to transmit a secret message between two parties.</p>

<h3>A Hyperdimensional Cipher</h3>

<p>Usually, we would develop a dictionary/ cleanup memory of randomly chosen hyperdimensional vectors to represent each symbol. We could do this, but then sharing the dictionary as our key to be able to decode messages would be big. Instead, we could share a single hyperdimensional vector and then use the protect/ rotation operator to create a dictionary of the alphabet and some numbers to order the letters. Think of this as the initial seed symbol and the rest being defined as <code>n+1</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">alphabet</span>
</span><span class='line'><span class="w">  </span><span class="p">[</span><span class="ss">:a</span><span class="w"> </span><span class="ss">:b</span><span class="w"> </span><span class="ss">:c</span><span class="w"> </span><span class="ss">:d</span><span class="w"> </span><span class="ss">:e</span><span class="w"> </span><span class="ss">:f</span><span class="w"> </span><span class="ss">:g</span><span class="w"> </span><span class="ss">:h</span><span class="w"> </span><span class="ss">:i</span><span class="w"> </span><span class="ss">:j</span><span class="w"> </span><span class="ss">:k</span><span class="w"> </span><span class="ss">:l</span><span class="w"> </span><span class="ss">:m</span><span class="w"> </span><span class="ss">:n</span><span class="w"> </span><span class="ss">:o</span><span class="w"> </span><span class="ss">:p</span><span class="w"> </span><span class="ss">:q</span><span class="w"> </span><span class="ss">:r</span><span class="w"> </span><span class="ss">:s</span><span class="w"> </span><span class="ss">:t</span><span class="w"> </span><span class="ss">:u</span><span class="w"> </span><span class="ss">:v</span><span class="w"> </span><span class="ss">:w</span><span class="w"> </span><span class="ss">:x</span><span class="w"> </span><span class="ss">:y</span><span class="w"> </span><span class="ss">:z</span><span class="w"> </span><span class="ss">:end-of-message</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">max-num</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">numbers</span><span class="w"> </span><span class="p">(</span><span class="nb">range </span><span class="mi">1</span><span class="w"> </span><span class="p">(</span><span class="nb">inc </span><span class="nv">max-num</span><span class="p">)))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">key-codes</span><span class="w"> </span><span class="p">(</span><span class="nb">into </span><span class="nv">alphabet</span><span class="w"> </span><span class="nv">numbers</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">add-keys-to-cleanup-mem!</span>
</span><span class='line'><span class="w">  </span><span class="s">&quot;Take a single hdv as a seed and create an alphabet + numbers of them by using rotation/ protect&quot;</span>
</span><span class='line'><span class="w">  </span><span class="p">[</span><span class="nv">seed-hdv</span><span class="p">]</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">vb/reset-hdv-mem!</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">doall</span>
</span><span class='line'><span class="w">    </span><span class="p">(</span><span class="nb">reduce </span><span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">v</span><span class="w"> </span><span class="nv">k</span><span class="p">]</span>
</span><span class='line'><span class="w">              </span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">nv</span><span class="w"> </span><span class="p">(</span><span class="nf">vb/protect</span><span class="w"> </span><span class="nv">v</span><span class="p">)]</span>
</span><span class='line'><span class="w">                </span><span class="p">(</span><span class="nf">vb/add-hdv!</span><span class="w"> </span><span class="nv">k</span><span class="w"> </span><span class="nv">nv</span><span class="p">)</span>
</span><span class='line'><span class="w">                </span><span class="nv">nv</span><span class="p">))</span>
</span><span class='line'><span class="w">            </span><span class="nv">seed-hdv</span>
</span><span class='line'><span class="w">            </span><span class="nv">key-codes</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can then encode a message by using a VSA data structure map with the form:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">{</span><span class="mi">1</span><span class="w"> </span><span class="ss">:c</span>,<span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="ss">:a</span>,<span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="ss">:t</span>,<span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="ss">:s</span><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>where the numbers are the key to the order of the sequence of the message.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">encode-message</span>
</span><span class='line'><span class="w">  </span><span class="s">&quot;Encode a message using key value pairs with numbers for ordering&quot;</span>
</span><span class='line'><span class="w">  </span><span class="p">[</span><span class="nv">message</span><span class="p">]</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nb">when </span><span class="p">(</span><span class="nb">&gt; </span><span class="p">(</span><span class="nb">count </span><span class="nv">message</span><span class="p">)</span><span class="w"> </span><span class="nv">max-num</span><span class="p">)</span>
</span><span class='line'><span class="w">    </span><span class="p">(</span><span class="nf">throw</span><span class="w"> </span><span class="p">(</span><span class="nf">ex-info</span><span class="w"> </span><span class="s">&quot;message too long&quot;</span><span class="w"> </span><span class="p">{</span><span class="ss">:allowed-n</span><span class="w"> </span><span class="nv">max-num</span><span class="p">})))</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">ds</span><span class="w"> </span><span class="p">(</span><span class="nb">zipmap </span><span class="nv">numbers</span>
</span><span class='line'><span class="w">                   </span><span class="p">(</span><span class="nb">conj </span><span class="p">(</span><span class="nf">-&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="nf">mapv</span><span class="w"> </span><span class="nb">str </span><span class="nv">message</span><span class="p">)</span>
</span><span class='line'><span class="w">                              </span><span class="p">(</span><span class="nf">mapv</span><span class="w"> </span><span class="nv">keyword</span><span class="p">))</span>
</span><span class='line'><span class="w">                         </span><span class="ss">:end-of-message</span><span class="p">))]</span>
</span><span class='line'><span class="w">    </span><span class="p">(</span><span class="nb">println </span><span class="s">&quot;Encoding &quot;</span><span class="w"> </span><span class="nv">message</span><span class="w"> </span><span class="s">&quot; into &quot;</span><span class="w"> </span><span class="nv">ds</span><span class="p">)</span>
</span><span class='line'><span class="w">    </span><span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span><span class="w"> </span><span class="nv">ds</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The message is now in a single hyperdimensional vector. We can decode the message by inspecting each of the numbers in the key value pairs encoded in the data structure.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">decode-message</span>
</span><span class='line'><span class="w">  </span><span class="s">&quot;Decode a message by getting the value of the numbered pairs&quot;</span>
</span><span class='line'><span class="w">  </span><span class="p">[</span><span class="nv">msg</span><span class="p">]</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">message-v</span>
</span><span class='line'><span class="w">        </span><span class="nv">_</span><span class="w"> </span><span class="p">(</span><span class="nb">println </span><span class="s">&quot;decoded message-v &quot;</span><span class="w"> </span><span class="nv">message-v</span><span class="p">)</span>
</span><span class='line'><span class="w">        </span><span class="nv">decoded</span><span class="w"> </span><span class="p">(</span><span class="nf">-&gt;&gt;</span><span class="w"> </span><span class="nv">message-v</span>
</span><span class='line'><span class="w">                     </span><span class="p">(</span><span class="nf">partition-by</span><span class="w"> </span><span class="o">#</span><span class="p">(</span><span class="nb">= </span><span class="nv">%</span><span class="w"> </span><span class="ss">:end-of-message</span><span class="p">))</span>
</span><span class='line'><span class="w">                     </span><span class="nv">first</span>
</span><span class='line'><span class="w">                     </span><span class="p">(</span><span class="nf">mapv</span><span class="w"> </span><span class="o">#</span><span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">keyword? </span><span class="nv">%</span><span class="p">)</span>
</span><span class='line'><span class="w">                              </span><span class="p">(</span><span class="nb">name </span><span class="nv">%</span><span class="p">)</span>
</span><span class='line'><span class="w">                              </span><span class="p">(</span><span class="nb">str </span><span class="nv">%</span><span class="p">)))</span>
</span><span class='line'><span class="w">                     </span><span class="p">(</span><span class="nb">apply </span><span class="nv">str</span><span class="p">))]</span>
</span><span class='line'><span class="w">    </span><span class="p">(</span><span class="nb">println </span><span class="s">&quot;Decoded message is &quot;</span><span class="w"> </span><span class="nv">decoded</span><span class="p">)</span>
</span><span class='line'><span class="w">    </span><span class="nv">decoded</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Some example code of generating and decoding the message:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="w">  </span><span class="p">(</span><span class="nf">vb/set-size!</span><span class="w"> </span><span class="mi">1</span><span class="nv">e4</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="k">def </span><span class="nv">seed-key-hdv</span><span class="w"> </span><span class="p">(</span><span class="nf">vb/hdv</span><span class="p">))</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">add-keys-to-cleanup-mem!</span><span class="w"> </span><span class="nv">seed-key-hdv</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">image/write-image-hdv</span><span class="w"> </span><span class="s">&quot;seed-key-hdv&quot;</span><span class="w"> </span><span class="nv">seed-key-hdv</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="k">def </span><span class="nv">message</span><span class="w"> </span><span class="p">(</span><span class="nf">encode-message</span><span class="w"> </span><span class="s">&quot;cats&quot;</span><span class="p">))</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">image/write-image-hdv</span><span class="w"> </span><span class="s">&quot;secret-message&quot;</span><span class="w"> </span><span class="nv">message</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">decode-message</span><span class="w"> </span><span class="nv">message</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="c1">;=&gt; &quot;cats&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The cool thing is that both hyperdimensional dictionary and the hyperdimensional encoded message can both be shared as a simple image like these:</p>

<ul>
<li><p><img src="https://raw.githubusercontent.com/gigasquid/vsa-clj/main/examples/seed-key-hdv.png" alt="" /> The seed key to generate the dictionary/ cleanup-mem</p></li>
<li><p><img src="https://raw.githubusercontent.com/gigasquid/vsa-clj/main/examples/secret-message.png" alt="" />The encoded secret message</p></li>
</ul>


<p>Then you can load up the seed key/ message from the image. Once you have the dictionary shared, you can create multiple encoded messages with it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">loaded-key</span><span class="w"> </span><span class="p">(</span><span class="nf">image/read-image-to-hdv</span><span class="w"> </span><span class="s">&quot;examples/seed-key-hdv.png&quot;</span><span class="p">))</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">add-keys-to-cleanup-mem!</span><span class="w"> </span><span class="nv">loaded-key</span><span class="p">)</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="k">def </span><span class="nv">loaded-message</span><span class="w"> </span><span class="p">(</span><span class="nf">image/read-image-to-hdv</span><span class="w"> </span><span class="s">&quot;examples/secret-message.png&quot;</span><span class="p">))</span>
</span><span class='line'><span class="w">  </span><span class="p">(</span><span class="nf">decode-message</span><span class="w"> </span><span class="nv">loaded-message</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Caveats</h3>

<p>Please keep in mind that this is just an experiment - <em>do not use</em> for anything important. Another interesting factor to keep in mind is that the VSA operations to get the key value are probabilistic  so that the correct decoding is not guaranteed. In fact, I set a limit on the 10,000 dimensional vector message to be 4 letters, which I found to be pretty reliable. For example, with 10,000 dimensions, encoding <code>catsz</code> decoded as <code>katsz</code>.</p>

<p>Increasing the number of dimensions lets you encode longer messages. This article is a good companion to look at <a href="https://link.springer.com/article/10.1007/s10462-021-10110-3">capacity across different implementations of VSAs</a>.</p>

<h3>Conclusion</h3>

<p>VSAs could be an interesting way to do ciphers. Some advantages could be that the distribution of the information across the vector and the nature of the mapped data structure, it is hard to do things like vowel counting to try to decipher messages. Of course you don&rsquo;t need to have letters and numbers be the only symbols used in the dictionary, they could represent other things as well. The simplicity of being able to encode data structures in a form that can easily be expressed as a black and white image, also lends in its flexibility. Another application might be the ability to combine this technique with deep learning to keep information safe during the training process.</p>

<p><a href="https://github.com/gigasquid/vsa-clj/blob/main/examples/vsa_cipher.clj">Link to the full github code</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vector Symbolic Architectures in Clojure]]></title>
    <link href="http://gigasquid.github.io/blog/2022/12/31/vector-symbolic-architectures-in-clojure/"/>
    <updated>2022-12-31T15:41:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2022/12/31/vector-symbolic-architectures-in-clojure</id>
    <content type="html"><![CDATA[<p><img src="https://live.staticflickr.com/65535/52596142860_c4cf8642b0_z.jpg" alt="" /></p>

<p><em>generated with Stable Diffusion</em></p>

<p>Before diving into the details of what Vector Symbolic Architectures are and what it means to implement Clojure data structures in them, I&rsquo;d like to start with some of my motivation in this space.</p>

<h2>Small AI for More Personal Enjoyment</h2>

<p>Over the last few years, I&rsquo;ve spent time learning, exploring, and contributing to open source deep learning. It continues to amaze me with its rapid movement and achievements at scale. However, the scale is really too big and too slow for me to enjoy it anymore.</p>

<p>Between work and family, I don&rsquo;t have a lot of free time. When I do get a few precious hours to do some coding <em>just for me</em>, I want it it to be small enough for me to fire up and play with it in a REPL on my local laptop and get a result back in under two minutes.</p>

<p>I also believe that the current state of AI is not likely to produce any more  meaningful <em>revolutionary</em> innovations in the current mainstream deep learning space. This is not to say that there won&rsquo;t be advances. Just as commercial airlines transformed the original first flight, I&rsquo;m sure we are going to continue to see the transformation of society with current big models at scale - I just think the next leap forward is going to come from somewhere else. And that somewhere else is going to be <em>small</em> AI.</p>

<h2>Vector Symbolic Architures aka Hyperdimensional Computing</h2>

<p>Although I&rsquo;m  talking about small AI,  VSA or Hyperdimensional computing is based on really big vectors - like 1,000,000 dimensions. The beauty and simplicity in it is that everything is a hypervector - symbols, maps, lists. Through the <a href="http://rctn.org/vs265/kanerva09-hyperdimensional.pdf">blessing of high dimensionality</a>, any random hypervector is mathematically guaranteed to be orthogonal to any other one. This all enables some cool things:</p>

<ul>
<li>Random hypervectors can be used to represent symbols (like numbers, strings, keywords, etc..)</li>
<li>We can use an algebra to operate on hypervectors: <em>bundling</em> and <em>binding</em> operations create new hypervectors that are compositions of each other and can store and retrieve key value pairs. These operations furthermore are <em>fuzzy</em> due to the nature of working with vectors. In the following code examples, I will be using the concrete model of <a href="https://redwood.berkeley.edu/wp-content/uploads/2021/08/Module2_VSA_models_slides.pdf">MAP (Multiply, Add, Permute)</a> by <a href="https://www.rossgayler.com/">R. Gayler</a>.</li>
<li>We can represent Clojure data structures such as maps and vectors in them and perform operations such as <code>get</code> with probabilistic outcomes.</li>
<li>Everything is a hypervector! I mean you have a keyword that is a symbol that is a hypervector, then you bundle that with other keywords to be a map. The result is a single hypervector. You then create a sequence structure and add some more in. The result is a single hypervector. The simplicity in the algebra and form of the VSA is beautiful - not unlike LISP itself. Actually, <a href="https://redwood.berkeley.edu/wp-content/uploads/2021/08/Neubert2019_Article_AnIntroductionToHyperdimension.pdf">P. Kanerva thought that a LISP could be made from it</a>. In my exploration, I only got as far as making some Clojure data structures, but I&rsquo;m sure it&rsquo;s possible.</li>
</ul>


<h2>Start with an Intro and a Paper</h2>

<p>A good place to start with Vector Symbolic Architectures is actually the paper referenced above - <a href="https://redwood.berkeley.edu/wp-content/uploads/2021/08/Neubert2019_Article_AnIntroductionToHyperdimension.pdf">An Introduction to Hyperdimensional Computing for Robots</a>. In general, I find the practice of taking a paper and then trying to implement it a great way to learn.</p>

<p>To work with VSAs in Clojure, I needed a high performing Clojure library with tensors and data types. I reached for <a href="https://github.com/techascent/tech.datatype">https://github.com/techascent/tech.datatype</a>. It could handle a million dimensions pretty easily on my laptop.</p>

<p>To create a new hypervector - simply chose random values between -1 and 1. This gives us a direction in space which is enough.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;; Uses Gaylor Method for HDV Operations</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">size</span> <span class="mi">1</span><span class="nv">e6</span><span class="p">)</span>  <span class="c1">; big enough for the &quot;Blessing of Dimensionality&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">binary-rand</span>
</span><span class='line'>  <span class="s">&quot;Choose a random binary magnitude for the vector +1 or -1&quot;</span>
</span><span class='line'>  <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">&gt; </span><span class="p">(</span><span class="nf">rand</span><span class="p">)</span> <span class="mf">0.5</span><span class="p">)</span> <span class="mi">-1</span> <span class="mi">1</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">hdv</span>
</span><span class='line'>  <span class="s">&quot;Create a random hyperdimensional vector of default size&quot;</span>
</span><span class='line'>  <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">dtt/-&gt;tensor</span> <span class="p">(</span><span class="nf">repeatedly</span> <span class="nv">size</span> <span class="o">#</span><span class="p">(</span><span class="nf">binary-rand</span><span class="p">))</span> <span class="ss">:datatype</span> <span class="ss">:int8</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The only main operations to create key value pairs is addition and matrix multiplication.</p>

<p>Adding two hyperdimensional vectors, (hdvs), together is calling bundling. Note we clip the values to 1 or -1. At high dimensions, only the direction really matters not the magnitude.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">clip</span>
</span><span class='line'>  <span class="s">&quot;Clips the hyperdimensional vector magnitude to 1 or -1.</span>
</span><span class='line'><span class="s">   We can discard these because of the nature of the large vectors</span>
</span><span class='line'><span class="s">   that the mangitudes do not matter&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">v</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">v</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">dtype-fn/min</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">dtype-fn/max</span> <span class="mi">-1</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">bundle</span>
</span><span class='line'>  <span class="s">&quot;Adds two hyperdimensional vectors together into a single bundle&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">v1</span> <span class="nv">v2</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">bundle-op</span> <span class="nv">v1</span> <span class="nv">v2</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">clip</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can assign key values using <code>bind</code> which is matrix multiplication.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">bind</span>
</span><span class='line'>  <span class="s">&quot;Binds two HDVs using the multiplication operator. This binding is akin to assigning a symbol to a value. &quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">v1</span> <span class="nv">v2</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">dtype-fn/*</span> <span class="nv">v1</span> <span class="nv">v2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>One cool thing is that the binding of a key value pair is also the inverse of itself. So to unbind is just to bind again.</p>

<p>The final thing we need is a cleanup memory. The purpose of this is to store the hdv somewhere without any noise. As the hdv gets bundled with other operations there is noise associated with it. It helps to use the cleaned up version by comparing the result to the memory version for future operations. For Clojure, this can be a simple atom.</p>

<p>Following along the example in the paper, we reset the cleanup memory and add some symbols.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/reset-hdv-mem!</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="ss">:name</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="s">&quot;Alice&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="ss">:yob</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="mi">1980</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="ss">:high-score</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="mi">1000</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next we create the key value map with combinations of <code>bind</code> and <code>bundle</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">H</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">vb/bind</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="ss">:name</span><span class="p">)</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="s">&quot;Alice&quot;</span><span class="p">))</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">vb/bundle</span>
</span><span class='line'>        <span class="p">(</span><span class="nf">vb/bind</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="ss">:yob</span><span class="p">)</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="mi">1980</span><span class="p">)))</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">vb/bundle</span>
</span><span class='line'>        <span class="p">(</span><span class="nf">vb/bind</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="ss">:high-score</span><span class="p">)</span> <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="mi">1000</span><span class="p">)))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>So <code>H</code> is just one hypervector as a result of this. We can then query it. <code>unbind-get</code> is using the <code>bind</code> operation as inverse. So if we want to query for the <code>:name</code> value, we get the <code>:name</code> hdv from memory and do the <code>bind</code> operation on the <code>H</code> data structure which is the inverse.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/unbind-get</span> <span class="nv">H</span> <span class="ss">:name</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; [&quot;Alice&quot; #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;  [-1 1 1 ... 1 -1 -1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can find other values like <code>:high-score</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/unbind-get</span> <span class="nv">H</span> <span class="ss">:high-score</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;;  [1000 #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;; [-1 -1 1 ... -1 1 1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Or go the other way and look for <code>Alice</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/unbind-get</span> <span class="nv">H</span> <span class="s">&quot;Alice&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; [:name #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;; [-1 1 -1 ... -1 -1 -1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now that we have the fundamentals from the paper, we can try to implement some Clojure data structures.</p>

<h2>Clojure Data Structures in VSAs</h2>

<p>First things first, let&rsquo;s clear our cleanup memory.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/reset-hdv-mem!</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s start off with a map, (keeping to non-nested versions to keep things simple).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">our-first-vsa-map</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">{</span><span class="ss">:x</span> <span class="mi">1</span> <span class="ss">:y</span> <span class="mi">2</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The result is a 1,000,000 dimension hypervector - but remember all the parts are also hypervectors as well. Let&rsquo;s take a look at what is in the cleanup memory so far.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="o">@</span><span class="nv">vb/cleanup-mem</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; {:x #tech.v3.tensor&lt;int8&gt;[1000000][1 -1 1 ... 1 -1 -1],</span>
</span><span class='line'><span class="c1">;;  1 #tech.v3.tensor&lt;int8&gt;[1000000][1 1 -1 ... -1 -1 -1],</span>
</span><span class='line'><span class="c1">;;  :y #tech.v3.tensor&lt;int8&gt;[1000000][1 1 -1 ... 1 1 1],</span>
</span><span class='line'><span class="c1">;;  2 #tech.v3.tensor&lt;int8&gt;[1000000][-1 -1 -1 ... -1 -1 1]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can write a <code>vsa-get</code> function that takes the composite hypervector of the map and get the value from it by finding the closest match with cosine similarity to the cleanup memory.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">our-first-vsa-map</span> <span class="ss">:x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [1 #tech.v3.tensor&lt;int8&gt;[1000000][1 1 -1 ... -1 -1 -1]</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the example above, the symbolic value is the first item in the vector, in this case the number 1, and the actual hypervector is the second value.</p>

<p>We can add onto the map with a new key value pair.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">our-second-vsa-map</span> <span class="p">(</span><span class="nf">vd/vsa-assoc</span> <span class="nv">our-first-vsa-map</span> <span class="ss">:z</span> <span class="mi">3</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">our-second-vsa-map</span> <span class="ss">:z</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [3 #tech.v3.tensor&lt;int8&gt;[1000000][1 -1 1 ... -1 -1 1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can represent Clojure vectors as VSA data structures as well by using the permute (or rotate) and adding them like a stack.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">our-first-vsa-vector-of-maps</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">[{</span><span class="ss">:x</span> <span class="mi">1</span><span class="p">}</span> <span class="p">{</span><span class="ss">:x</span> <span class="mi">2</span> <span class="ss">:y</span> <span class="mi">3</span><span class="p">}]))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; We can get the value of x in the 2nd map by</span>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">our-first-vsa-vector-of-maps</span> <span class="ss">:x</span> <span class="p">{</span><span class="ss">:idx</span> <span class="mi">1</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; [2 #tech.v3.tensor&lt;int8&gt;[1000000][-1 1 1 ... 1 -1 1]]</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; Or the first map</span>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">our-first-vsa-vector-of-maps</span> <span class="ss">:x</span> <span class="p">{</span><span class="ss">:idx</span> <span class="mi">0</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [1 #tech.v3.tensor&lt;int8&gt;[1000000][-1 -1 1 ... 1 1 1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can also add onto the Clojure vector with a conj.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">our-second-vsa-vector-of-maps</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">vd/vsa-conj</span> <span class="nv">our-first-vsa-vector-of-maps</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">{</span><span class="ss">:z</span> <span class="mi">5</span><span class="p">})))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">our-second-vsa-vector-of-maps</span> <span class="ss">:z</span> <span class="p">{</span><span class="ss">:idx</span> <span class="mi">2</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [5 #tech.v3.tensor&lt;int8&gt;[1000000][-1 1 1 ... -1 -1 -1]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>What is really cool about this is that we have built in fuzziness or similarity matching. For example, with this map, we have more than one possibility of matching.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">vsa-simple-map</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">{</span><span class="ss">:x</span> <span class="mi">1</span> <span class="ss">:y</span> <span class="mi">1</span> <span class="ss">:z</span> <span class="mi">3</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can see all the possible matches and scores</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">vsa-simple-map</span> <span class="ss">:x</span> <span class="p">{</span><span class="ss">:threshold</span> <span class="mi">-1</span> <span class="ss">:verbose?</span> <span class="nv">true</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [{1 #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;      [1 -1 1 ... -1 -1 -1], :dot 125165.0, :cos-sim 0.1582533568106879}  {:x #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;      [1 -1 -1 ... -1 -1 1], :dot 2493.0, :cos-sim 0.0031520442498225933} {:z #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;      [-1 -1 1 ... 1 1 -1], :dot 439.0, :cos-sim 5.550531190020531E-4}    {3 #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;      [-1 -1 1 ... -1 -1 1], :dot -443.0, :cos-sim -5.601105506102723E-4}  {:y #tech.v3.tensor&lt;int8&gt;[1000000]</span>
</span><span class='line'><span class="c1">;;      [-1 -1 1 ... 1 1 1], :dot -751.0, :cos-sim -9.495327844431478E-4}]</span>
</span></code></pre></td></tr></table></div></figure>


<p>This opens up the possibility of defining compound symbolic values and doing fuzzy matching. For example with colors.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/reset-hdv-mem!</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">primary-color-vsa-map</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">{</span><span class="ss">:x</span> <span class="ss">:red</span> <span class="ss">:y</span> <span class="ss">:yellow</span> <span class="ss">:z</span> <span class="ss">:blue</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s add a new compound value to the cleanup memory that is green based on yellow and blue.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vb/add-hdv!</span> <span class="ss">:green</span> <span class="p">(</span><span class="nf">vb/bundle</span>
</span><span class='line'>                      <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="ss">:yellow</span><span class="p">)</span>
</span><span class='line'>                      <span class="p">(</span><span class="nf">vb/get-hdv</span> <span class="ss">:blue</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now we can query the hdv color map for things that are close to green.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">primary-color-vsa-map</span> <span class="ss">:green</span> <span class="p">{</span><span class="ss">:threshold</span> <span class="mf">0.1</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  [{:z #tech.v3.tensor&lt;int8&gt;[1000000][1 -1 1 ... -1 1 1]}</span>
</span><span class='line'><span class="c1">;;     {:y #tech.v3.tensor&lt;int8&gt;[1000000] [-1 1 1 ... 1 1 1]}]</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can also define an <code>inspect</code> function for a hdv by comparing the similarity of all the values of the cleanup memory in it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">vd/vsa-inspect</span> <span class="nv">primary-color-vsa-map</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; Note that it includes green in it since it is a compound value</span>
</span><span class='line'><span class="c1">;; =&gt;  #{:y :yellow :green :z :red :blue :x}</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-inspect</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">{</span><span class="ss">:x</span> <span class="ss">:red</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  #{:red :x}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, we can implement clojure <code>map</code> and <code>filter</code> functions on the vector data structures that can also include fuzziness.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">color-vsa-vector-map</span> <span class="p">(</span><span class="nf">vd/clj-&gt;vsa</span> <span class="p">[{</span><span class="ss">:x</span> <span class="ss">:yellow</span><span class="p">}</span> <span class="p">{</span><span class="ss">:x</span> <span class="ss">:green</span><span class="p">}</span> <span class="p">{</span><span class="ss">:z</span> <span class="ss">:red</span><span class="p">}]))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">vd/vsa-map</span> <span class="o">#</span><span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">%</span> <span class="ss">:yellow</span> <span class="p">{</span><span class="ss">:threshold</span> <span class="mf">0.01</span><span class="p">})</span>
</span><span class='line'>                  <span class="p">(</span><span class="nf">mapv</span> <span class="nv">ffirst</span><span class="p">))</span>
</span><span class='line'>            <span class="nv">color-vsa-vector-map</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  ([:x] [:x] [])</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">color-vsa-vector-map</span>
</span><span class='line'>     <span class="p">(</span><span class="nf">vd/vsa-filter</span> <span class="o">#</span><span class="p">(</span><span class="nf">vd/vsa-get</span> <span class="nv">%</span> <span class="ss">:yellow</span> <span class="p">{</span><span class="ss">:threshold</span> <span class="mf">0.01</span><span class="p">}))</span>
</span><span class='line'>     <span class="nv">count</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;; =&gt;  2</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Wrap Up</h2>

<p>VSAs and hyperdimensional computing seem like a natural fit for LISP and Clojure. I&rsquo;ve only scratched the surface here in how the two can fit together. I hope that more people are inspired to look into it and <em>small AI with big dimensions</em>.</p>

<p>Full code and examples here <a href="https://github.com/gigasquid/vsa-clj">https://github.com/gigasquid/vsa-clj</a>.</p>

<p><em>Special thanks to Ross Gayler in helping me to implement VSAs and understanding their coolness.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Breakfast With Zero-Shot NLP]]></title>
    <link href="http://gigasquid.github.io/blog/2021/03/15/breakfast-with-zero-shot-nlp/"/>
    <updated>2021-03-15T09:07:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2021/03/15/breakfast-with-zero-shot-nlp</id>
    <content type="html"><![CDATA[<p><img src="https://i.imgflip.com/51ror1.jpg" alt="" /></p>

<p>What if I told you that you could pick up a library model and instantly classify text with arbitrary categories without any training or fine tuning?</p>

<p>That is exactly what we are going to do with <a href="https://joeddav.github.io/blog/2020/05/29/ZSL.html">Hugging Face&rsquo;s zero-shot learning model</a>. We will also be using <a href="https://github.com/clj-python/libpython-clj">libpython-clj</a> to do this exploration without leaving the comfort of our trusty Clojure REPL.</p>

<h3>What&rsquo;s for breakfast?</h3>

<p>We&rsquo;ll start off by taking some text from a recipe description and trying to decide if it&rsquo;s for breakfast, lunch or dinner:</p>

<p><code>"French Toast with egg and bacon in the center with maple syrup on top. Sprinkle with powdered sugar if desired."</code></p>

<p>Next we will need to install the required python deps:</p>

<p><code>pip install numpy torch transformers lime</code></p>

<p>Now we just need to set up the libpython clojure namespace to load the Hugging Face transformers library.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">gigasquid.zeroshot</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span>
</span><span class='line'>   <span class="p">[</span><span class="nv">libpython-clj2.python</span> <span class="ss">:as</span> <span class="nv">py</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">py.</span> <span class="nv">py..</span> <span class="nv">py.-</span><span class="p">]]</span>
</span><span class='line'>   <span class="p">[</span><span class="nv">libpython-clj2.require</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">require-python</span><span class="p">]]))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">[</span><span class="nv">transformers</span> <span class="ss">:bind-ns</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>Setup is complete. We are now ready to classify with zeroshot.</p>

<h4>Classify with Zero Shot</h4>

<p>To create the classifier with zero shot, you need only create it with a handy pipeline function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">classifier</span> <span class="p">(</span><span class="nf">py.</span> <span class="nv">transformers</span> <span class="s">&quot;pipeline&quot;</span> <span class="s">&quot;zero-shot-classification&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>After that you need just the text you want to classify and category labels you want to use.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">text</span> <span class="s">&quot;French Toast with egg and bacon in the center with maple syrup on top. Sprinkle with powdered sugar if desired.&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">labels</span> <span class="p">[</span><span class="s">&quot;breakfast&quot;</span> <span class="s">&quot;lunch&quot;</span> <span class="s">&quot;dinner&quot;</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>Classification is only a function call away with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">classifier</span> <span class="nv">text</span> <span class="nv">labels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span><span class="ss">&#39;labels</span><span class="o">&#39;</span><span class="err">:</span> <span class="p">[</span><span class="ss">&#39;breakfast</span><span class="o">&#39;</span>, <span class="ss">&#39;lunch</span><span class="o">&#39;</span>, <span class="ss">&#39;dinner</span><span class="o">&#39;</span><span class="p">]</span>,
</span><span class='line'> <span class="ss">&#39;scores</span><span class="o">&#39;</span><span class="err">:</span> <span class="p">[</span><span class="mf">0.989736795425415</span>, <span class="mf">0.007010194938629866</span>, <span class="mf">0.003252972150221467</span><span class="p">]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Breakfast is the winner. Notice that all the  probabilities add up to 1. This is because the default mode for <code>classify</code> uses <code>softmax</code>. We can change that so the categories are each considered independently with the <code>:multi-class</code> option.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">classifier</span> <span class="nv">text</span> <span class="nv">labels</span> <span class="ss">:multi_class</span> <span class="nv">true</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span><span class="ss">&#39;labels</span><span class="o">&#39;</span><span class="err">:</span> <span class="p">[</span><span class="ss">&#39;breakfast</span><span class="o">&#39;</span>, <span class="ss">&#39;lunch</span><span class="o">&#39;</span>, <span class="ss">&#39;dinner</span><span class="o">&#39;</span><span class="p">]</span>,
</span><span class='line'> <span class="ss">&#39;scores</span><span class="o">&#39;</span><span class="err">:</span> <span class="p">[</span><span class="mf">0.9959920048713684</span>, <span class="mf">0.22608685493469238</span>, <span class="mf">0.031050905585289</span><span class="p">]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This is a really powerful technique for such an easy to use library. However, how can we do anything with it if we don&rsquo;t understand how it is working and get a handle on how to debug it. We need some level of trust in it for utility.</p>

<p>This is where LIME enters.</p>

<h3>Using LIME for Interpretable Models</h3>

<p>One of the biggest problems holding back applying state of the art machine learning models to real life problems is that of interpretability and trust. The <a href="https://github.com/marcotcr/lime">lime technique</a> is a well designed tool to help with this. One of the reasons that I really like it is that it is <em>model agnostic</em>. This means that you can use it with whatever code you want to use with it as long as you adhere to it&rsquo;s <em>api</em>. You need to provide it with the input and a function that will classify and return the probabilities in a numpy array.</p>

<p>The creation of the explainer is only a <code>require</code> away:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">[</span><span class="nv">lime.lime_text</span> <span class="ss">:as</span> <span class="nv">lime</span><span class="p">])</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="ss">&#39;numpy</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">explainer</span> <span class="p">(</span><span class="nf">lime/LimeTextExplainer</span> <span class="ss">:class_names</span> <span class="nv">labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>We need to create a function that will take in some text and then return the probabilities  for the labels. Since the zeroshot classifier will reorder the returning labels/probs by the value, we need to make sure that it will match up by index to the original labels.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">predict-probs</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">text</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">result</span> <span class="p">(</span><span class="nf">classifier</span> <span class="nv">text</span> <span class="nv">labels</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">result-scores</span> <span class="p">(</span><span class="nb">get </span><span class="nv">result</span> <span class="s">&quot;scores&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">result-labels</span> <span class="p">(</span><span class="nb">get </span><span class="nv">result</span> <span class="s">&quot;labels&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">result-map</span> <span class="p">(</span><span class="nb">zipmap </span><span class="nv">result-labels</span> <span class="nv">result-scores</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">mapv</span> <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">cn</span><span class="p">]</span>
</span><span class='line'>            <span class="p">(</span><span class="nb">get </span><span class="nv">result-map</span> <span class="nv">cn</span><span class="p">))</span>
</span><span class='line'>          <span class="nv">labels</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">predict-texts</span>
</span><span class='line'>  <span class="p">[</span><span class="nv">texts</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">println </span><span class="s">&quot;lime texts are &quot;</span> <span class="nv">texts</span><span class="p">)</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">numpy/array</span> <span class="p">(</span><span class="nf">mapv</span> <span class="nv">predict-probs</span> <span class="nv">texts</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'> <span class="p">(</span><span class="nf">predict-texts</span> <span class="p">[</span><span class="nv">text</span><span class="p">])</span> <span class="c1">;=&gt;  [[0.99718672 0.00281324]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally we make an explanation for our text here. We are only using 6 features and 100 samples, to keep the cpus down, but in real life you would want to use closer to the default amount of <code>5000</code> samples. The samples are how the explainers work, it modifies the text over and over again and sees the difference in classification values. For example, one of the sample texts for our case is <code>' Toast with   bacon in the center with  syrup on .  with  sugar  desired.'</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">exp-result</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">py.</span> <span class="nv">explainer</span> <span class="s">&quot;explain_instance&quot;</span> <span class="nv">text</span> <span class="nv">predict-texts</span>
</span><span class='line'>       <span class="ss">:num_features</span> <span class="mi">6</span>
</span><span class='line'>       <span class="ss">:num_samples</span> <span class="mi">100</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">py.</span> <span class="nv">exp-result</span> <span class="s">&quot;save_to_file&quot;</span> <span class="s">&quot;explanation.html&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://live.staticflickr.com/65535/51039510876_e547177bb2_h.jpg" alt="" /></p>

<p>Now it becomes more clear. The model is using mainly the word <code>toast</code> to classify it as breakfast with supporting words also being <code>french</code>, <code>egg</code>, <code>maple</code>, and <code>syrup</code>. The word <code>the</code> is also in there too which could be an artifact of the low numbers of samples we used or not. But now at least we have the tools to dig in and understand.</p>

<h2>Final Thoughts</h2>

<p>Exciting advances are happening in Deep Learning and NLP. To make them truly useful,  we will need to continue to consider how to make them interpretable and debuggable.</p>

<p>As always, keep your Clojure REPL handy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thoughts on AI Debate 2]]></title>
    <link href="http://gigasquid.github.io/blog/2020/12/24/thoughts-on-ai-debate-2/"/>
    <updated>2020-12-24T10:59:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2020/12/24/thoughts-on-ai-debate-2</id>
    <content type="html"><![CDATA[<p><img src="https://montrealartificialintelligence.com/aidebate2mosaic1440x720v8.jpg" alt="" /></p>

<h2>AI Debate 2 from Montreal.AI</h2>

<p>I had the pleasure of watching the second AI debate from Montreal.AI last night. The first AI debate occurred last year between <a href="https://yoshuabengio.org/">Yoshua Bengio</a> and <a href="https://en.wikipedia.org/wiki/Gary_Marcus">Gary Marcus</a> entitled <a href="https://montrealartificialintelligence.com/aidebate.html">“The Best Way Forward for AI”</a> in which Yoshua argued that Deep Learning could achieve General AI through its own paradigm, while Marcus argued that Deep Learning alone was not sufficient and needed a hybrid approach involving symbolics and inspiration from other disciplines.</p>

<p><br></p>

<p>This interdisciplinary thread of Gary’s linked the two programs. The second AI debate was entitled <a href="https://montrealartificialintelligence.com/aidebate2.html">“Moving AI Forward: An Interdisciplinary Approach”</a> and reflected a broad panel that explored themes on architecture, neuroscience and psychology, and trust/ethics. The second program was not really a debate, but more of a showcase of ideas in the form of 3 minute presentations from the panelists and discussion around topics with Marcus serving as a capable moderator.</p>

<p><br></p>

<p>The program aired Wednesday night and was 3 hours long. I watched it live with an unavoidable break in the middle to fetch dinner for my family, but the whole recording is up now on the <a href="https://montrealartificialintelligence.com/aidebate2.html">website</a>. Some of the highlights for me were thoughts around System 1 and System 2,  reinforcement learning, and the properties of evolution.</p>

<p><br></p>

<p>There was much discussion around System 1 and System 2 in relation to AI. One of the author’s of the recently published paper <a href="https://arxiv.org/pdf/2010.06002.pdf">“Thinking Fast and Slow in AI”</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Francesca.Rossi2">Francesca Rossi</a> was a panelist as well as <a href="https://en.wikipedia.org/wiki/Daniel_Kahneman">Danny Kahneman</a> the author of “Thinking Fast and Slow”. Applying the abstraction of these sysems to AI with Deep Learning being System 1 is very appealing, however as Kahneman pointed out in his talk, this abstraction is leaky at its heart as the human System 1 encompasses much more than current AI system 1, (like a model of the world). It is interesting to think of one of the differences in human System 1 and System 2 in relation to one being fast and concurrent while the other is slower and sequential and laden with attention. Why is this so? Is this a constraint and design feature that we should bring to our AI design?</p>

<p><br></p>

<p><a href="http://www.incompleteideas.net/">Richard Sutton</a> gave a thought provoking talk on how reinforcement learning is the first fully implemented computational theory of intelligence. He pointed to <a href="https://apsc450computationalneuroscience.wordpress.com/marrs-three-levels-of-inquiry/">Marr’s three levels</a>  at which any information processing machine must be understood: hardware implementation, representation/algorithm, and finally the high level theory. That is: what is the goal of the computation? What logic can the strategy be carried out? AI has made great strides due to this computational theory. However, it is only one theory. We need more. I personally think that innovation and exploration in this area could lead to an exciting future in AI.</p>

<p><br></p>

<p>Evolution is a fundamental force that drives humans and the world around us. <a href="https://www.cs.ucf.edu/~kstanley/">Ken Stanely</a> reminded us that while computers dominate at solving problems, humans still rule at open-ended innovation over the millenia. The underlying properties of evolution still elude our deep understanding. Studying the core nature of this powerful phenomena is a very important area of research.</p>

<p><br></p>

<p>The last question of the evening to all the panelists was the greatest Christmas gift of all - “Where do you want AI to go?”. The diversity of the answers reflected the broad hopes shared by many that will light the way to come. I’ll paraphrase some of the ones here:</p>

<ul>
<li>Want to understand fundamental laws and principles and use them to better the human condition.</li>
<li>Understand the different varieties of intelligence.</li>
<li>Want an intelligent and superfriendly apprentice. To understand self by emulating.</li>
<li>To move beyond GPT-3 remixing to really assisting creativity for humanity.</li>
<li>Hope that AI will amplify us and our abilities.</li>
<li>Use AI to help people understand what bias they have.</li>
<li>That humans will still have something to add after AI have mastered a domain</li>
<li>To understand the brain in the most simple and beautiful way.</li>
<li>Gain a better clarity and understanding of our own values by deciding which to endow our AI with.</li>
<li>Want the costs and benefits of AI to be distributed globally and economically.</li>
</ul>


<p><br></p>

<p>Thanks again Montreal.AI for putting together such a great program and sharing it with the community. I look forward to next year.</p>

<p><br></p>

<p>Merry Christmas everyone!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure Interop With Python NLP Libraries]]></title>
    <link href="http://gigasquid.github.io/blog/2020/01/24/clojure-interop-with-python-nlp-libraries/"/>
    <updated>2020-01-24T15:34:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2020/01/24/clojure-interop-with-python-nlp-libraries</id>
    <content type="html"><![CDATA[<p><img src="http:////live.staticflickr.com/65535/49435394578_400fdf1c7f_c.jpg" alt="clojure-python" /></p>

<p>In this edition of the blog series of Clojure/Python interop with <a href="https://github.com/cnuernber/libpython-clj">libpython-clj</a>, we&rsquo;ll be taking a look at two popular Python NLP libraries: <a href="https://www.nltk.org/">NLTK</a> and <a href="https://spacy.io/">SpaCy</a>.</p>

<h2>NLTK - Natural Language Toolkit</h2>

<p>I was taking requests for doing examples of python-clojure interop libraries on twitter the other day, and by <em>far</em> NLTK was the most requested library. After looking into it, I can see why. It&rsquo;s the most popular natural language processing library in Python and you will see it everywhere there is text someone is touching.</p>

<h3>Installation</h3>

<p>To use the NLTK toolkit you will need to install it. I use <code>sudo pip3 install nltk</code>, but libpython-clj now supports virtual environments with this <a href="https://github.com/cnuernber/libpython-clj/pull/53">PR</a>, so feel free to use whatever is best for you.</p>

<h3>Features</h3>

<p>We&rsquo;ll take a quick tour of the features of NLTK following along initially with the <a href="https://www.nltk.org/book/ch01.html">nltk official book</a> and then moving onto this more data task centered <a href="https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk">tutorial</a>.</p>

<p>First, we need to require all of our things as usual:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">gigasquid.nltk</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">libpython-clj.require</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">require-python</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">libpython-clj.python</span> <span class="ss">:as</span> <span class="nv">py</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">py.</span> <span class="nv">py..</span> <span class="nv">py.-</span><span class="p">]]))</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk</span> <span class="ss">:as</span> <span class="nv">nltk</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Downloading packages</h4>

<p>There are all sorts of packages available to download from NLTK. To start out and tour the library, I would go with a small one that has basic data for the nltk book tutorial.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="nf">nltk/download</span> <span class="s">&quot;book&quot;</span><span class="p">)</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk.book</span> <span class="ss">:as</span> <span class="nv">book</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<p>There are all other sorts of downloads as well, such as <code>(nltk/download "popular")</code> for most used ones. You can also download <code>"all"</code>, but beware that it is big.</p>

<p>You can check out some of the texts it downloaded with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nf">book/texts</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">;;; prints out in repl</span>
</span><span class='line'>  <span class="c1">;; text1: Moby Dick by Herman Melville 1851</span>
</span><span class='line'>  <span class="c1">;; text2: Sense and Sensibility by Jane Austen 1811</span>
</span><span class='line'>  <span class="c1">;; text3: The Book of Genesis</span>
</span><span class='line'>  <span class="c1">;; text4: Inaugural Address Corpus</span>
</span><span class='line'>  <span class="c1">;; text5: Chat Corpus</span>
</span><span class='line'>  <span class="c1">;; text6: Monty Python and the Holy Grail</span>
</span><span class='line'>  <span class="c1">;; text7: Wall Street Journal</span>
</span><span class='line'>  <span class="c1">;; text8: Personals Corpus</span>
</span><span class='line'>  <span class="c1">;; text9: The Man Who Was Thursday by G . K . Chesterton 1908</span>
</span><span class='line'>
</span><span class='line'>  <span class="nv">book/text1</span> <span class="c1">;=&gt;  &lt;Text: Moby Dick by Herman Melville 1851&gt;</span>
</span><span class='line'>  <span class="nv">book/text2</span> <span class="c1">;=&gt;  &lt;Text: Sense and Sensibility by Jane Austen 1811&gt;</span>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>  You can do fun things like see how many tokens are in a text</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nb">count </span><span class="p">(</span><span class="nf">py.-</span> <span class="nv">book/text3</span> <span class="nv">tokens</span><span class="p">))</span>  <span class="c1">;=&gt; 44764</span>
</span></code></pre></td></tr></table></div></figure>


<p>  Or even see the lexical diversity, which is a measure of the richness of the text by looking at the unique set of word tokens against the total tokens.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="kd">defn </span><span class="nv">lexical-diversity</span> <span class="p">[</span><span class="nv">text</span><span class="p">]</span>
</span><span class='line'>    <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">tokens</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">text</span> <span class="nv">tokens</span><span class="p">)]</span>
</span><span class='line'>      <span class="p">(</span><span class="nb">/ </span><span class="p">(</span><span class="nb">-&gt; </span><span class="nv">tokens</span> <span class="nb">set </span><span class="nv">count</span><span class="p">)</span>
</span><span class='line'>         <span class="p">(</span><span class="nb">* </span><span class="mf">1.0</span> <span class="p">(</span><span class="nb">count </span><span class="nv">tokens</span><span class="p">)))))</span>
</span><span class='line'>
</span><span class='line'>  <span class="p">(</span><span class="nf">lexical-diversity</span> <span class="nv">book/text3</span><span class="p">)</span> <span class="c1">;=&gt; 0.06230453042623537</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">lexical-diversity</span> <span class="nv">book/text5</span><span class="p">)</span> <span class="c1">;=&gt; 0.13477005109975562</span>
</span></code></pre></td></tr></table></div></figure>


<p> This of course is all very interesting but I prefer to look at some more practical tasks, so we are going to look at some sentence tokenization.</p>

<h4>Sentence Tokenization</h4>

<p> Text can be broken up into individual word tokens or sentence tokens. Let&rsquo;s start off first with the token package</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk.tokenize</span> <span class="ss">:as</span> <span class="nv">tokenize</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">text</span> <span class="s">&quot;Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.</span>
</span><span class='line'><span class="s">The sky is pinkish-blue. You shouldn&#39;t eat cardboard&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>To tokenize sentences, you take the text and use <code>tokenize/sent_tokenize</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="k">def </span><span class="nv">text</span> <span class="s">&quot;Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.</span>
</span><span class='line'><span class="s">The sky is pinkish-blue. You shouldn&#39;t eat cardboard&quot;</span><span class="p">)</span>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">tokenized-sent</span> <span class="p">(</span><span class="nf">tokenize/sent_tokenize</span> <span class="nv">text</span><span class="p">))</span>
</span><span class='line'> <span class="nv">tokenized-sent</span>
</span><span class='line'> <span class="c1">;;=&gt; [&#39;Hello Mr. Smith, how are you doing today?&#39;, &#39;The weather is great, and city is awesome.&#39;, &#39;The sky is pinkish-blue.&#39;, &quot;You shouldn&#39;t eat cardboard&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Likewise, to tokenize words, you use <code>tokenize/word_tokenize</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="k">def </span><span class="nv">text</span> <span class="s">&quot;Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.</span>
</span><span class='line'><span class="s">The sky is pinkish-blue. You shouldn&#39;t eat cardboard&quot;</span><span class="p">)</span>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">tokenized-sent</span> <span class="p">(</span><span class="nf">tokenize/sent_tokenize</span> <span class="nv">text</span><span class="p">))</span>
</span><span class='line'> <span class="nv">tokenized-sent</span>
</span><span class='line'> <span class="c1">;;=&gt; [&#39;Hello Mr. Smith, how are you doing today?&#39;, &#39;The weather is great, and city is awesome.&#39;, &#39;The sky is pinkish-blue.&#39;, &quot;You shouldn&#39;t eat cardboard&quot;]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">tokenized-word</span> <span class="p">(</span><span class="nf">tokenize/word_tokenize</span> <span class="nv">text</span><span class="p">))</span>
</span><span class='line'> <span class="nv">tokenized-word</span>
</span><span class='line'>  <span class="c1">;;=&gt; [&#39;Hello&#39;, &#39;Mr.&#39;, &#39;Smith&#39;, &#39;,&#39;, &#39;how&#39;, &#39;are&#39;, &#39;you&#39;, &#39;doing&#39;, &#39;today&#39;, &#39;?&#39;, &#39;The&#39;, &#39;weather&#39;, &#39;is&#39;, &#39;great&#39;, &#39;,&#39;, &#39;and&#39;, &#39;city&#39;, &#39;is&#39;, &#39;awesome&#39;, &#39;.&#39;, &#39;The&#39;, &#39;sky&#39;, &#39;is&#39;, &#39;pinkish-blue&#39;, &#39;.&#39;, &#39;You&#39;, &#39;should&#39;, &quot;n&#39;t&quot;, &#39;eat&#39;, &#39;cardboard&#39;]</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Frequency Distribution</h4>

<p> You can also look at the frequency distribution of the words with using the probability package.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk.probability</span> <span class="ss">:as</span> <span class="nv">probability</span><span class="p">]))</span>
</span><span class='line'>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">fdist</span> <span class="p">(</span><span class="nf">probability/FreqDist</span> <span class="nv">tokenized-word</span><span class="p">))</span>
</span><span class='line'> <span class="nv">fdist</span> <span class="c1">;=&gt; &lt;FreqDist with 25 samples and 30 outcomes&gt;</span>
</span><span class='line'>
</span><span class='line'> <span class="p">(</span><span class="nf">py.</span> <span class="nv">fdist</span> <span class="nv">most_common</span><span class="p">)</span>
</span><span class='line'>  <span class="c1">;=&gt; [(&#39;is&#39;, 3), (&#39;,&#39;, 2), (&#39;The&#39;, 2), (&#39;.&#39;, 2), (&#39;Hello&#39;, 1), (&#39;Mr.&#39;, 1), (&#39;Smith&#39;, 1), (&#39;how&#39;, 1), (&#39;are&#39;, 1), (&#39;you&#39;, 1), (&#39;doing&#39;, 1), (&#39;today&#39;, 1), (&#39;?&#39;, 1), (&#39;weather&#39;, 1), (&#39;great&#39;, 1), (&#39;and&#39;, 1), (&#39;city&#39;, 1), (&#39;awesome&#39;, 1), (&#39;sky&#39;, 1), (&#39;pinkish-blue&#39;, 1), (&#39;You&#39;, 1), (&#39;should&#39;, 1), (&quot;n&#39;t&quot;, 1), (&#39;eat&#39;, 1), (&#39;cardboard&#39;, 1)]</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Stop Words</h4>

<p>Stop words are considered noise in text and there are ways to use the library to remove them using the <code>nltk.corpus</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">stop-words</span> <span class="p">(</span><span class="nb">into </span><span class="o">#</span><span class="p">{}</span> <span class="p">(</span><span class="nf">py.</span> <span class="nv">corpus/stopwords</span> <span class="nv">words</span> <span class="s">&quot;english&quot;</span><span class="p">)))</span>
</span><span class='line'> <span class="nv">stop-words</span>
</span><span class='line'>  <span class="c1">;=&gt; #{&quot;d&quot; &quot;itself&quot; &quot;more&quot; &quot;didn&#39;t&quot; &quot;ain&quot; &quot;won&quot; &quot;hers&quot;....}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now that we have a collection of the stop words, we can filter them out of our text in the normal way in Clojure.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">filtered-sent</span> <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">tokenized-sent</span>
</span><span class='line'>                         <span class="p">(</span><span class="nb">map </span><span class="nv">tokenize/word_tokenize</span><span class="p">)</span>
</span><span class='line'>                         <span class="p">(</span><span class="nb">map </span><span class="o">#</span><span class="p">(</span><span class="nb">remove </span><span class="nv">stop-words</span> <span class="nv">%</span><span class="p">))))</span>
</span><span class='line'> <span class="nv">filtered-sent</span>
</span><span class='line'> <span class="c1">;; ((&quot;Hello&quot; &quot;Mr.&quot; &quot;Smith&quot; &quot;,&quot; &quot;today&quot; &quot;?&quot;)</span>
</span><span class='line'> <span class="c1">;; (&quot;The&quot; &quot;weather&quot; &quot;great&quot; &quot;,&quot; &quot;city&quot; &quot;awesome&quot; &quot;.&quot;)</span>
</span><span class='line'> <span class="c1">;; (&quot;The&quot; &quot;sky&quot; &quot;pinkish-blue&quot; &quot;.&quot;)</span>
</span><span class='line'> <span class="c1">;; (&quot;You&quot; &quot;n&#39;t&quot; &quot;eat&quot; &quot;cardboard&quot;))</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Lexion Normalization and Lemmatization</h4>

<p>Stemming and Lemmatization allow ways for the text to be reduced to base words and normalized.
For example, the word <code>flying</code> has a stemmed word of <code>fli</code> and a lemma of <code>fly</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk.stem</span> <span class="ss">:as</span> <span class="nv">stem</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">nltk.stem.wordnet</span> <span class="ss">:as</span> <span class="nv">wordnet</span><span class="p">]))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">lem</span> <span class="p">(</span><span class="nf">wordnet/WordNetLemmatizer</span><span class="p">)</span>
</span><span class='line'>       <span class="nv">stem</span> <span class="p">(</span><span class="nf">stem/PorterStemmer</span><span class="p">)</span>
</span><span class='line'>       <span class="nv">word</span> <span class="s">&quot;flying&quot;</span><span class="p">]</span>
</span><span class='line'>   <span class="p">{</span><span class="ss">:lemmatized-word</span> <span class="p">(</span><span class="nf">py.</span> <span class="nv">lem</span> <span class="nv">lemmatize</span> <span class="nv">word</span> <span class="s">&quot;v&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="ss">:stemmed-word</span> <span class="p">(</span><span class="nf">py.</span> <span class="nv">stem</span> <span class="nv">stem</span> <span class="nv">word</span><span class="p">)})</span>
</span><span class='line'> <span class="c1">;=&gt; {:lemmatized-word &quot;fly&quot;, :stemmed-word &quot;fli&quot;}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>POS Tagging</h4>

<p>It also has support for Part-of-Speech (POS) Tagging. A quick example of that is:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">sent</span> <span class="s">&quot;Albert Einstein was born in Ulm, Germany in 1879.&quot;</span>
</span><span class='line'>       <span class="nv">tokens</span> <span class="p">(</span><span class="nf">nltk/word_tokenize</span> <span class="nv">sent</span><span class="p">)]</span>
</span><span class='line'>   <span class="p">{</span><span class="ss">:tokens</span> <span class="nv">tokens</span>
</span><span class='line'>    <span class="ss">:pos-tag</span> <span class="p">(</span><span class="nf">nltk/pos_tag</span> <span class="nv">tokens</span><span class="p">)})</span>
</span><span class='line'> <span class="c1">;; {:tokens</span>
</span><span class='line'> <span class="c1">;; [&#39;Albert&#39;, &#39;Einstein&#39;, &#39;was&#39;, &#39;born&#39;, &#39;in&#39;, &#39;Ulm&#39;, &#39;,&#39;, &#39;Germany&#39;, &#39;in&#39;, &#39;1879&#39;, &#39;.&#39;],</span>
</span><span class='line'> <span class="c1">;; :pos-tag</span>
</span><span class='line'> <span class="c1">;; [(&#39;Albert&#39;, &#39;NNP&#39;), (&#39;Einstein&#39;, &#39;NNP&#39;), (&#39;was&#39;, &#39;VBD&#39;), (&#39;born&#39;, &#39;VBN&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;Ulm&#39;, &#39;NNP&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;Germany&#39;, &#39;NNP&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;1879&#39;, &#39;CD&#39;), (&#39;.&#39;, &#39;.&#39;)]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Phew! That&rsquo;s a brief overview of what NLTK can do, now what about the other library SpaCy?</p>

<h2>SpaCy</h2>

<p><a href="https://spacy.io/usage/spacy-101#whats-spacy">SpaCy</a> is the main competitor to NLTK. It has a more opinionated library which is more object oriented than NLTK which mainly processes text. It has better performance for tokenization and POS tagging and has support for word vectors, which NLTK does not.</p>

<p>Let&rsquo;s dive in a take a look at it.</p>

<h3>Installation</h3>

<p>To install spaCy, you will need to do:</p>

<ul>
<li><code>pip3 install spacy</code></li>
<li><code>python3 -m spacy download en_core_web_sm</code> to load up the small language model</li>
</ul>


<p>We&rsquo;ll be following along this <a href="https://spacy.io/usage/spacy-101#annotat">tutorial</a></p>

<p>We will, of course, need to load up the library</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">spacy</span> <span class="ss">:as</span> <span class="nv">spacy</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<p>and its language model:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">nlp</span> <span class="p">(</span><span class="nf">spacy/load</span> <span class="s">&quot;en_core_web_sm&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Linguistic Annotations</h4>

<p>There are many linguistic annotations that are available, from POS, lemmas, and more:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nb">doc </span><span class="p">(</span><span class="nf">nlp</span> <span class="s">&quot;Apple is looking at buying U.K. startup for $1 billion&quot;</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">map </span><span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">token</span><span class="p">]</span>
</span><span class='line'>         <span class="p">[(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">text</span><span class="p">)</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">pos_</span><span class="p">)</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">dep_</span><span class="p">)])</span>
</span><span class='line'>       <span class="nv">doc</span><span class="p">))</span>
</span><span class='line'><span class="c1">;; ([&quot;Apple&quot; &quot;PROPN&quot; &quot;nsubj&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;is&quot; &quot;AUX&quot; &quot;aux&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;looking&quot; &quot;VERB&quot; &quot;ROOT&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;at&quot; &quot;ADP&quot; &quot;prep&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;buying&quot; &quot;VERB&quot; &quot;pcomp&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;U.K.&quot; &quot;PROPN&quot; &quot;compound&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;startup&quot; &quot;NOUN&quot; &quot;dobj&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;for&quot; &quot;ADP&quot; &quot;prep&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;$&quot; &quot;SYM&quot; &quot;quantmod&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;1&quot; &quot;NUM&quot; &quot;compound&quot;]</span>
</span><span class='line'><span class="c1">;;  [&quot;billion&quot; &quot;NUM&quot; &quot;pobj&quot;])</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here are some more:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nb">doc </span><span class="p">(</span><span class="nf">nlp</span> <span class="s">&quot;Apple is looking at buying U.K. startup for $1 billion&quot;</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">map </span><span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">token</span><span class="p">]</span>
</span><span class='line'>         <span class="p">{</span><span class="ss">:text</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">text</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:lemma</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">lemma_</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:pos</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">pos_</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:tag</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">tag_</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:dep</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">dep_</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:shape</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">shape_</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:alpha</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">is_alpha</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:is_stop</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">is_stop</span><span class="p">)}</span> <span class="p">)</span>
</span><span class='line'>       <span class="nv">doc</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; ({:text &quot;Apple&quot;,</span>
</span><span class='line'><span class="c1">;;   :lemma &quot;Apple&quot;,</span>
</span><span class='line'><span class="c1">;;   :pos &quot;PROPN&quot;,</span>
</span><span class='line'><span class="c1">;;   :tag &quot;NNP&quot;,</span>
</span><span class='line'><span class="c1">;;   :dep &quot;nsubj&quot;,</span>
</span><span class='line'><span class="c1">;;   :shape &quot;Xxxxx&quot;,</span>
</span><span class='line'><span class="c1">;;   :alpha true,</span>
</span><span class='line'><span class="c1">;;   :is_stop false}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;is&quot;,</span>
</span><span class='line'><span class="c1">;;   :lemma &quot;be&quot;,</span>
</span><span class='line'><span class="c1">;;   :pos &quot;AUX&quot;,</span>
</span><span class='line'><span class="c1">;;   :tag &quot;VBZ&quot;,</span>
</span><span class='line'><span class="c1">;;   :dep &quot;aux&quot;,</span>
</span><span class='line'><span class="c1">;;   :shape &quot;xx&quot;,</span>
</span><span class='line'><span class="c1">;;   :alpha true,</span>
</span><span class='line'><span class="c1">;;   :is_stop true}</span>
</span><span class='line'><span class="c1">;;  ...</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Named Entities</h3>

<p>It also handles named entities in the same fashion.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nb">doc </span><span class="p">(</span><span class="nf">nlp</span> <span class="s">&quot;Apple is looking at buying U.K. startup for $1 billion&quot;</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">map </span><span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">ent</span><span class="p">]</span>
</span><span class='line'>         <span class="p">{</span><span class="ss">:text</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">ent</span> <span class="nv">text</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:start-char</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">ent</span> <span class="nv">start_char</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:end-char</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">ent</span> <span class="nv">end_char</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:label</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">ent</span> <span class="nv">label_</span><span class="p">)}</span> <span class="p">)</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">py.-</span> <span class="nb">doc </span><span class="nv">ents</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; ({:text &quot;Apple&quot;, :start-char 0, :end-char 5, :label &quot;ORG&quot;}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;U.K.&quot;, :start-char 27, :end-char 31, :label &quot;GPE&quot;}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;$1 billion&quot;, :start-char 44, :end-char 54, :label &quot;MONEY&quot;})</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, it can handle pretty much the same things as NLTK. But let&rsquo;s take a look at what it can do that NLTK and that is with word vectors.</p>

<h4>Word Vectors</h4>

<p>In order to use word vectors, you will have to load up a medium or large size data model because the small ones don&rsquo;t ship with word vectors. You can do that at the command line with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="nv">python3</span> <span class="nv">-m</span> <span class="nv">spacy</span> <span class="nv">download</span> <span class="nv">en_core_web_md</span>
</span></code></pre></td></tr></table></div></figure>


<p>You will need to restart your repl and then load it with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">([</span><span class="nv">spacy</span> <span class="ss">:as</span> <span class="nv">spacy</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">nlp</span> <span class="p">(</span><span class="nf">spacy/load</span> <span class="s">&quot;en_core_web_md&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now you can see cool word vector stuff!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">tokens</span> <span class="p">(</span><span class="nf">nlp</span> <span class="s">&quot;dog cat banana afskfsd&quot;</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">map </span><span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">token</span><span class="p">]</span>
</span><span class='line'>         <span class="p">{</span><span class="ss">:text</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">text</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:has-vector</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">has_vector</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:vector_norm</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">vector_norm</span><span class="p">)</span>
</span><span class='line'>          <span class="ss">:is_oov</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token</span> <span class="nv">is_oov</span><span class="p">)}</span> <span class="p">)</span>
</span><span class='line'>       <span class="nv">tokens</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; ({:text &quot;dog&quot;,</span>
</span><span class='line'><span class="c1">;;   :has-vector true,</span>
</span><span class='line'><span class="c1">;;   :vector_norm 7.033673286437988,</span>
</span><span class='line'><span class="c1">;;   :is_oov false}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;cat&quot;,</span>
</span><span class='line'><span class="c1">;;   :has-vector true,</span>
</span><span class='line'><span class="c1">;;   :vector_norm 6.680818557739258,</span>
</span><span class='line'><span class="c1">;;   :is_oov false}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;banana&quot;,</span>
</span><span class='line'><span class="c1">;;   :has-vector true,</span>
</span><span class='line'><span class="c1">;;   :vector_norm 6.700014114379883,</span>
</span><span class='line'><span class="c1">;;   :is_oov false}</span>
</span><span class='line'><span class="c1">;;  {:text &quot;afskfsd&quot;, :has-vector false, :vector_norm 0.0, :is_oov true})</span>
</span></code></pre></td></tr></table></div></figure>


<p>And find similarity between different words.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">tokens</span> <span class="p">(</span><span class="nf">nlp</span> <span class="s">&quot;dog cat banana&quot;</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">for </span><span class="p">[</span><span class="nv">token1</span> <span class="nv">tokens</span>
</span><span class='line'>        <span class="nv">token2</span> <span class="nv">tokens</span><span class="p">]</span>
</span><span class='line'>    <span class="p">{</span><span class="ss">:token1</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token1</span> <span class="nv">text</span><span class="p">)</span>
</span><span class='line'>     <span class="ss">:token2</span> <span class="p">(</span><span class="nf">py.-</span> <span class="nv">token2</span> <span class="nv">text</span><span class="p">)</span>
</span><span class='line'>     <span class="ss">:similarity</span> <span class="p">(</span><span class="nf">py.</span> <span class="nv">token1</span> <span class="nv">similarity</span> <span class="nv">token2</span><span class="p">)}))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; ({:token1 &quot;dog&quot;, :token2 &quot;dog&quot;, :similarity 1.0}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;dog&quot;, :token2 &quot;cat&quot;, :similarity 0.8016854524612427}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;dog&quot;, :token2 &quot;banana&quot;, :similarity 0.2432764321565628}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;cat&quot;, :token2 &quot;dog&quot;, :similarity 0.8016854524612427}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;cat&quot;, :token2 &quot;cat&quot;, :similarity 1.0}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;cat&quot;, :token2 &quot;banana&quot;, :similarity 0.28154364228248596}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;banana&quot;, :token2 &quot;dog&quot;, :similarity 0.2432764321565628}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;banana&quot;, :token2 &quot;cat&quot;, :similarity 0.28154364228248596}</span>
</span><span class='line'><span class="c1">;;  {:token1 &quot;banana&quot;, :token2 &quot;banana&quot;, :similarity 1.0})</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Wrap up</h2>

<p>We&rsquo;ve seen a grand tour of the two most popular natural language python libraries that you can now use through Clojure interop!</p>

<p>I hope you&rsquo;ve enjoyed it and if you are interested in exploring yourself, the code examples are <a href="https://github.com/gigasquid/libpython-clj-examples">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parens for Pyplot]]></title>
    <link href="http://gigasquid.github.io/blog/2020/01/18/parens-for-pyplot/"/>
    <updated>2020-01-18T15:39:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2020/01/18/parens-for-pyplot</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/cnuernber/libpython-clj">libpython-clj</a> has opened the door for Clojure to directly interop with Python libraries. That means we can take just about any Python library and directly use it in our Clojure REPL. But what about <a href="https://matplotlib.org/">matplotlib</a>?</p>

<p>Matplotlib.pyplot is a standard fixture in most tutorials and python data science code. How do we interop with a python graphics library?</p>

<h2>How do you interop?</h2>

<p>It turns out that matplotlib has a headless mode where we can export the graphics and then display it using any method that we would normally use to display a .png file. In my case, I made a quick macro for it using the shell <code>open</code>. I&rsquo;m sure that someone out that could improve upon it, (and maybe even make it a cool utility lib), but it suits what I&rsquo;m doing so far:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="kd">ns </span><span class="nv">gigasquid.plot</span>
</span><span class='line'><span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">libpython-clj.require</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">require-python</span><span class="p">]]</span>
</span><span class='line'><span class="p">[</span><span class="nv">libpython-clj.python</span> <span class="ss">:as</span> <span class="nv">py</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">py.</span> <span class="nv">py..</span> <span class="nv">py.-</span><span class="p">]]</span>
</span><span class='line'><span class="p">[</span><span class="nv">clojure.java.shell</span> <span class="ss">:as</span> <span class="nv">sh</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;;; This uses the headless version of matplotlib to generate a graph then copy it to the JVM</span>
</span><span class='line'><span class="c1">;; where we can then print it</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;;;; have to set the headless mode before requiring pyplot</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">mplt</span> <span class="p">(</span><span class="nf">py/import-module</span> <span class="s">&quot;matplotlib&quot;</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">py.</span> <span class="nv">mplt</span> <span class="s">&quot;use&quot;</span> <span class="s">&quot;Agg&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="ss">&#39;matplotlib.pyplot</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="ss">&#39;matplotlib.backends.backend_agg</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="ss">&#39;numpy</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defmacro </span><span class="nv">with-show</span>
</span><span class='line'>  <span class="s">&quot;Takes forms with mathplotlib.pyplot to then show locally&quot;</span>
</span><span class='line'>  <span class="p">[</span><span class="o">&amp;</span> <span class="nv">body</span><span class="p">]</span>
</span><span class='line'>  <span class="o">`</span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">_#</span> <span class="p">(</span><span class="nf">matplotlib.pyplot/clf</span><span class="p">)</span>
</span><span class='line'>         <span class="nv">fig#</span> <span class="p">(</span><span class="nf">matplotlib.pyplot/figure</span><span class="p">)</span>
</span><span class='line'>         <span class="nv">agg-canvas#</span> <span class="p">(</span><span class="nf">matplotlib.backends.backend_agg/FigureCanvasAgg</span> <span class="nv">fig#</span><span class="p">)]</span>
</span><span class='line'>     <span class="o">~</span><span class="p">(</span><span class="nb">cons </span><span class="ss">&#39;do</span> <span class="nv">body</span><span class="p">)</span>
</span><span class='line'>     <span class="p">(</span><span class="nf">py.</span> <span class="nv">agg-canvas#</span> <span class="s">&quot;draw&quot;</span><span class="p">)</span>
</span><span class='line'>     <span class="p">(</span><span class="nf">matplotlib.pyplot/savefig</span> <span class="s">&quot;temp.png&quot;</span><span class="p">)</span>
</span><span class='line'>     <span class="p">(</span><span class="nf">sh/sh</span> <span class="s">&quot;open&quot;</span> <span class="s">&quot;temp.png&quot;</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Parens for Pyplot!</h2>

<p>Now that we have our wrapper let&rsquo;s take it for a spin. We&rsquo;ll be following along more or less this <a href="http://cs231n.github.io/python-numpy-tutorial/#matplotlib-plotting">tutorial for numpy plotting</a></p>

<p>For setup you will need the following installed in your python environment:</p>

<ul>
<li>numpy</li>
<li>matplotlib</li>
<li>pillow</li>
</ul>


<p>We are also going to use the latest and greatest syntax from libpython-clj so you are going to need to install the snapshot version locally until the next version goes out:</p>

<ul>
<li><code>git clone git@github.com:cnuernber/libpython-clj.git</code></li>
<li><code>cd cd libpython-clj</code></li>
<li><code>lein install</code></li>
</ul>


<p>After that is all setup we can require the libs we need in clojure.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">gigasquid.numpy-plot</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">libpython-clj.require</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">require-python</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">libpython-clj.python</span> <span class="ss">:as</span> <span class="nv">py</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">py.</span> <span class="nv">py..</span> <span class="nv">py.-</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">gigasquid.plot</span> <span class="ss">:as</span> <span class="nv">plot</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>plot</code> namespace contains the macro for <code>with-show</code> above. The <code>py.</code> and others is the new and improved syntax for interop.</p>

<h3>Simple Sin and Cos</h3>

<p>Let&rsquo;s start off with a simple sine and cosine functions. This code will create a <code>x</code> numpy vector of a range from 0 to <code>3 * pi</code> in 0.1 increments and then create <code>y</code> numpy vector of the <code>sin</code> of that and plot it</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">x</span> <span class="p">(</span><span class="nf">numpy/arange</span> <span class="mi">0</span> <span class="p">(</span><span class="nb">* </span><span class="mi">3</span> <span class="nv">numpy/pi</span><span class="p">)</span> <span class="mf">0.1</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">y</span> <span class="p">(</span><span class="nf">numpy/sin</span> <span class="nv">x</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">plot/with-show</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/plot</span> <span class="nv">x</span> <span class="nv">y</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://live.staticflickr.com/65535/49405284796_014447588d_z.jpg" alt="sin" /></p>

<p>Beautiful yes!</p>

<p>Let&rsquo;s get a bit more complicated now and and plot both the sin and cosine as well as add labels, title, and legend.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">x</span> <span class="p">(</span><span class="nf">numpy/arange</span> <span class="mi">0</span> <span class="p">(</span><span class="nb">* </span><span class="mi">3</span> <span class="nv">numpy/pi</span><span class="p">)</span> <span class="mf">0.1</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">y-sin</span> <span class="p">(</span><span class="nf">numpy/sin</span> <span class="nv">x</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">y-cos</span> <span class="p">(</span><span class="nf">numpy/cos</span> <span class="nv">x</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">plot/with-show</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/plot</span> <span class="nv">x</span> <span class="nv">y-sin</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/plot</span> <span class="nv">x</span> <span class="nv">y-cos</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/xlabel</span> <span class="s">&quot;x axis label&quot;</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/ylabel</span> <span class="s">&quot;y axis label&quot;</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/title</span> <span class="s">&quot;Sine and Cosine&quot;</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/legend</span> <span class="p">[</span><span class="s">&quot;Sine&quot;</span> <span class="s">&quot;Cosine&quot;</span><span class="p">])))</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http:////live.staticflickr.com/65535/49405284806_1d04957bce_z.jpg" alt="sin and cos" /></p>

<p>We can also add subplots. Subplots are when you divide the plots into different portions.
It is a bit stateful and involves making one subplot <em>active</em> and making changes and then making the other subplot <em>active</em>. Again not too hard to do with Clojure.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">x</span> <span class="p">(</span><span class="nf">numpy/arange</span> <span class="mi">0</span> <span class="p">(</span><span class="nb">* </span><span class="mi">3</span> <span class="nv">numpy/pi</span><span class="p">)</span> <span class="mf">0.1</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">y-sin</span> <span class="p">(</span><span class="nf">numpy/sin</span> <span class="nv">x</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">y-cos</span> <span class="p">(</span><span class="nf">numpy/cos</span> <span class="nv">x</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">plot/with-show</span>
</span><span class='line'>      <span class="c1">;;; set up a subplot gird that has a height of 2 and width of 1</span>
</span><span class='line'>      <span class="c1">;; and set the first such subplot as active</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/subplot</span> <span class="mi">2</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/plot</span> <span class="nv">x</span> <span class="nv">y-sin</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/title</span> <span class="s">&quot;Sine&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">;;; set the second subplot as active and make the second plot</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/subplot</span> <span class="mi">2</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/plot</span> <span class="nv">x</span> <span class="nv">y-cos</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/title</span> <span class="s">&quot;Cosine&quot;</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http:////live.staticflickr.com/65535/49405284836_8e49e4a6b8_z.jpg" alt="sin and cos subplots" /></p>

<h3>Plotting with Images</h3>

<p>Pyplot also has functions for working directly with images as well. Here we take a picture of my cat and create another version of it that is tinted.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">img</span> <span class="p">(</span><span class="nf">matplotlib.pyplot/imread</span> <span class="s">&quot;resources/cat.jpg&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">img-tinted</span> <span class="p">(</span><span class="nf">numpy/multiply</span> <span class="nv">img</span> <span class="p">[</span><span class="mi">1</span> <span class="mf">0.95</span> <span class="mf">0.9</span><span class="p">])]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">plot/with-show</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/subplot</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/imshow</span> <span class="nv">img</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/subplot</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">matplotlib.pyplot/imshow</span> <span class="p">(</span><span class="nf">numpy/uint8</span> <span class="nv">img-tinted</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/49404801993_ed398d5768_n.jpg" alt="cat tinted" /></p>

<h3>Pie charts</h3>

<p>Finally, we can show how to do a pie chart. I asked people in a <a href="https://twitter.com/gigasquid/status/1218358472049397761">twitter thread</a> what they wanted an example of in python interop and one of them was a pie chart. This is for you!</p>

<p>The original code for this example came from this <a href="https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_features.html">tutorial</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">labels</span> <span class="p">[</span><span class="s">&quot;Frogs&quot;</span> <span class="s">&quot;Hogs&quot;</span> <span class="s">&quot;Dogs&quot;</span> <span class="s">&quot;Logs&quot;</span><span class="p">]</span>
</span><span class='line'>        <span class="nv">sizes</span> <span class="p">[</span><span class="mi">15</span> <span class="mi">30</span> <span class="mi">45</span> <span class="mi">10</span><span class="p">]</span>
</span><span class='line'>        <span class="nv">explode</span> <span class="p">[</span><span class="mi">0</span> <span class="mf">0.1</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span> <span class="c1">; only explode the 2nd slice (Hogs)</span>
</span><span class='line'>        <span class="p">]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">plot/with-show</span>
</span><span class='line'>      <span class="p">(</span><span class="k">let </span><span class="p">[[</span><span class="nv">fig1</span> <span class="nv">ax1</span><span class="p">]</span> <span class="p">(</span><span class="nf">matplotlib.pyplot/subplots</span><span class="p">)]</span>
</span><span class='line'>        <span class="p">(</span><span class="nf">py.</span> <span class="nv">ax1</span> <span class="s">&quot;pie&quot;</span> <span class="nv">sizes</span> <span class="ss">:explode</span> <span class="nv">explode</span> <span class="ss">:labels</span> <span class="nv">labels</span> <span class="ss">:autopct</span> <span class="s">&quot;%1.1f%%&quot;</span>
</span><span class='line'>                             <span class="ss">:shadow</span> <span class="nv">true</span> <span class="ss">:startangle</span> <span class="mi">90</span><span class="p">)</span>
</span><span class='line'>        <span class="p">(</span><span class="nf">py.</span> <span class="nv">ax1</span> <span class="s">&quot;axis&quot;</span> <span class="s">&quot;equal&quot;</span><span class="p">))</span> <span class="c1">;equal aspec ration ensures that pie is drawn as circle</span>
</span><span class='line'>      <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/49404802008_7e84ceff76_z.jpg" alt="pie chart" /></p>

<h3>Onwards and Upwards!</h3>

<p>This is just the beginning. In upcoming posts, I will be showcasing examples of interop with different libraries from the python ecosystem. Part of the goal is to get people used to how to use interop but also to raise awareness of the capabilities of the python libraries out there right now since they have been historically out of our ecosystem.</p>

<p>If you have any libraries that you would like examples of, I&rsquo;m taking requests. Feel free to leave them in the comments of the blog or in the <a href="https://twitter.com/gigasquid/status/1218358472049397761">twitter thread</a>.</p>

<p>Until next time, happy interoping!</p>

<p>PS All the code examples are here <a href="https://github.com/gigasquid/libpython-clj-examples">https://github.com/gigasquid/libpython-clj-examples</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hugging Face GPT With Clojure]]></title>
    <link href="http://gigasquid.github.io/blog/2020/01/10/hugging-face-gpt-with-clojure/"/>
    <updated>2020-01-10T19:33:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2020/01/10/hugging-face-gpt-with-clojure</id>
    <content type="html"><![CDATA[<p><img src="https://live.staticflickr.com/65535/49364554561_6e4f4d0a51_w.jpg" alt="" /></p>

<p>A new age in Clojure has dawned. We now have interop access to any python library with <a href="https://github.com/cnuernber/libpython-clj">libpython-clj</a>.</p>

<p><br></p>

<p>Let me pause a minute to repeat.</p>

<p><br></p>

<p><strong> You can now interop with ANY python library. </strong></p>

<p><br></p>

<p>I know. It&rsquo;s overwhelming. It took a bit for me to come to grips with it too.</p>

<p><br></p>

<p>Let&rsquo;s take an example of something that I&rsquo;ve <em>always</em> wanted to do and have struggled with mightly finding a way to do it in Clojure:<br/>
I want to use the latest cutting edge GPT2 code out there to generate text.</p>

<p>Right now, that library is <a href="https://github.com/huggingface/transformers">Hugging Face Transformers</a>.<br/>
<br></p>

<p>Get ready. We will wrap that sweet hugging face code in Clojure parens!</p>

<h3>The setup</h3>

<p>The first thing you will need to do is to have python3 installed and the two libraries that we need:</p>

<p><br></p>

<ul>
<li>pytorch - <code>sudo pip3 install torch</code></li>
<li>hugging face transformers - <code>sudo pip3 install transformers</code></li>
</ul>


<p><br></p>

<p>Right now, some of you may not want to proceed. You might have had a bad relationship with Python in the past. It&rsquo;s ok, remember that some of us had bad relationships with Java, but still lead a happy and fulfilled life with Clojure and still can enjoy it from interop. The same is true with Python. Keep an open mind.</p>

<p><br></p>

<p>There might be some others that don&rsquo;t want to have anything to do with Python and want to keep your Clojure pure. Well, that is a valid choice. But you are missing out on what the big, vibrant, and chaotic Python Deep Learning ecosystem has to offer.</p>

<p><br></p>

<p>For those of you that are still along for the ride, let&rsquo;s dive in.</p>

<p><br></p>

<p>Your deps file should have just a single extra dependency in it:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="ss">:deps</span> <span class="p">{</span><span class="nv">org.clojure/clojure</span> <span class="p">{</span><span class="ss">:mvn/version</span> <span class="s">&quot;1.10.1&quot;</span><span class="p">}</span>
</span><span class='line'>        <span class="nv">cnuernber/libpython-clj</span> <span class="p">{</span><span class="ss">:mvn/version</span> <span class="s">&quot;1.30&quot;</span><span class="p">}}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Diving Into Interop</h3>

<p>The first thing that we need to do is require the libpython library.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">gigasquid.gpt2</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">libpython-clj.require</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">require-python</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">libpython-clj.python</span> <span class="ss">:as</span> <span class="nv">py</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<p>It has a very nice <code>require-python</code> syntax that we will use to load the python libraries so that we can use them in our Clojure code.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">(</span><span class="nf">transformers</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">require-python</span> <span class="o">&#39;</span><span class="p">(</span><span class="nf">torch</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here we are going to follow along with the OpenAI GPT-2 tutorial and translate it into interop code.
The original tutorial is <a href="https://huggingface.co/transformers/quickstart.html">here</a></p>

<p><br></p>

<p>Let&rsquo;s take the python side first:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span></span><span class="kn">import</span> <span class="nn">torch</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># Load pre-trained model tokenizer (vocabulary)</span>
</span><span class='line'><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>This is going to translate in our interop code to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">tokenizer</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">transformers/GPT2Tokenizer</span> <span class="nv">from_pretrained</span> <span class="s">&quot;gpt2&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>py/$a</code> function is used to call attributes on a Python object. We get the <code>transformers/GPTTokenizer</code> object that we have available to use and call <code>from_pretrained</code> on it with the string argument <code>"gpt2"</code></p>

<p><br></p>

<p>Next in the Python tutorial is:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span></span><span class="c1"># Encode a text inputs</span>
</span><span class='line'><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Who was Jim Henson ? Jim Henson was a&quot;</span>
</span><span class='line'><span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># Convert indexed tokens in a PyTorch tensor</span>
</span><span class='line'><span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>This is going to translate to Clojure:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">text</span> <span class="s">&quot;Who was Jim Henson ? Jim Henson was a&quot;</span><span class="p">)</span>
</span><span class='line'><span class="c1">;; encode text input</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">indexed-tokens</span>  <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">tokenizer</span> <span class="nv">encode</span> <span class="nv">text</span><span class="p">))</span>
</span><span class='line'><span class="nv">indexed-tokens</span> <span class="c1">;=&gt;[8241, 373, 5395, 367, 19069, 5633, 5395, 367, 19069, 373, 257]</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; convert indexed tokens to pytorch tensor</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">tokens-tensor</span> <span class="p">(</span><span class="nf">torch/tensor</span> <span class="p">[</span><span class="nv">indexed-tokens</span><span class="p">]))</span>
</span><span class='line'><span class="nv">tokens-tensor</span>
</span><span class='line'><span class="c1">;; ([[ 8241,   373,  5395,   367, 19069,  5633,  5395,   367, 19069,   373,</span>
</span><span class='line'><span class="c1">;;    257]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here we are again using <code>py/$a</code> to call the <code>encode</code> method on the text. However, when we are just calling a function, we can do so directly with <code>(torch/tensor [indexed-tokens])</code>. We can even directly use vectors.</p>

<p><br></p>

<p>Again, you are doing this in the REPL, so you have full power for inspection and display of the python objects. It is a great interop experience - (cider even has doc information on the python functions in the minibuffer)!</p>

<p><br></p>

<p>The next part is to load the model itself. This will take a few minutes, since it has to download a big file from s3 and load it up.</p>

<p><br></p>

<p>In Python:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span></span><span class="c1"># Load pre-trained model (weights)</span>
</span><span class='line'><span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>In Clojure:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;;; Load pre-trained model (weights)</span>
</span><span class='line'><span class="c1">;;; Note: this will take a few minutes to download everything</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">model</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">transformers/GPT2LMHeadModel</span> <span class="nv">from_pretrained</span> <span class="s">&quot;gpt2&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The next part is to run the model with the tokens and make the predictions.</p>

<p><br></p>

<p>Here the code starts to diverge a tiny bit.</p>

<p><br></p>

<p>Python:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span></span><span class="c1"># Set the model in evaluation mode to deactivate the DropOut modules</span>
</span><span class='line'><span class="c1"># This is IMPORTANT to have reproducible results during evaluation!</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># If you have a GPU, put everything on cuda</span>
</span><span class='line'><span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">tokens_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># Predict all tokens</span>
</span><span class='line'><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span class='line'>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">)</span>
</span><span class='line'>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># get the predicted next sub-word (in our case, the word &#39;man&#39;)</span>
</span><span class='line'><span class="n">predicted_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span class='line'><span class="n">predicted_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">indexed_tokens</span> <span class="o">+</span> <span class="p">[</span><span class="n">predicted_index</span><span class="p">])</span>
</span><span class='line'><span class="k">assert</span> <span class="n">predicted_text</span> <span class="o">==</span> <span class="s1">&#39;Who was Jim Henson? Jim Henson was a man&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>And Clojure</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;;; Set the model in evaluation mode to deactivate the DropOut modules</span>
</span><span class='line'><span class="c1">;;; This is IMPORTANT to have reproducible results during evaluation!</span>
</span><span class='line'><span class="p">(</span><span class="nf">py/$a</span> <span class="nv">model</span> <span class="nv">eval</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">;;; Predict all tokens</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">predictions</span> <span class="p">(</span><span class="nf">py/with</span> <span class="p">[</span><span class="nv">r</span> <span class="p">(</span><span class="nf">torch/no_grad</span><span class="p">)]</span>
</span><span class='line'>                          <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nf">model</span> <span class="nv">tokens-tensor</span><span class="p">))))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;;; get the predicted next sub-word&quot;</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">predicted-index</span> <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">last-word-predictions</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">predictions</span> <span class="nb">first </span><span class="nv">last</span><span class="p">)</span>
</span><span class='line'>                           <span class="nv">arg-max</span> <span class="p">(</span><span class="nf">torch/argmax</span> <span class="nv">last-word-predictions</span><span class="p">)]</span>
</span><span class='line'>                       <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">arg-max</span> <span class="nv">item</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="nv">predicted-index</span> <span class="c1">;=&gt;582</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">py/$a</span> <span class="nv">tokenizer</span> <span class="nv">decode</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nb">into </span><span class="p">[]</span> <span class="nv">indexed-tokens</span><span class="p">)</span>
</span><span class='line'>                            <span class="p">(</span><span class="nb">conj </span><span class="nv">predicted-index</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;=&gt; &quot;Who was Jim Henson? Jim Henson was a man&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The main differences is that we are obviously not using the python array syntax in our code to manipulate the lists. For example, instead of using <code>outputs[0]</code>, we are going to use <code>(first outputs)</code>. But, other than that, it is a pretty good match, even with the <code>py/with</code>.</p>

<p>Also note that we are not making the call to configure it with GPU. This is intentionally left out to keep things simple for people to try it out. Sometimes, GPU configuration can be a bit tricky to set up depending on your system. For this example, you definitely won&rsquo;t need it since it runs fast enough on cpu. If you do want to do something more complicated later, like fine tuning, you will need to invest some time to get it set up.</p>

<h3>Doing Longer Sequences</h3>

<p>The next example in the tutorial goes on to cover generating longer text.</p>

<p><br></p>

<p>Python</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">generated</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;The Manhattan bridge&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">generated</span><span class="p">])</span>
</span><span class='line'><span class="n">past</span> <span class="o">=</span> <span class="kc">None</span>
</span><span class='line'>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
</span><span class='line'>    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>    <span class="n">output</span><span class="p">,</span> <span class="n">past</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">)</span>
</span><span class='line'>    <span class="n">token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">generated</span> <span class="o">+=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
</span><span class='line'>    <span class="n">context</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">sequence</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="nb">print</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>And Clojure</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">tokenizer</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">transformers/GPT2Tokenizer</span> <span class="nv">from_pretrained</span> <span class="s">&quot;gpt2&quot;</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">model</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">transformers/GPT2LMHeadModel</span> <span class="nv">from_pretrained</span> <span class="s">&quot;gpt2&quot;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">generated</span> <span class="p">(</span><span class="nb">into </span><span class="p">[]</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">tokenizer</span> <span class="nv">encode</span> <span class="s">&quot;The Manhattan bridge&quot;</span><span class="p">)))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">context</span> <span class="p">(</span><span class="nf">torch/tensor</span> <span class="p">[</span><span class="nv">generated</span><span class="p">]))</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">generate-sequence-step</span> <span class="p">[{</span><span class="ss">:keys</span> <span class="p">[</span><span class="nv">generated-tokens</span> <span class="nv">context</span> <span class="nv">past</span><span class="p">]}]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">let </span><span class="p">[[</span><span class="nv">output</span> <span class="nv">past</span><span class="p">]</span> <span class="p">(</span><span class="nf">model</span> <span class="nv">context</span> <span class="ss">:past</span> <span class="nv">past</span><span class="p">)</span>
</span><span class='line'>        <span class="nv">token</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">torch/argmax</span> <span class="p">(</span><span class="nb">first </span><span class="nv">output</span><span class="p">)))</span>
</span><span class='line'>        <span class="nv">new-generated</span>  <span class="p">(</span><span class="nb">conj </span><span class="nv">generated-tokens</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">token</span> <span class="nv">tolist</span><span class="p">))]</span>
</span><span class='line'>    <span class="p">{</span><span class="ss">:generated-tokens</span> <span class="nv">new-generated</span>
</span><span class='line'>     <span class="ss">:context</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">token</span> <span class="nv">unsqueeze</span> <span class="mi">0</span><span class="p">)</span>
</span><span class='line'>     <span class="ss">:past</span> <span class="nv">past</span>
</span><span class='line'>     <span class="ss">:token</span> <span class="nv">token</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">decode-sequence</span> <span class="p">[{</span><span class="ss">:keys</span> <span class="p">[</span><span class="nv">generated-tokens</span><span class="p">]}]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">tokenizer</span> <span class="nv">decode</span> <span class="nv">generated-tokens</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">loop </span><span class="p">[</span><span class="nv">step</span> <span class="p">{</span><span class="ss">:generated-tokens</span> <span class="nv">generated</span>
</span><span class='line'>             <span class="ss">:context</span> <span class="nv">context</span>
</span><span class='line'>             <span class="ss">:past</span> <span class="nv">nil</span><span class="p">}</span>
</span><span class='line'>       <span class="nv">i</span> <span class="mi">10</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">pos? </span><span class="nv">i</span><span class="p">)</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">recur</span> <span class="p">(</span><span class="nf">generate-sequence-step</span> <span class="nv">step</span><span class="p">)</span> <span class="p">(</span><span class="nb">dec </span><span class="nv">i</span><span class="p">))</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">decode-sequence</span> <span class="nv">step</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;=&gt; &quot;The Manhattan bridge\n\nThe Manhattan bridge is a major artery for&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The great thing is once we have it embedded in our code, there is no stopping. We can create a nice function:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">generate-text</span> <span class="p">[</span><span class="nv">starting-text</span> <span class="nv">num-of-words-to-predict</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">tokens</span> <span class="p">(</span><span class="nb">into </span><span class="p">[]</span> <span class="p">(</span><span class="nf">py/$a</span> <span class="nv">tokenizer</span> <span class="nv">encode</span> <span class="nv">starting-text</span><span class="p">))</span>
</span><span class='line'>        <span class="nv">context</span> <span class="p">(</span><span class="nf">torch/tensor</span> <span class="p">[</span><span class="nv">tokens</span><span class="p">])</span>
</span><span class='line'>        <span class="nv">result</span> <span class="p">(</span><span class="nf">reduce</span>
</span><span class='line'>                <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">r</span> <span class="nv">i</span><span class="p">]</span>
</span><span class='line'>                  <span class="p">(</span><span class="nb">println </span><span class="nv">i</span><span class="p">)</span>
</span><span class='line'>                  <span class="p">(</span><span class="nf">generate-sequence-step</span> <span class="nv">r</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>                <span class="p">{</span><span class="ss">:generated-tokens</span> <span class="nv">tokens</span>
</span><span class='line'>                 <span class="ss">:context</span> <span class="nv">context</span>
</span><span class='line'>                 <span class="ss">:past</span> <span class="nv">nil</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'>                <span class="p">(</span><span class="nb">range </span><span class="nv">num-of-words-to-predict</span><span class="p">))]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">decode-sequence</span> <span class="nv">result</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>And finally we can generate some fun text!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">generate-text</span> <span class="s">&quot;Clojure is a dynamic, general purpose programming language, combining the approachability and interactive&quot;</span> <span class="mi">20</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;=&gt; &quot;Clojure is a dynamic, general purpose programming language, combining the approachability and interactive. It is a language that is easy to learn and use, and is easy to use for anyone&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Clojure is a dynamic, general purpose programming language, combining the approachability and interactive. It is a language that is easy to learn and use, and is easy to use for anyone</strong></p>

<p><br></p>

<p>So true GPT2! So true!</p>

<h3>Wrap-up</h3>

<p>libpython-clj is a really powerful tool that will allow Clojurists to better explore, leverage, and integrate Python libraries into their code.</p>

<p><br></p>

<p>I&rsquo;ve been really impressed with it so far and I encourage you to check it out.</p>

<p><br></p>

<p>There is a <a href="https://github.com/gigasquid/libpython-clj-examples">repo with the examples</a> out there if you want to check them out. There is also an example of doing MXNet MNIST classification there as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integrating Deep Learning With clojure.spec]]></title>
    <link href="http://gigasquid.github.io/blog/2019/10/11/integrating-deep-learning-with-clojure-dot-spec/"/>
    <updated>2019-10-11T13:51:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/10/11/integrating-deep-learning-with-clojure-dot-spec</id>
    <content type="html"><![CDATA[<p>clojure.spec allows you to write specifications for data and use them for validation. It also provides a generative aspect that allows for robust testing as well as an additional way to understand your data through manual inspection. The dual nature of validation and generation is a natural fit for deep learning models that consist of paired discriminator/generator models.</p>

<p><br></p>

<p><strong><strong>TLDR: In this post we show that you can leverage the dual nature of clojure.spec&rsquo;s validator/generator to incorporate a deep learning model&rsquo;s classifier/generator.</strong></strong></p>

<p><br></p>

<p>A common use of clojure.spec is at the boundaries to validate that incoming data is indeed in the expected form. Again, this is boundary is a fitting place to integrate models for the deep learning paradigm and our traditional software code.</p>

<p>Before we get into the deep learning side of things, let&rsquo;s take a quick refresher on how to use clojure.spec.</p>

<h2>quick view of clojure.spec</h2>

<p>To create a simple spec for keywords that are cat sounds, we can use <code>s/def</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/def</span> <span class="ss">::cat-sounds</span> <span class="o">#</span><span class="p">{</span><span class="ss">:meow</span> <span class="ss">:purr</span> <span class="ss">:hiss</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>To do the validation, you can use the <code>s/valid?</code> function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::cat-sounds</span> <span class="ss">:meow</span><span class="p">)</span> <span class="c1">;=&gt; true</span>
</span><span class='line'><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::cat-sounds</span> <span class="ss">:bark</span><span class="p">)</span> <span class="c1">;=&gt; false</span>
</span></code></pre></td></tr></table></div></figure>


<p>For the generation side of things, we can turn the spec into generator and sample it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">gen/sample</span> <span class="p">(</span><span class="nf">s/gen</span> <span class="ss">::cat-sounds</span><span class="p">))</span>
</span><span class='line'><span class="c1">;=&gt;(:hiss :hiss :hiss :meow :meow :purr :hiss :meow :meow :meow)</span>
</span></code></pre></td></tr></table></div></figure>


<p>There is the ability to compose specs by adding them together with <code>s/and</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/def</span> <span class="ss">::even-number</span> <span class="p">(</span><span class="nf">s/and</span> <span class="nv">int?</span> <span class="nv">even?</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">gen/sample</span> <span class="p">(</span><span class="nf">s/gen</span> <span class="ss">::even-number</span><span class="p">))</span>
</span><span class='line'><span class="c1">;=&gt; (0 0 -2 2 0 10 -4 8 6 8)</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can also control the generation by creating a custom generator using <code>s/with-gen</code>.
In the following the spec is only that the data be a general string, but using the custom generator, we can restrict the output to only be a certain set of example cat names.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/def</span> <span class="ss">::cat-name</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">s/with-gen</span>
</span><span class='line'>    <span class="nv">string?</span>
</span><span class='line'>    <span class="o">#</span><span class="p">(</span><span class="nf">s/gen</span> <span class="o">#</span><span class="p">{</span><span class="s">&quot;Suki&quot;</span> <span class="s">&quot;Bill&quot;</span> <span class="s">&quot;Patches&quot;</span> <span class="s">&quot;Sunshine&quot;</span><span class="p">})))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::cat-name</span> <span class="s">&quot;Peaches&quot;</span><span class="p">)</span> <span class="c1">;=&gt; true</span>
</span><span class='line'><span class="p">(</span><span class="nf">gen/sample</span> <span class="p">(</span><span class="nf">s/gen</span> <span class="ss">::cat-name</span><span class="p">))</span>
</span><span class='line'><span class="c1">;; (&quot;Patches&quot; &quot;Sunshine&quot; &quot;Sunshine&quot; &quot;Suki&quot; &quot;Suki&quot; &quot;Sunshine&quot;</span>
</span><span class='line'><span class="c1">;;  &quot;Suki&quot; &quot;Patches&quot; &quot;Sunshine&quot; &quot;Suki&quot;)</span>
</span></code></pre></td></tr></table></div></figure>


<p>For further information on clojure.spec, I whole-heartedly recommend the <a href="https://clojure.org/guides/spec">spec Guide</a>. But, now with a basic overview of spec, we can move on to creating specs for our Deep Learning models.</p>

<h2>Creating specs for Deep Learning Models</h2>

<p>In previous posts, we covered making <a href="https://gigasquidsoftware.com/blog/2019/08/16/simple-autoencoder/">simple autoencoders for handwritten digits</a>.</p>

<p><img src="http://live.staticflickr.com/65535/48647524478_ca35bef78f_n.jpg" alt="handwritten digits" /></p>

<p>Then, we made models that would:</p>

<ul>
<li>Take an image of a digit and give you back the string value (ex: &ldquo;2&rdquo;) - <a href="https://gigasquidsoftware.com/blog/2019/08/30/focus-on-the-discriminator/">post</a></li>
<li>Take a string number value and give you back a digit image. - <a href="https://gigasquidsoftware.com/blog/2019/09/06/focus-on-the-generator/">post</a></li>
</ul>


<p>We will use both of the models to make a spec with a custom generator.</p>

<p><br></p>

<p><em>Note: For the sake of simplicity, some of the supporting code is left out. But if you want to see the whole code, it is on <a href="(https://github.com/gigasquid/clojure-mxnet-autoencoder/blob/master/src/clojure_mxnet_autoencoder/model_specs.clj">github</a>)</em></p>

<p><br></p>

<p>With the help of the trained discriminator model, we can make a function that takes in an image and returns the number string value.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">discriminate</span> <span class="p">[</span><span class="nv">image</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/forward</span> <span class="nv">discriminator-model</span> <span class="p">{</span><span class="ss">:data</span> <span class="p">[</span><span class="nv">image</span><span class="p">]})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/outputs</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">ffirst</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">ndarray/argmax-channel</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">ndarray/-&gt;vec</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">first</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">int</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s test it out with a test-image:</p>

<p><img src="http://live.staticflickr.com/65535/48881532151_251e30840e_s.jpg" alt="test-discriminator-image" /></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">discriminate</span> <span class="nv">my-test-image</span><span class="p">)</span> <span class="c1">;=&gt; 6</span>
</span></code></pre></td></tr></table></div></figure>


<p>Likewise, with the trained generator model, we can make a function that takes a string number and returns the corresponding image.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">generate</span> <span class="p">[</span><span class="nv">label</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/forward</span> <span class="nv">generator-model</span> <span class="p">{</span><span class="ss">:data</span> <span class="p">[(</span><span class="nf">ndarray/array</span> <span class="p">[</span><span class="nv">label</span><span class="p">]</span> <span class="p">[</span><span class="nv">batch-size</span><span class="p">])]})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/outputs</span><span class="p">)</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">ffirst</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Giving it a test drive as well:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">generated-test-image</span> <span class="p">(</span><span class="nf">generate</span> <span class="mi">3</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;generated-image&quot;</span>
</span><span class='line'>             <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span>
</span><span class='line'>           <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="nv">generated-test-image</span> <span class="p">[</span><span class="nv">batch-size</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48881532451_023de68ddb_s.jpg" alt="generated-test-image" /></p>

<p>Great! Let&rsquo;s go ahead and start writing specs. First let&rsquo;s make a quick spec to describe a MNIST number - which is a single digit between 0 and 9.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/def</span> <span class="ss">::mnist-number</span> <span class="p">(</span><span class="nf">s/and</span> <span class="nv">int?</span> <span class="o">#</span><span class="p">(</span><span class="nb">&lt;= </span><span class="mi">0</span> <span class="nv">%</span> <span class="mi">9</span><span class="p">)))</span>
</span><span class='line'><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::mnist-number</span> <span class="mi">3</span><span class="p">)</span> <span class="c1">;=&gt; true</span>
</span><span class='line'><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::mnist-number</span> <span class="mi">11</span><span class="p">)</span> <span class="c1">;=&gt; false</span>
</span><span class='line'><span class="p">(</span><span class="nf">gen/sample</span> <span class="p">(</span><span class="nf">s/gen</span> <span class="ss">::mnist-number</span><span class="p">))</span>
</span><span class='line'><span class="c1">;=&gt; (0 1 0 3 5 3 7 5 0 1)</span>
</span></code></pre></td></tr></table></div></figure>


<p>We now have both parts to validate and generate and can create a spec for it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/def</span> <span class="ss">::mnist-image</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">s/with-gen</span>
</span><span class='line'>      <span class="o">#</span><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::mnist-number</span> <span class="p">(</span><span class="nf">discriminate</span> <span class="nv">%</span><span class="p">))</span>
</span><span class='line'>      <span class="o">#</span><span class="p">(</span><span class="nf">gen/fmap</span> <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">n</span><span class="p">]</span>
</span><span class='line'>                   <span class="p">(</span><span class="k">do </span><span class="p">(</span><span class="nf">ndarray/copy</span> <span class="p">(</span><span class="nf">generate</span> <span class="nv">n</span><span class="p">))))</span>
</span><span class='line'>                 <span class="p">(</span><span class="nf">s/gen</span> <span class="ss">::mnist-number</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>::mnist-number</code> spec is used for the validation after the <code>discriminate</code> model is used. On the generator side, we use the generator for the <code>::mnist-number</code> spec and feed that into the deep learning generator model to get sample images.</p>

<p>We have a test function that will help us test out this new spec, called <code>test-model-spec</code>. It will return a map with the following form:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">{</span><span class="ss">:spec</span> <span class="nv">name-of-the-spec</span>
</span><span class='line'> <span class="ss">:valid?</span> <span class="nv">whether</span> <span class="nb">or not </span><span class="nv">the</span> <span class="o">`</span><span class="nv">s/valid?</span><span class="o">`</span> <span class="nv">called</span> <span class="nv">on</span> <span class="nv">the</span> <span class="nb">test </span><span class="nv">value</span> <span class="nv">is</span> <span class="nv">true</span> <span class="nb">or </span><span class="nv">not</span>
</span><span class='line'> <span class="ss">:sample-values</span> <span class="nv">This</span> <span class="nv">calls</span> <span class="nv">the</span> <span class="nv">discriminator</span> <span class="nv">model</span> <span class="nv">on</span> <span class="nv">the</span> <span class="nv">generated</span> <span class="nv">values</span>
</span><span class='line'> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>It will also write an image of all the sample images to a file named <code>sample-spec-name</code></p>

<p>Let&rsquo;s try it on our test image:</p>

<p><img src="http://live.staticflickr.com/65535/48881532151_251e30840e_s.jpg" alt="test-discriminator-image" /></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">s/valid?</span> <span class="ss">::mnist-image</span> <span class="nv">my-test-image</span><span class="p">)</span> <span class="c1">;=&gt; true</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">test-model-spec</span> <span class="ss">::mnist-image</span> <span class="nv">my-test-image</span><span class="p">)</span>
</span><span class='line'><span class="c1">;; {:spec &quot;mnist-image&quot;</span>
</span><span class='line'><span class="c1">;;  :valid? true</span>
</span><span class='line'><span class="c1">;;  :sample-values [0 0 0 1 3 1 0 2 7 3]}</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48882235262_1e0dd7b758_q.jpg" alt="sample-mnist-image" /></p>

<p>Pretty cool!</p>

<p>Let&rsquo;s do some more specs. But first, our spec is going to be a bit repetitive, so we&rsquo;ll make a quick macro to make things easier.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defmacro </span><span class="nv">def-model-spec</span> <span class="p">[</span><span class="nv">spec-key</span> <span class="nv">spec</span> <span class="nv">discriminate-fn</span> <span class="nv">generate-fn</span><span class="p">]</span>
</span><span class='line'>    <span class="o">`</span><span class="p">(</span><span class="nf">s/def</span> <span class="o">~</span><span class="nv">spec-key</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">s/with-gen</span>
</span><span class='line'>         <span class="o">#</span><span class="p">(</span><span class="nf">s/valid?</span> <span class="o">~</span><span class="nv">spec</span> <span class="p">(</span><span class="o">~</span><span class="nv">discriminate-fn</span> <span class="nv">%</span><span class="p">))</span>
</span><span class='line'>         <span class="o">#</span><span class="p">(</span><span class="nf">gen/fmap</span> <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">n#</span><span class="p">]</span>
</span><span class='line'>                      <span class="p">(</span><span class="k">do </span><span class="p">(</span><span class="nf">ndarray/copy</span> <span class="p">(</span><span class="o">~</span><span class="nv">generate-fn</span> <span class="nv">n#</span><span class="p">))))</span>
</span><span class='line'>                    <span class="p">(</span><span class="nf">s/gen</span> <span class="o">~</span><span class="nv">spec</span><span class="p">)))))</span>
</span></code></pre></td></tr></table></div></figure>


<h3>More Specs - More Fun</h3>

<p>This time let&rsquo;s define an even mnist image spec</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="nf">def-model-spec</span> <span class="ss">::even-mnist-image</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">s/and</span> <span class="ss">::mnist-number</span> <span class="nv">even?</span><span class="p">)</span>
</span><span class='line'>    <span class="nv">discriminate</span>
</span><span class='line'>    <span class="nv">generate</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="p">(</span><span class="nf">test-model-spec</span> <span class="ss">::even-mnist-image</span> <span class="nv">my-test-image</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">;; {:spec &quot;even-mnist-image&quot;</span>
</span><span class='line'>  <span class="c1">;;  :valid? true</span>
</span><span class='line'>  <span class="c1">;;  :sample-values [0 0 2 0 8 2 2 2 0 0]}</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48882253157_02e45d3132_q.jpg" alt="sample-even-mnist-image" /></p>

<p>And Odds</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nf">def-model-spec</span> <span class="ss">::odd-mnist-image</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">s/and</span> <span class="ss">::mnist-number</span> <span class="nv">odd?</span><span class="p">)</span>
</span><span class='line'>    <span class="nv">discriminate</span>
</span><span class='line'>    <span class="nv">generate</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="p">(</span><span class="nf">test-model-spec</span> <span class="ss">::odd-mnist-image</span> <span class="nv">my-test-image</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">;; {:spec &quot;odd-mnist-image&quot;</span>
</span><span class='line'>  <span class="c1">;;  :valid? false</span>
</span><span class='line'>  <span class="c1">;;  :sample-values [5 1 5 1 3 3 3 1 1 1]}</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48881548138_c18850f806_q.jpg" alt="sample-odd-mnist-image" /></p>

<p>Finally, let&rsquo;s do Odds that are over 2!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nf">def-model-spec</span> <span class="ss">::odd-over-2-mnist-image</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">s/and</span> <span class="ss">::mnist-number</span> <span class="nv">odd?</span> <span class="o">#</span><span class="p">(</span><span class="nb">&gt; </span><span class="nv">%</span> <span class="mi">2</span><span class="p">))</span>
</span><span class='line'>    <span class="nv">discriminate</span>
</span><span class='line'>    <span class="nv">generate</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="p">(</span><span class="nf">test-model-spec</span> <span class="ss">::odd-over-2-mnist-image</span> <span class="nv">my-test-image</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">;; {:spec &quot;odd-over-2-mnist-image&quot;</span>
</span><span class='line'>  <span class="c1">;;  :valid? false</span>
</span><span class='line'>  <span class="c1">;;  :sample-values [3 3 3 5 3 5 7 7 7 3]}</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48882089776_6f55416418_q.jpg" alt="sample-odd-over-2-mnist-image" /></p>

<h2>Conclusion</h2>

<p>We have shown some of the potential of integrating deep learning models with Clojure. clojure.spec is a powerful tool and it can be leveraged in new and interesting ways for both deep learning and AI more generally.</p>

<p>I hope that more people are intrigued to experiment and take a further look into what we can do in this area.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Focus on the Generator]]></title>
    <link href="http://gigasquid.github.io/blog/2019/09/06/focus-on-the-generator/"/>
    <updated>2019-09-06T18:07:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/09/06/focus-on-the-generator</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/smigla-bobinski/19705409981/in/album-72157647756733695/" title="SIMULACRA by Karina Smigla-Bobinski"><img src="https://live.staticflickr.com/330/19705409981_4e0ae93572.jpg" width="500" height="267" alt="SIMULACRA by Karina Smigla-Bobinski"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>In this first post of this series, we took a look at a <a href="https://gigasquidsoftware.com/blog/2019/08/16/simple-autoencoder/">simple autoencoder</a>. It took and image and transformed it back to an image. Then, we <a href="https://gigasquidsoftware.com/blog/2019/08/30/focus-on-the-discriminator/">focused in on the disciminator</a> portion of the model, where we took an image and transformed it to a label. Now, we focus in on the generator portion of the model do the inverse operation: we transform a label to an image. In recap:</p>

<ul>
<li>Autoencoder: image -> image</li>
<li>Discriminator: image -> label</li>
<li>Generator: label -> image (This is what we are doing now!)</li>
</ul>


<p><img src="https://live.staticflickr.com/65535/48689260086_11fe4b089b_b.jpg" alt="generator" /></p>

<h2>Still Need Data of Course</h2>

<p>Nothing changes here. We are still using the MNIST handwritten digit set and have an input and out to our model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">def</span>
</span><span class='line'>  <span class="nv">train-data</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">mx-io/mnist-iter</span> <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                     <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                     <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>                     <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>                     <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>                     <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">def</span>
</span><span class='line'>  <span class="nv">test-data</span> <span class="p">(</span><span class="nf">mx-io/mnist-iter</span>
</span><span class='line'>             <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>              <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>              <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>              <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>              <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>              <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">input</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input&quot;</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">output</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input_&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>The Generator Model</h2>

<p>The model does change to one hot encode the label for the number. Other than that, it&rsquo;s pretty much the exact same second half of the autoencoder model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">get-symbol</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">as-&gt;</span> <span class="nv">input</span> <span class="nv">data</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/one-hot</span> <span class="s">&quot;onehot&quot;</span> <span class="p">{</span><span class="ss">:indices</span> <span class="nv">data</span> <span class="ss">:depth</span> <span class="mi">10</span><span class="p">})</span>
</span><span class='line'>    <span class="c1">;; decode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;decode1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">50</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid3&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;; decode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;decode2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">100</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid4&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;;output</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;result&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">784</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid5&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/linear-regression-output</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:label</span> <span class="nv">output</span><span class="p">})))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">data-desc</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">first</span>
</span><span class='line'>   <span class="p">(</span><span class="nf">mx-io/provide-data-desc</span> <span class="nv">train-data</span><span class="p">)))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">label-desc</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">first</span>
</span><span class='line'>   <span class="p">(</span><span class="nf">mx-io/provide-label-desc</span> <span class="nv">train-data</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>When binding the shapes to the model, we now need to specify that the input data shapes is the label instead of the image and the output of the model is going to be the image.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">def</span>
</span><span class='line'>  <span class="nv">model</span>
</span><span class='line'>  <span class="c1">;;; change data shapes to label shapes</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/module</span> <span class="p">(</span><span class="nf">get-symbol</span><span class="p">)</span> <span class="p">{</span><span class="ss">:data-names</span> <span class="p">[</span><span class="s">&quot;input&quot;</span><span class="p">]</span> <span class="ss">:label-names</span> <span class="p">[</span><span class="s">&quot;input_&quot;</span><span class="p">]})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/bind</span> <span class="p">{</span><span class="ss">:data-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">label-desc</span> <span class="ss">:name</span> <span class="s">&quot;input&quot;</span><span class="p">)]</span>
</span><span class='line'>               <span class="ss">:label-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">data-desc</span> <span class="ss">:name</span> <span class="s">&quot;input_&quot;</span><span class="p">)]})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/init-params</span> <span class="p">{</span><span class="ss">:initializer</span>  <span class="p">(</span><span class="nf">initializer/uniform</span> <span class="mi">1</span><span class="p">)})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/init-optimizer</span> <span class="p">{</span><span class="ss">:optimizer</span> <span class="p">(</span><span class="nf">optimizer/adam</span> <span class="p">{</span><span class="ss">:learning-rage</span> <span class="mf">0.001</span><span class="p">})})))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">my-metric</span> <span class="p">(</span><span class="nf">eval-metric/mse</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Training</h2>

<p>The training of the model is pretty straight forward. Just being mindful that we are using hte batch-label, (number label),  as the input and and validating with the batch-data, (image).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">train</span> <span class="p">[</span><span class="nv">num-epochs</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">doseq </span><span class="p">[</span><span class="nv">epoch-num</span> <span class="p">(</span><span class="nb">range </span><span class="mi">0</span> <span class="nv">num-epochs</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="s">&quot;starting epoch &quot;</span> <span class="nv">epoch-num</span><span class="p">)</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">mx-io/do-batches</span>
</span><span class='line'>     <span class="nv">train-data</span>
</span><span class='line'>     <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">batch</span><span class="p">]</span>
</span><span class='line'>       <span class="c1">;;; change input to be the label</span>
</span><span class='line'>       <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">model</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/forward</span> <span class="p">{</span><span class="ss">:data</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">batch</span><span class="p">)</span>
</span><span class='line'>                       <span class="ss">:label</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">)})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update-metric</span> <span class="nv">my-metric</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">))</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/backward</span><span class="p">)</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update</span><span class="p">))))</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="s">&quot;result for epoch &quot;</span> <span class="nv">epoch-num</span> <span class="s">&quot; is &quot;</span>
</span><span class='line'>             <span class="p">(</span><span class="nf">eval-metric/get-and-reset</span> <span class="nv">my-metric</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Results Before Training</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">my-test-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">test-data</span><span class="p">))</span>
</span><span class='line'>  <span class="c1">;;; change to input labels</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">test-labels</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">my-test-batch</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-labels</span><span class="p">}</span> <span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;before-training-preds&quot;</span>
</span><span class='line'>               <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span>
</span><span class='line'>               <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">preds</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span><span class='line'>
</span><span class='line'>  <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">test-labels</span> <span class="nb">first </span><span class="nv">ndarray/-&gt;vec</span> <span class="p">(</span><span class="nb">take </span><span class="mi">10</span><span class="p">))</span>
</span><span class='line'>  <span class="c1">;=&gt; (6.0 1.0 0.0 0.0 3.0 1.0 4.0 8.0 0.0 9.0)</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://live.staticflickr.com/65535/48689304281_a41bf39353.jpg" alt="before training" /></p>

<p>Not very impressive&hellip; Let&rsquo;s train</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">train</span> <span class="mi">3</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">0</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">0</span>  <span class="nv">is</span>
</span><span class='line'><span class="p">[</span><span class="nv">mse</span> <span class="mf">0.0723091</span><span class="p">]</span>
</span><span class='line'><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">1</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">1</span>  <span class="nv">is</span>  <span class="p">[</span><span class="nv">mse</span> <span class="mf">0.053891845</span><span class="p">]</span>
</span><span class='line'><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">2</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">2</span>  <span class="nv">is</span>  <span class="p">[</span><span class="nv">mse</span> <span class="mf">0.05337505</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Results After Training</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span> <span class="p">(</span><span class="k">def </span><span class="nv">my-test-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">test-data</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">test-labels</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">my-test-batch</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-labels</span><span class="p">}))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;after-training-preds&quot;</span>
</span><span class='line'>               <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span>
</span><span class='line'>               <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">preds</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">test-labels</span> <span class="nb">first </span><span class="nv">ndarray/-&gt;vec</span> <span class="p">(</span><span class="nb">take </span><span class="mi">10</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">;=&gt;   (9.0 5.0 7.0 1.0 8.0 6.0 6.0 0.0 8.0 1.0)</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://live.staticflickr.com/65535/48689328481_338416ba7c.jpg" alt="after training" /></p>

<p>Cool! The first row is indeed</p>

<p><code>(9.0 5.0 7.0 1.0 8.0 6.0 6.0 0.0 8.0 1.0)</code></p>

<h2>Save Your Model</h2>

<p>Don&rsquo;t forget to save the generator model off - we are going to use it next time.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">m/save-checkpoint</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:prefix</span> <span class="s">&quot;model/generator&quot;</span> <span class="ss">:epoch</span> <span class="mi">2</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>Happy Deep Learning until next time &hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Focus on the Discriminator]]></title>
    <link href="http://gigasquid.github.io/blog/2019/08/30/focus-on-the-discriminator/"/>
    <updated>2019-08-30T10:16:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/08/30/focus-on-the-discriminator</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/marcomagrini/698692268/in/photolist-24JYSq-hTTAJN-4gjQW9-9GRKCW-4gfNhz-x2yZ-6Nnwy1-6Lm68p-66BVjW-8hawRk-4sE2Jz-5Z6uvQ-6B4iH3-qzDvGU-aNpvLT-9UFZLh-egKvNt-bMh6PR-ceG9AL-gDqtze-96JhRW-7EWMH6-3MTfDt-9rUJ4W-dFPssj-8LLrys-aDAda3-9rUJ45-7xLAFR-prSHik-7yDFHC-7erqEc-6YJx8e-39SyR4-dkQnGi-7hy6zT-4UokrH-hkMoBr-9tBN3K-jq8Bpu-aDMSk2-pwQdmt-9tFrUD-6TzF6G-WDAsCC-8Mm4tD-8M8hyS-4yzkGK-67MPUw-crfg" title="sunflowers"><img src="https://live.staticflickr.com/1007/698692268_b31d429272.jpg" width="500" height="325" alt="sunflowers"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>In the <a href="https://gigasquidsoftware.com/blog/2019/08/16/simple-autoencoder/">last post</a>, we took a look at a simple autoencoder. The autoencoder is a deep learning model that takes in an image and, (through an encoder and decoder), works to produce the same image. In short:</p>

<ul>
<li>Autoencoder: image -> image</li>
</ul>


<p>For a discriminator, we are going to focus on only the first half on the autoencoder.</p>

<p><img src="https://live.staticflickr.com/65535/48647347383_9577b7b672_b.jpg" alt="discriminator" /></p>

<p>Why only half? We want a different transformation. We are going to want to take an image as input and then do some <em>discrimination</em> of the image and classify what type of image it is. In our case, the model is going to input an image of a handwritten digit and attempt to decide which number it is.</p>

<ul>
<li>Discriminator: image -> label</li>
</ul>


<p>As always, with deep learning. To do anything, we need data.</p>

<h3>MNIST Data</h3>

<p>Nothing changes here from the autoencoder code. We are still using the MNIST dataset for handwritten digits.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;;; Load the MNIST datasets</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">train-data</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">mx-io/mnist-iter</span>
</span><span class='line'>   <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>    <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>    <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>    <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">test-data</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">mx-io/mnist-iter</span>
</span><span class='line'>   <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>    <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>    <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>    <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The model will change since we want a different output.</p>

<h3>The Model</h3>

<p>We are still taking in the image as input, and using the same encoder layers from the autoencoder model. However, at the end, we use a fully connected layer that has 10 hidden nodes - one for each label of the digits 0-9. Then we use a softmax for the classification output.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">input</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input&quot;</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">output</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input_&quot;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">get-symbol</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">as-&gt;</span> <span class="nv">input</span> <span class="nv">data</span>
</span><span class='line'>    <span class="c1">;; encode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;encode1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">100</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;; encode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;encode2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">50</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;;; this last bit changed from autoencoder</span>
</span><span class='line'>    <span class="c1">;;output</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;result&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">10</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/softmax-output</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:label</span> <span class="nv">output</span><span class="p">})))</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the autoencoder, we were never actually using the label, but we will certainly need to use it this time. It is reflected in the model&rsquo;s bindings with the data and label shapes.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">model</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/module</span> <span class="p">(</span><span class="nf">get-symbol</span><span class="p">)</span> <span class="p">{</span><span class="ss">:data-names</span> <span class="p">[</span><span class="s">&quot;input&quot;</span><span class="p">]</span> <span class="ss">:label-names</span> <span class="p">[</span><span class="s">&quot;input_&quot;</span><span class="p">]})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/bind</span> <span class="p">{</span><span class="ss">:data-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">data-desc</span> <span class="ss">:name</span> <span class="s">&quot;input&quot;</span><span class="p">)]</span>
</span><span class='line'>                        <span class="ss">:label-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">label-desc</span> <span class="ss">:name</span> <span class="s">&quot;input_&quot;</span><span class="p">)]})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/init-params</span> <span class="p">{</span><span class="ss">:initializer</span> <span class="p">(</span><span class="nf">initializer/uniform</span> <span class="mi">1</span><span class="p">)})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/init-optimizer</span> <span class="p">{</span><span class="ss">:optimizer</span> <span class="p">(</span><span class="nf">optimizer/adam</span> <span class="p">{</span><span class="ss">:learning-rage</span> <span class="mf">0.001</span><span class="p">})})))</span>
</span></code></pre></td></tr></table></div></figure>


<p>For the evaluation metric, we are also going to use an accuracy metric vs a mean squared error (mse) metric</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">my-metric</span> <span class="p">(</span><span class="nf">eval-metric/accuracy</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>With these items in place, we are ready to train the model.</p>

<h3>Training</h3>

<p>The training from the autoencoder needs to changes to use the real label for the the forward pass and updating the metric.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">train</span> <span class="p">[</span><span class="nv">num-epochs</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">doseq </span><span class="p">[</span><span class="nv">epoch-num</span> <span class="p">(</span><span class="nb">range </span><span class="mi">0</span> <span class="nv">num-epochs</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="s">&quot;starting epoch &quot;</span> <span class="nv">epoch-num</span><span class="p">)</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">mx-io/do-batches</span>
</span><span class='line'>     <span class="nv">train-data</span>
</span><span class='line'>     <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">batch</span><span class="p">]</span>
</span><span class='line'>       <span class="c1">;;; here we make sure to use the label</span>
</span><span class='line'>       <span class="c1">;;; now for forward and update-metric</span>
</span><span class='line'>       <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">model</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/forward</span> <span class="p">{</span><span class="ss">:data</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">)</span>
</span><span class='line'>                       <span class="ss">:label</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">batch</span><span class="p">)})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update-metric</span> <span class="nv">my-metric</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">batch</span><span class="p">))</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/backward</span><span class="p">)</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update</span><span class="p">))))</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="p">{</span><span class="ss">:epoch</span> <span class="nv">epoch-num</span>
</span><span class='line'>              <span class="ss">:metric</span> <span class="p">(</span><span class="nf">eval-metric/get-and-reset</span> <span class="nv">my-metric</span><span class="p">)})))</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Let&rsquo;s Run Things</h3>

<p>It&rsquo;s always a good idea to take a look at things before you start training.</p>

<p>The first batch of the training data looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="k">def </span><span class="nv">my-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">train-data</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">images</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">my-batch</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;originals&quot;</span>
</span><span class='line'>               <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span>
</span><span class='line'>               <span class="ss">:x</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">images</span>
</span><span class='line'>                      <span class="nv">first</span>
</span><span class='line'>                      <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">]))})</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://live.staticflickr.com/65535/48648000857_fb17f0de66.jpg" alt="training-batch" /></p>

<p>Before training, if we take the first batch from the test data and predict what the labels are:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="k">def </span><span class="nv">my-test-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">test-data</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="k">def </span><span class="nv">test-images</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">my-test-batch</span><span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;test-images&quot;</span>
</span><span class='line'>               <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span>
</span><span class='line'>               <span class="ss">:x</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">test-images</span>
</span><span class='line'>                      <span class="nv">first</span>
</span><span class='line'>                      <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">]))})</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://live.staticflickr.com/65535/48647524478_ca35bef78f.jpg" alt="test-batch" /></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-images</span><span class="p">}</span> <span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">preds</span>
</span><span class='line'>       <span class="nv">first</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">ndarray/argmax-channel</span><span class="p">)</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">ndarray/-&gt;vec</span><span class="p">)</span>
</span><span class='line'>       <span class="p">(</span><span class="nb">take </span><span class="mi">10</span><span class="p">))</span>
</span><span class='line'> <span class="c1">;=&gt; (1.0 8.0 8.0 8.0 8.0 8.0 2.0 8.0 8.0 1.0)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Yeah, not even close. The real first line of the images is <code>6 1 0 0 3 1 4 8 0 9</code></p>

<p>Let&rsquo;s Train!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nf">train</span> <span class="mi">3</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; starting epoch  0</span>
</span><span class='line'><span class="c1">;; {:epoch 0, :metric [accuracy 0.83295]}</span>
</span><span class='line'><span class="c1">;; starting epoch  1</span>
</span><span class='line'><span class="c1">;; {:epoch 1, :metric [accuracy 0.9371333]}</span>
</span><span class='line'><span class="c1">;; starting epoch  2</span>
</span><span class='line'><span class="c1">;; {:epoch 2, :metric [accuracy 0.9547667]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>After the training, let&rsquo;s have another look at the predicted labels.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-images</span><span class="p">}</span> <span class="p">))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="nv">preds</span>
</span><span class='line'>       <span class="nv">first</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">ndarray/argmax-channel</span><span class="p">)</span>
</span><span class='line'>       <span class="p">(</span><span class="nf">ndarray/-&gt;vec</span><span class="p">)</span>
</span><span class='line'>       <span class="p">(</span><span class="nb">take </span><span class="mi">10</span><span class="p">))</span>
</span><span class='line'> <span class="c1">;=&gt; (6.0 1.0 0.0 0.0 3.0 1.0 4.0 8.0 0.0 9.0)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Predicted = <code>(6.0 1.0 0.0 0.0 3.0 1.0 4.0 8.0 0.0 9.0)</code></li>
<li>Actual = <code>6 1 0 0 3 1 4 8 0 9</code></li>
</ul>


<p>Rock on!</p>

<h3>Closing</h3>

<p>In this post, we focused on the first half of the autoencoder and made a discriminator model that took in an image and gave us a label.</p>

<p>Don&rsquo;t forget to save the trained model for later, we&rsquo;ll be using it.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span>  <span class="p">(</span><span class="nf">m/save-checkpoint</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:prefix</span> <span class="s">&quot;model/discriminator&quot;</span>
</span><span class='line'>                            <span class="ss">:epoch</span> <span class="mi">2</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>Until then, here is a picture of the cat in a basket to keep you going.</p>

<p><img src="https://live.staticflickr.com/65535/48647579433_ce703809fa_z.jpg" alt="Otto in basket" /></p>

<p><em>P.S. If you want to run all the code for yourself. It is <a href="https://github.com/gigasquid/clojure-mxnet-autoencoder/blob/master/src/clojure_mxnet_autoencoder/discriminator.clj">here</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Autoencoder]]></title>
    <link href="http://gigasquid.github.io/blog/2019/08/16/simple-autoencoder/"/>
    <updated>2019-08-16T16:16:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/08/16/simple-autoencoder</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/horlik/2901925672/in/photolist-5qr8pf-qkv3m8-32RwmC-dZBC2B-ja8ch-48vDg-f56TGS-oUfNKn-652ZqG-QnCrbX-y3C828-jeGkmu-dxwE9L-jKaGtZ-haQ6j3-61w8UJ-WmitYz-tLymA-dZCHC4-CGvx3R-CC3GPE-BSxzda-eu625R-vHAgnk-cR7WAE-jZiLgu-BsZwLP-fhfvPT-dN1Rf9-o8Mkby-8zDocw-5DvC7S-CEij58-oaw922-akUgeW-ayQiGU-aay1vS-2fVFske-2eoRpCe-rqwa4o-9VJPtv-opgEcq-MDfFe-9yzUaK-4is9Z9-cutXnm-f9U23-L7hpoe-3i3H-enSJKf" title="Perfect mirror"><img src="https://live.staticflickr.com/3274/2901925672_325f5faeb8.jpg" width="500" height="364" alt="Perfect mirror"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>If you look long enough into the autoencoder, it looks back at you.</em></p>

<p>The Autoencoder is a fun deep learning model to look into. Its goal is simple: given an input image, we would like to have the same output image.</p>

<p>It&rsquo;s sort of an identity function for deep learning models, but it is composed of two parts: an encoder and decoder, with the encoder translating the images to a <em>latent space representation</em> and the encoder translating that back to a regular images that we can view.</p>

<p><img src="https://camo.githubusercontent.com/1ab40362a922059fa3686914cf5cff803ba7dd43/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4c53594e57356d33544e377852583631425a686f5a412e706e67" alt="" /></p>

<p>We are going to make a simple autoencoder with Clojure MXNet for handwritten digits using the MNIST dataset.</p>

<h3>The Dataset</h3>

<p>We first load up the training data into an iterator that will allow us to cycle through all the images.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">train-data</span> <span class="p">(</span><span class="nf">mx-io/mnist-iter</span> <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                   <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                   <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>                                   <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>                                   <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>                                   <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Notice there the the input shape is 784. We are purposely flattening out our 28x28 image of a number to just be a one dimensional flat array. The reason is so that we can use a simpler model for the autoencoder.</p>

<p>We also load up the corresponding test data.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">test-data</span> <span class="p">(</span><span class="nf">mx-io/mnist-iter</span> <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                  <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                  <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>                                  <span class="ss">:batch-size</span> <span class="nv">batch-size</span>
</span><span class='line'>                                  <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>                                  <span class="ss">:shuffle</span> <span class="nv">true</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>When we are working with deep learning models we keep the training and the test data separate. When we train the model, we won&rsquo;t use the test data. That way we can evaluate it later on the unseen test data.</p>

<h3>The Model</h3>

<p>Now we need to define the layers of the model. We know we are going to have an input and an output. The input will be the array that represents the image of the digit and the output will also be an array which is reconstruction of that image.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">input</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input&quot;</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">output</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;input_&quot;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">get-symbol</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">as-&gt;</span> <span class="nv">input</span> <span class="nv">data</span>
</span><span class='line'>    <span class="c1">;; encode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;encode1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">100</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;; encode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;encode2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">50</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;; decode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;decode1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">50</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid3&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;; decode</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;decode2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">100</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid4&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">;;output</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;result&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">784</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;sigmoid5&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;sigmoid&quot;</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/linear-regression-output</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:label</span> <span class="nv">output</span><span class="p">})))</span>
</span></code></pre></td></tr></table></div></figure>


<p>From the model above we can see the input (image) being passed through simple layers of encoder to its latent representation, and then boosted back up from the decoder back into an output (image). It goes through the pleasingly symmetric transformation of:</p>

<p>784 (image) -> 100 -> 50 -> 50 -> 100 -> 784 (output)</p>

<p>We can now construct the full model with the <em>module</em> api from clojure-mxnet.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">data-desc</span> <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nf">mx-io/provide-data-desc</span> <span class="nv">train-data</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">model</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/module</span> <span class="p">(</span><span class="nf">get-symbol</span><span class="p">)</span> <span class="p">{</span><span class="ss">:data-names</span> <span class="p">[</span><span class="s">&quot;input&quot;</span><span class="p">]</span> <span class="ss">:label-names</span> <span class="p">[</span><span class="s">&quot;input_&quot;</span><span class="p">]})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/bind</span> <span class="p">{</span><span class="ss">:data-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">data-desc</span> <span class="ss">:name</span> <span class="s">&quot;input&quot;</span><span class="p">)]</span>
</span><span class='line'>                        <span class="ss">:label-shapes</span> <span class="p">[(</span><span class="nb">assoc </span><span class="nv">data-desc</span> <span class="ss">:name</span> <span class="s">&quot;input_&quot;</span><span class="p">)]})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/init-params</span> <span class="p">{</span><span class="ss">:initializer</span>  <span class="p">(</span><span class="nf">initializer/uniform</span> <span class="mi">1</span><span class="p">)})</span>
</span><span class='line'>               <span class="p">(</span><span class="nf">m/init-optimizer</span> <span class="p">{</span><span class="ss">:optimizer</span> <span class="p">(</span><span class="nf">optimizer/adam</span> <span class="p">{</span><span class="ss">:learning-rage</span> <span class="mf">0.001</span><span class="p">})})))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Notice that when we are binding the <code>data-shapes</code> and <code>label-shapes</code> we are using only the <code>data</code> from our handwritten digit dataset, (the images), and not the labels. This will ensure that as it trains it will seek to recreate the input image for the output image.</p>

<h3>Before Training</h3>

<p>Before we start our training, let&rsquo;s get a baseline of what the original images look like and what the output of the untrained model is.</p>

<p>To look at the original images we can take the first training batch of 100 images and visualize them. Since we are initially using the flattened <code>[784]</code> image representation. We need to reshape it to the 28x28 image that we can recognize.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">my-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">train-data</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">images</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">my-batch</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/shape</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">images</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;originals&quot;</span> <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span> <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">images</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span></code></pre></td></tr></table></div></figure>


<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567560737/in/dateposted-public/" title="originals"><img src="https://live.staticflickr.com/65535/48567560737_672d065ac2.jpg" width="420" height="420" alt="originals"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>We can also do the same visualization with the test batch of data images by putting them into the <code>predict-batch</code> and using our model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;;; before training</span>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">my-test-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">test-data</span><span class="p">))</span>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">test-images</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">my-test-batch</span><span class="p">))</span>
</span><span class='line'> <span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-images</span><span class="p">}</span> <span class="p">))</span>
</span><span class='line'> <span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;before-training-preds&quot;</span> <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span> <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">preds</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span></code></pre></td></tr></table></div></figure>


<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567589067/in/dateposted-public/" title="before-training-preds"><img src="https://live.staticflickr.com/65535/48567589067_e44eeda1a9.jpg" width="420" height="420" alt="before-training-preds"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>They are not anything close to recognizable as numbers.</p>

<h3>Training</h3>

<p>The next step is to train the model on the data. We set up a training function to step through all the batches of data.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">my-metric</span> <span class="p">(</span><span class="nf">eval-metric/mse</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="kd">defn </span><span class="nv">train</span> <span class="p">[</span><span class="nv">num-epochs</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">doseq </span><span class="p">[</span><span class="nv">epoch-num</span> <span class="p">(</span><span class="nb">range </span><span class="mi">0</span> <span class="nv">num-epochs</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="s">&quot;starting epoch &quot;</span> <span class="nv">epoch-num</span><span class="p">)</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">mx-io/do-batches</span>
</span><span class='line'>     <span class="nv">train-data</span>
</span><span class='line'>     <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">batch</span><span class="p">]</span>
</span><span class='line'>       <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">model</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/forward</span> <span class="p">{</span><span class="ss">:data</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">)</span> <span class="ss">:label</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">)})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update-metric</span> <span class="nv">my-metric</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">))</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/backward</span><span class="p">)</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">m/update</span><span class="p">))))</span>
</span><span class='line'>    <span class="p">(</span><span class="nb">println </span><span class="s">&quot;result for epoch &quot;</span> <span class="nv">epoch-num</span> <span class="s">&quot; is &quot;</span> <span class="p">(</span><span class="nf">eval-metric/get-and-reset</span> <span class="nv">my-metric</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>For each batch of 100 images it is doing the following:</p>

<ul>
<li>Run the forward pass of the model with both the data and label being the image</li>
<li>Update the accuracy of the model with the <code>mse</code> (mean squared error metric)</li>
<li>Do the backward computation</li>
<li>Update the model according to the optimizer and the forward/backward computation.</li>
</ul>


<p>Let&rsquo;s train it for 3 epochs.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">0</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">0</span>  <span class="nv">is</span>  <span class="p">[</span><span class="nv">mse</span> <span class="mf">0.06460866</span><span class="p">]</span>
</span><span class='line'><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">1</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">1</span>  <span class="nv">is</span>  <span class="p">[</span><span class="nv">mse</span> <span class="mf">0.033874355</span><span class="p">]</span>
</span><span class='line'><span class="nv">starting</span> <span class="nv">epoch</span>  <span class="mi">2</span>
</span><span class='line'><span class="nv">result</span> <span class="nb">for </span><span class="nv">epoch</span>  <span class="mi">2</span>  <span class="nv">is</span>  <span class="p">[</span><span class="nv">mse</span> <span class="mf">0.027255038</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<h3>After training</h3>

<p>We can check the test images again and see if they look better.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;;; after training</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">my-test-batch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">test-data</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">test-images</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">my-test-batch</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-batch</span> <span class="nv">model</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">test-images</span><span class="p">}</span> <span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">viz/im-sav</span> <span class="p">{</span><span class="ss">:title</span> <span class="s">&quot;after-training-preds&quot;</span> <span class="ss">:output-path</span> <span class="s">&quot;results/&quot;</span> <span class="ss">:x</span> <span class="p">(</span><span class="nf">ndarray/reshape</span> <span class="p">(</span><span class="nb">first </span><span class="nv">preds</span><span class="p">)</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">1</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">])})</span>
</span></code></pre></td></tr></table></div></figure>


<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/50581552@N06/48567523206/in/dateposted-public/" title="after-training-preds"><img src="https://live.staticflickr.com/65535/48567523206_d78480012f.jpg" width="420" height="420" alt="after-training-preds"></a><script async src="http://gigasquid.github.io//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>Much improved! They definitely look like numbers.</p>

<h3>Wrap up</h3>

<p>We&rsquo;ve made a simple autoencoder that can take images of digits and compress them down to a latent space representation the can later be decoded into the same image.</p>

<p>If you want to check out the full code for this example, you can find it <a href="https://github.com/gigasquid/clojure-mxnet-autoencoder">here</a>.</p>

<p>Stay tuned. We&rsquo;ll take this example and build on it in future posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet April Update]]></title>
    <link href="http://gigasquid.github.io/blog/2019/04/26/clojure-mxnet-april-update/"/>
    <updated>2019-04-26T15:51:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/04/26/clojure-mxnet-april-update</id>
    <content type="html"><![CDATA[<p>Spring is bringing some beautiful new things to the  <a href="http://mxnet.incubator.apache.org/">Clojure MXNet</a>. Here are some highlights for the month of April.</p>

<h2>Shipped</h2>

<p>We&rsquo;ve merged <a href="https://github.com/apache/incubator-mxnet/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Aclosed+clojure">10 PRs</a> over the last month. Many of them focus on core improvements to documentation and usability which is very important.</p>

<p>The MXNet project is also preparing a new release <code>1.4.1</code>, so keep on the lookout for that to hit in the near future.</p>

<h2>Clojure MXNet Made Simple Article Series</h2>

<p><a href="https://arthurcaillau.com/about/">Arthur Caillau</a> added another post to his fantastic series - <a href="https://arthurcaillau.com/mxnet-made-simple-pretrained-models/">MXNet made simple: Pretrained Models for image classification - Inception and VGG</a></p>

<h2>Cool Stuff in Development</h2>

<h3>New APIs</h3>

<p>Great progress was made on the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092678">new version of the API for the Clojure NDArray and Symbol APIs</a> by <a href="https://github.com/kedarbellare">Kedar Bellare</a>. We now have an experimental new version of the apis that are generated more directly from the C code so that we can have more control over the output.</p>

<p>For example the new version of the generated api for NDArray looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">defn</span>
</span><span class='line'> <span class="nv">activation</span>
</span><span class='line'> <span class="s">&quot;Applies an activation function element-wise to the input.</span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  The following activation functions are supported:</span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  - `relu`: Rectified Linear Unit, :math:`y = max(x, 0)`</span>
</span><span class='line'><span class="s">  - `sigmoid`: :math:`y = \\frac{1}{1 + exp(-x)}`</span>
</span><span class='line'><span class="s">  - `tanh`: Hyperbolic tangent, :math:`y = \\frac{exp(x) - exp(-x)}{exp(x) + exp(-x)}`</span>
</span><span class='line'><span class="s">  - `softrelu`: Soft ReLU, or SoftPlus, :math:`y = log(1 + exp(x))`</span>
</span><span class='line'><span class="s">  - `softsign`: :math:`y = \\frac{x}{1 + abs(x)}`</span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  Defined in src/operator/nn/activation.cc:L167</span>
</span><span class='line'><span class="s">  </span>
</span><span class='line'><span class="s">  `data`: The input array.</span>
</span><span class='line'><span class="s">  `act-type`: Activation function to be applied.</span>
</span><span class='line'><span class="s">  `out`: Output array. (optional)&quot;</span>
</span><span class='line'> <span class="p">([</span><span class="nv">data</span> <span class="nv">act-type</span><span class="p">]</span> <span class="p">(</span><span class="nf">activation</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span>, <span class="ss">:act-type</span> <span class="nv">act-type</span><span class="p">}))</span>
</span><span class='line'> <span class="p">([{</span><span class="ss">:keys</span> <span class="p">[</span><span class="nv">data</span> <span class="nv">act-type</span> <span class="nv">out</span><span class="p">]</span>, <span class="ss">:or</span> <span class="p">{</span><span class="nv">out</span> <span class="nv">nil</span><span class="p">}</span>, <span class="ss">:as</span> <span class="nv">opts</span><span class="p">}]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">util/coerce-return</span>
</span><span class='line'>   <span class="p">(</span><span class="nf">NDArrayAPI/Activation</span> <span class="nv">data</span> <span class="nv">act-type</span> <span class="p">(</span><span class="nf">util/-&gt;option</span> <span class="nv">out</span><span class="p">)))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>as opposed to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">defn</span>
</span><span class='line'> <span class="nv">activation</span>
</span><span class='line'> <span class="p">([</span><span class="o">&amp;</span> <span class="nv">nd-array-and-params</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">util/coerce-return</span>
</span><span class='line'>   <span class="p">(</span><span class="nf">NDArray/Activation</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">util/coerce-param</span>
</span><span class='line'>     <span class="nv">nd-array-and-params</span>
</span><span class='line'>     <span class="o">#</span><span class="p">{</span><span class="s">&quot;scala.collection.Seq&quot;</span><span class="p">})))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>So much nicer!!!</p>

<h3>BERT (State of the Art for NLP)</h3>

<p>We also have some really exciting examples for BERT in a <a href="https://github.com/apache/incubator-mxnet/pull/14769">PR</a> that will be merged soon. If you are not familiar with BERT, this <a href="http://jalammar.github.io/illustrated-bert/">blog post</a> is a good overview. Basically, it&rsquo;s the state of the art in NLP right now. With the help of exported models from <a href="https://github.com/dmlc/gluon-nlp">GluonNLP</a>, we can do both inference and fine tuning of BERT models in MXNet with Clojure! This is an excellent example of cross fertilization across the GluonNLP, Scala, and Clojure MXNet projects.</p>

<p>There are two examples.</p>

<p>1) BERT question and answer inference based off of a fine tuned model of the <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD Dataset</a> in GluonNLP which is then exported. It allows one to actually do some natural language question and answering like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="nv">Question</span> <span class="nv">Answer</span> <span class="nv">Data</span>
</span><span class='line'><span class="p">{</span><span class="ss">:input-answer</span>
</span><span class='line'> <span class="s">&quot;Rich Hickey is the creator of the Clojure language. Before Clojure, he developed dotLisp, a similar project based on the .NET platform, and three earlier attempts to provide interoperability between Lisp and Java: a Java foreign language interface for Common Lisp, A Foreign Object Interface for Lisp, and a Lisp-friendly interface to Java Servlets.&quot;</span>,
</span><span class='line'> <span class="ss">:input-question</span> <span class="s">&quot;Who created Clojure?&quot;</span>,
</span><span class='line'> <span class="ss">:ground-truth-answers</span> <span class="p">[</span><span class="s">&quot;rich&quot;</span> <span class="s">&quot;hickey&quot;</span><span class="p">]}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nv">Predicted</span> <span class="nv">Answer</span><span class="err">:</span>  <span class="p">[</span><span class="nv">rich</span> <span class="nv">hickey</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>2) The second example is using the exported BERT base model and then fine tuning it in Clojure to do a task with sentence pair classification to see if two sentences are equivalent or not.</p>

<p>The nice thing about this is that we were able to convert the existing <a href="https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html">tutorial in GluonNLP</a> over to a Clojure Jupyter notebook with the <code>lein-jupyter</code> plugin. I didn&rsquo;t realize that there is a nifty <code>save-as</code> command in Jupyter that can generate a markdown file, which makes for very handy documentation. Take a peek at the tutorial <a href="https://github.com/apache/incubator-mxnet/blob/d062d46f1c351dc9b70a038511b564dab5c43266/contrib/clojure-package/examples/bert/fine-tune-bert.md">here</a>. It might make its way into a blog post on its own in the next week or two.</p>

<h2>Upcoming Events</h2>

<ul>
<li><p>I&rsquo;ll be speaking about Clojure MXNet at the next <a href="https://twitter.com/scicloj">Scicloj Event</a> on May 15th at 10PM UTC. Please join us and get involved in making Clojure a great place for Data Science.</p></li>
<li><p>I&rsquo;m also really excited to attend <a href="https://iclr.cc/">ICLR</a> in a couple weeks. It is a <em>huge conference</em> that I&rsquo;m sure will melt my mind with the latest research in Deep Learning. If anyone else is planning to attend, please say hi :)</p></li>
</ul>


<h2>Get Involved</h2>

<p>As always, we welcome involvement in the true Apache tradition. If you have questions or want to say hi, head on over the the closest #mxnet room on your preferred server. We are on Clojurian&rsquo;s slack and Zulip</p>

<h2>Cat Picture of the Month</h2>

<p>To close out, let&rsquo;s take a lesson from my cats and don&rsquo;t forget the importance of naps.</p>

<p><img src="https://live.staticflickr.com/65535/47707608431_5c5d0c73f8_c.jpg"></p>

<p>Have a great rest of April!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet March Update]]></title>
    <link href="http://gigasquid.github.io/blog/2019/03/22/clojure-mxnet-march-update/"/>
    <updated>2019-03-22T10:42:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2019/03/22/clojure-mxnet-march-update</id>
    <content type="html"><![CDATA[<p>I&rsquo;m starting a monthly update for <a href="http://mxnet.incubator.apache.org/">Clojure MXNet</a>. The goal is to share the progress and exciting things that are happening in the project and our community.</p>

<p>Here&rsquo;s some highlights for the month of March.</p>

<h2>Shipped</h2>

<p>Under the shipped heading, the 1.4.0 release of MXNet has been released, along with the <a href="https://search.maven.org/search?q=clojure%20mxnet">Clojure MXNet Jars</a>. There have been improvements to the JVM memory management and an Image API addition. You can see the full list of changes <a href="https://github.com/apache/incubator-mxnet/releases/tag/1.4.0#clojure">here</a></p>

<h2>Clojure MXNet Made Simple Article Series</h2>

<p><a href="https://arthurcaillau.com/about/">Arthur Caillau</a> authored a really nice series of blog posts to help get people started with Clojure MXNet.</p>

<ul>
<li><a href="https://arthurcaillau.com/mxnet-clojure-aws/">Getting started with Clojure and MXNet on AWS</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-ndarrays-api/">MXNet made simple: Clojure NDArray API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-symbol-api/">MXNet made simple: Clojure Symbol API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-module-api/">MXNet made simple: Clojure Module API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-symbol-visualization/">MXNet made simple: Clojure Symbol Visualization API</a></li>
<li><a href="https://arthurcaillau.com/mxnet-made-simple-image-manipulation/">MXNet made simple: Image Manipulation with OpenCV and MXNet</a></li>
</ul>


<h2>Lein Template &amp; Docker file</h2>

<p><a href="https://github.com/hellonico/">Nicolas Modrzyk</a> created a Leiningen template that allows you to easily get a MXNet project started - with a notebook too! It&rsquo;s a great way to take Clojure MXNet for a spin</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># create project
</span><span class='line'>lein new clj-mxnet hello
</span><span class='line'>
</span><span class='line'># run included sample
</span><span class='line'>lein run
</span><span class='line'>
</span><span class='line'># start notebook engine
</span><span class='line'>lein notebook
</span><span class='line'>
</span><span class='line'># open notebook
</span><span class='line'>http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj
</span><span class='line'># open empty notebook with all namespaces
</span><span class='line'>http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj</span></code></pre></td></tr></table></div></figure>


<p>There also is a docker file as well</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker run -it -p 10000:10000 hellonico/mxnet
</span><span class='line'>
</span><span class='line'>After starting the container, you can open the same notebooks as above:
</span><span class='line'>
</span><span class='line'># open notebook
</span><span class='line'>http://0.0.0.0:10000/worksheet.html?filename=notes/practice.clj
</span><span class='line'># open empty notebook with all namespaces
</span><span class='line'>http://0.0.0.0:10000/worksheet.html?filename=notes/empty.clj</span></code></pre></td></tr></table></div></figure>


<h2>Cool Stuff in Development</h2>

<p>There are a few really interesting things cooking for the future.</p>

<p>One is a <a href="https://github.com/apache/incubator-mxnet/pull/14372">PR for memory fixes</a> from the Scala team that is getting really close to merging. This will be a solution to some the the memory problems that were encountered by early adopters of the Module API.</p>

<p>Another, is the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092678">new version of the API for the Clojure NDArray and Symbol APIs</a> that is being spearheaded by Kedar Bellare</p>

<p>Finally, work is being started to create a <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103089990">Gluon API for the Clojure package</a> which is quite exciting.</p>

<h2>Get Involved</h2>

<p>As always, we welcome involvement in the true Apache tradition. If you have questions or want to say hi, head on over the the closest #mxnet room on your preferred server. We are on Clojurian&rsquo;s slack and Zulip.</p>

<h2>Cat Picture of the Month</h2>

<p>There is no better way to close out an update than a cat picture, so here is a picture of my family cat watching birds at the window.</p>

<p><img src="https://farm8.staticflickr.com/7862/46718997174_13bf6e88ea_z.jpg"></p>

<p>Have a great rest of March!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Object Detection With Clojure MXNet]]></title>
    <link href="http://gigasquid.github.io/blog/2019/01/19/object-detection-with-clojure-mxnet/"/>
    <updated>2019-01-19T13:34:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2019/01/19/object-detection-with-clojure-mxnet</id>
    <content type="html"><![CDATA[<p><img src="https://c1.staticflickr.com/8/7837/32928474208_4960caafb3.jpg" alt="" /></p>

<p>Object detection just landed in MXNet thanks to the work of contributors <a href="https://github.com/kedarbellare">Kedar Bellare</a> and <a href="https://github.com/hellonico/">Nicolas Modrzyk</a>. Kedar ported over the <code>infer</code> package to Clojure, making inference and prediction much easier for users and Nicolas integrated in his <a href="https://github.com/hellonico/origami">Origami</a> OpenCV library into the the examples to make the visualizations happen.</p>

<p>We&rsquo;ll walk through the main steps to use the <code>infer</code> object detection which include creating the detector with a model and then loading the image and running the inference on it.</p>

<h3>Creating the Detector</h3>

<p>To create the detector you need to define a couple of things:</p>

<ul>
<li>How big is your image?</li>
<li>What model are you going to be using for object detection?</li>
</ul>


<p>In the code below, we are going to be giving it an color image of size 512 x 512.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">create-detector</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">descriptors</span> <span class="p">[{</span><span class="ss">:name</span> <span class="s">&quot;data&quot;</span>
</span><span class='line'>                      <span class="ss">:shape</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">3</span> <span class="mi">512</span> <span class="mi">512</span><span class="p">]</span>
</span><span class='line'>                      <span class="ss">:layout</span> <span class="nv">layout/NCHW</span>
</span><span class='line'>                      <span class="ss">:dtype</span> <span class="nv">dtype/FLOAT32</span><span class="p">}]</span>
</span><span class='line'>        <span class="nv">factory</span> <span class="p">(</span><span class="nf">infer/model-factory</span> <span class="nv">model-path-prefix</span> <span class="nv">descriptors</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">infer/create-object-detector</span> <span class="nv">factory</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The shape is going to be <code>[1 3 512 512]</code>.

<ul>
<li>The <code>1</code> is for the batch size which in our case is a single image.</li>
<li>The <code>3</code> is for the channels in the image which for a RGB image is <code>3</code></li>
<li>The <code>512</code> is for the image height and width.</li>
</ul>
</li>
<li>The <code>layout</code> specifies that the shape given is in terms of <code>NCHW</code> which is batch size, channel size, height, and width.</li>
<li>The <code>dtype</code> is the image data type which will be the standard <code>FLOAT32</code></li>
<li>The <code>model-path-prefix</code> points to the place where the trained model we are using for object detection lives.</li>
</ul>


<p>The model we are going to use is the <a href="https://arxiv.org/abs/1512.02325">Single Shot Multiple Box Object Detector (SSD)</a>. You can download the model yourself using this <a href="https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/examples/infer/objectdetector/scripts/get_ssd_data.sh">script</a>.</p>

<h3>How to Load an Image and Run the Detector</h3>

<p>Now that we have a model and a detector, we can load an image up and run the object detection.</p>

<p>To load the image use <code>load-image</code> which will load the image from the path.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">infer/load-image-from-file</span> <span class="nv">input-image</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then run the detection using <code>infer/detect-objects</code> which will give you the top five predictions by default.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">infer/detect-objects</span> <span class="nv">detector</span> <span class="nv">image</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>It will give an output something like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">[[{</span><span class="ss">:class</span> <span class="s">&quot;person&quot;</span>,
</span><span class='line'>   <span class="ss">:prob</span> <span class="mf">0.9657765</span>,
</span><span class='line'>   <span class="ss">:x-min</span> <span class="mf">0.021868259</span>,
</span><span class='line'>   <span class="ss">:y-min</span> <span class="mf">0.049295247</span>,
</span><span class='line'>   <span class="ss">:x-max</span> <span class="mf">0.9975169</span>,
</span><span class='line'>   <span class="ss">:y-max</span> <span class="mf">0.9734151</span><span class="p">}</span>
</span><span class='line'>  <span class="p">{</span><span class="ss">:class</span> <span class="s">&quot;dog&quot;</span>,
</span><span class='line'>   <span class="ss">:prob</span> <span class="mf">0.17513266</span>,
</span><span class='line'>   <span class="ss">:x-min</span> <span class="mf">0.16772352</span>,
</span><span class='line'>   <span class="ss">:y-min</span> <span class="mf">0.45792937</span>,
</span><span class='line'>   <span class="ss">:x-max</span> <span class="mf">0.55409217</span>,
</span><span class='line'>   <span class="ss">:y-max</span> <span class="mf">0.72507095</span><span class="p">}</span>
</span><span class='line'>   <span class="nv">...</span>
</span><span class='line'><span class="p">]]</span>
</span></code></pre></td></tr></table></div></figure>


<p>which you can then use to draw bounding boxes on the image.</p>

<h3>Try Running the Example</h3>

<p><img src="https://c1.staticflickr.com/8/7804/31862638207_61be3a6e3c_b.jpg" alt="" /></p>

<p>One of the best ways to explore using it is with the <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package/examples/infer/objectdetector">object detection example</a> in the MXNet repo. It will be coming out officially in the <code>1.5.0</code> release, but you can get an early peek at it by building the project and running the example with the nightly snapshot.</p>

<p>You can do this by cloning the <a href="https://github.com/apache/incubator-mxnet">MXNet Repo</a> and changing directory to <code>contrib/clojure-package</code>.</p>

<p>Next, edit the <code>project.clj</code> to look like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defproject </span><span class="nv">org.apache.mxnet.contrib.clojure/clojure-mxnet</span> <span class="s">&quot;1.5.0-SNAPSHOT&quot;</span>
</span><span class='line'>  <span class="ss">:description</span> <span class="s">&quot;Clojure package for MXNet&quot;</span>
</span><span class='line'>  <span class="ss">:url</span> <span class="s">&quot;https://github.com/apache/incubator-mxnet&quot;</span>
</span><span class='line'>  <span class="ss">:license</span> <span class="p">{</span><span class="ss">:name</span> <span class="s">&quot;Apache License&quot;</span>
</span><span class='line'>            <span class="ss">:url</span> <span class="s">&quot;http://www.apache.org/licenses/LICENSE-2.0&quot;</span><span class="p">}</span>
</span><span class='line'>  <span class="ss">:dependencies</span> <span class="p">[[</span><span class="nv">org.clojure/clojure</span> <span class="s">&quot;1.9.0&quot;</span><span class="p">]</span>
</span><span class='line'>                 <span class="p">[</span><span class="nv">t6/from-scala</span> <span class="s">&quot;0.3.0&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>                 <span class="c1">;; To use with nightly snapshot</span>
</span><span class='line'>                 <span class="c1">;[org.apache.mxnet/mxnet-full_2.11-osx-x86_64-cpu &quot;&lt;insert-snapshot-version&gt;&quot;]</span>
</span><span class='line'>                 <span class="c1">;[org.apache.mxnet/mxnet-full_2.11-linux-x86_64-cpu &quot;&lt;insert-snapshot-version&gt;&quot;]</span>
</span><span class='line'>                 <span class="c1">;[org.apache.mxnet/mxnet-full_2.11-linux-x86_64-gpu &quot;&lt;insert-snapshot-version&quot;]</span>
</span><span class='line'>
</span><span class='line'>                 <span class="p">[</span><span class="nv">org.apache.mxnet/mxnet-full_2.11-osx-x86_64-cpu</span> <span class="s">&quot;1.5.0-SNAPSHOT&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>                 <span class="c1">;;; CI</span>
</span><span class='line'>                 <span class="o">#</span><span class="nv">_</span><span class="p">[</span><span class="nv">org.apache.mxnet/mxnet-full_2.11</span> <span class="s">&quot;INTERNAL&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>                 <span class="p">[</span><span class="nv">org.clojure/tools.logging</span> <span class="s">&quot;0.4.0&quot;</span><span class="p">]</span>
</span><span class='line'>                 <span class="p">[</span><span class="nv">org.apache.logging.log4j/log4j-core</span> <span class="s">&quot;2.8.1&quot;</span><span class="p">]</span>
</span><span class='line'>                 <span class="p">[</span><span class="nv">org.apache.logging.log4j/log4j-api</span> <span class="s">&quot;2.8.1&quot;</span><span class="p">]</span>
</span><span class='line'>                 <span class="p">[</span><span class="nv">org.slf4j/slf4j-log4j12</span> <span class="s">&quot;1.7.25&quot;</span> <span class="ss">:exclusions</span> <span class="p">[</span><span class="nv">org.slf4j/slf4j-api</span><span class="p">]]]</span>
</span><span class='line'>  <span class="ss">:pedantic?</span> <span class="ss">:skip</span>
</span><span class='line'>  <span class="ss">:plugins</span> <span class="p">[[</span><span class="nv">lein-codox</span> <span class="s">&quot;0.10.3&quot;</span> <span class="ss">:exclusions</span> <span class="p">[</span><span class="nv">org.clojure/clojure</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">lein-cloverage</span> <span class="s">&quot;1.0.10&quot;</span> <span class="ss">:exclusions</span> <span class="p">[</span><span class="nv">org.clojure/clojure</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">lein-cljfmt</span> <span class="s">&quot;0.5.7&quot;</span><span class="p">]]</span>
</span><span class='line'>  <span class="ss">:codox</span> <span class="p">{</span><span class="ss">:namespaces</span> <span class="p">[</span><span class="o">#</span><span class="s">&quot;^org\.apache\.clojure-mxnet\.(?!gen).*&quot;</span><span class="p">]}</span>
</span><span class='line'>  <span class="ss">:aot</span> <span class="p">[</span><span class="nv">dev.generator</span><span class="p">]</span>
</span><span class='line'>  <span class="ss">:repositories</span> <span class="p">[[</span><span class="s">&quot;staging&quot;</span> <span class="p">{</span><span class="ss">:url</span> <span class="s">&quot;https://repository.apache.org/content/repositories/staging&quot;</span>                  <span class="ss">:snapshots</span> <span class="nv">true</span>
</span><span class='line'>                             <span class="ss">:update</span> <span class="ss">:always</span><span class="p">}]</span>
</span><span class='line'>                 <span class="p">[</span><span class="s">&quot;snapshots&quot;</span> <span class="p">{</span><span class="ss">:url</span> <span class="s">&quot;https://repository.apache.org/content/repositories/snapshots&quot;</span>               <span class="ss">:snapshots</span> <span class="nv">true</span>
</span><span class='line'>                              <span class="ss">:update</span> <span class="ss">:always</span><span class="p">}]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you are running on linux, you should change the <code>mxnet-full_2.11-osx-x86_64-cpu</code> to <code>mxnet-full_2.11-linux-x86_64-cpu</code>.</p>

<p>Next, go ahead and do <code>lein test</code> to make sure that everything builds ok. If you run into any trouble please refer to <a href="https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/README.md">README</a> for any missing dependencies.</p>

<p>After that do a <code>lein install</code> to install the <code>clojure-mxnet</code> jar to your local maven. Now you are ready to <code>cd examples/infer/object-detection</code> to try it out. Refer to the README for more details.</p>

<p>If you run into any problems getting started, feel free to reach out in the Clojurian #mxnet slack room or open an issue at the MXNet project. We are a friendly group and happy to help out.</p>

<p>Thanks again to the community for the contributions to make this possible. It&rsquo;s great seeing new things coming to life.</p>

<p>Happy Object Detecting!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to GAN a Flan]]></title>
    <link href="http://gigasquid.github.io/blog/2018/12/18/how-to-gan-a-flan/"/>
    <updated>2018-12-18T16:34:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2018/12/18/how-to-gan-a-flan</id>
    <content type="html"><![CDATA[<p>It&rsquo;s holiday time and that means parties and getting together with friends. Bringing a baked good or dessert to a gathering is a time honored tradition. But what if this year, you could take it to the next level? Everyone brings actual food. But with the help of Deep Learning, you can bring something completely different -  you can bring the <em>image</em> of baked good! I&rsquo;m not talking about just any old image that someone captured with a camera or created with a pen and paper. I&rsquo;m talking about the computer itself <strong>creating</strong>. This image would be never before seen, totally unique, and crafted by the creative process of the machine.</p>

<p>That is exactly what we are going to do. We are going to create a <em>flan</em></p>

<p><img src="https://c1.staticflickr.com/5/4065/4339500429_aa9c55f246_n.jpg" alt="Photo by Lucia Sanchez on Flickr" /></p>

<p>If you&rsquo;ve never had a flan before, it&rsquo;s a yummy dessert made of a baked custard with caramel sauce on it.</p>

<p>&ldquo;Why a flan?&rdquo;, you may ask. There are quite a few reasons:</p>

<ul>
<li>It&rsquo;s tasty in real life.</li>
<li>Flan rhymes with GAN, <em>(unless you pronounce it &ldquo;Gaaahn&rdquo;)</em>.</li>
<li>Why not?</li>
</ul>


<p>Onto the recipe. How are we actually going to make this work? We need some ingredients:</p>

<ul>
<li><a href="https://clojure.org/">Clojure</a> - the most advanced programming language to create generative desserts.</li>
<li><a href="https://mxnet.apache.org">Apache MXNet</a> - a flexible and efficient deep learning library that has a Clojure package.</li>
<li>1000-5000 pictures of flans - for Deep Learning you need data!</li>
</ul>


<h2>Gather Flan Pictures</h2>

<p>The first thing you want to do is gather your 1000 or more images with a <a href="https://github.com/montoyamoraga/scrapers">scraper</a>. The scraper will crawl google, bing, or instagram and download pictures of <em>mostly</em> flans to your computer. You may have to eyeball and remove any clearly wrong ones from your stash.</p>

<p>Next, you need to gather all these images in a directory and run a tool called <a href="https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py">im2rec.py</a> on them to turn them into an <a href="https://mxnet.incubator.apache.org/tutorials/basic/data.html#loading-data-using-image-iterators">image record iterator</a> for use with MXNet. This will produce an optimized format that will allow our deep learning program to efficiently cycle through them.</p>

<p>Run:</p>

<pre><code>python3 im2rec.py --resize 28 root flan
</code></pre>

<p>to produce a <code>flan.rec</code> file with images resized to 28x28 that we can use next.</p>

<h2>Load Flan Pictures into MXNet</h2>

<p>The next step is to import the image record iterator into the MXNet with the <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package">Clojure API</a>. We can do this with the <code>io</code> namespace.</p>

<p>Add this to your require:</p>

<pre><code>[org.apache.clojure-mxnet.io :as mx-io]
</code></pre>

<p>Now, we can load our images:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">flan-iter</span> <span class="p">(</span><span class="nf">mx-io/image-record-iter</span> <span class="p">{</span><span class="ss">:path-imgrec</span> <span class="s">&quot;flan.rec&quot;</span>
</span><span class='line'>                                         <span class="ss">:data-shape</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">28</span> <span class="mi">28</span><span class="p">]</span>
</span><span class='line'>                                         <span class="ss">:batch-size</span> <span class="nv">batch-size</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, that we have the images, we need to create our <code>model</code>. This is what is actually going to do the learning and creating of images.</p>

<h2>Creating a GAN model.</h2>

<p>GAN stands for <em>Generative Adversarial Network</em>. This is a incredibly cool deep learning technique that has two different models pitted against each, yet both learning and getting better at the same time. The two models are a generator and a discriminator. The generator model creates a new image from a random noise vector. The discriminator then tries to tell whether the image is a real image or a fake image. We need to create both of these models for our network.</p>

<p>First, the discriminator model. We are going to use the <code>symbol</code> namespace for the clojure package:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">discriminator</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">as-&gt;</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;data&quot;</span><span class="p">)</span> <span class="nv">data</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/convolution</span> <span class="s">&quot;d1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span>
</span><span class='line'>                           <span class="ss">:kernel</span> <span class="p">[</span><span class="mi">4</span> <span class="mi">4</span><span class="p">]</span>
</span><span class='line'>                           <span class="ss">:pad</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">3</span><span class="p">]</span>
</span><span class='line'>                           <span class="ss">:stride</span> <span class="p">[</span><span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
</span><span class='line'>                           <span class="ss">:num-filter</span> <span class="nv">ndf</span>
</span><span class='line'>                           <span class="ss">:no-bias</span> <span class="nv">true</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/batch-norm</span> <span class="s">&quot;dbn1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:fix-gamma</span> <span class="nv">true</span> <span class="ss">:eps</span> <span class="nv">eps</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/leaky-re-lu</span> <span class="s">&quot;dact1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;leaky&quot;</span> <span class="ss">:slope</span> <span class="mf">0.2</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>  <span class="nv">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>There is a variable for the <code>data</code> coming in, (which is the picture of the flan), it then flows through the other layers which consist of convolutions, normalization, and activation layers. The last three layers actually repeat another two times before ending in the output, which tells whether it thinks the image was a fake or not.</p>

<p>The generator model looks similar:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">defn </span><span class="nv">generator</span> <span class="p">[]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">as-&gt;</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;rand&quot;</span><span class="p">)</span> <span class="nv">data</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/deconvolution</span> <span class="s">&quot;g1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span>
</span><span class='line'>                             <span class="ss">:kernel</span> <span class="p">[</span><span class="mi">4</span> <span class="mi">4</span><span class="p">]</span>
</span><span class='line'>                             <span class="ss">:pad</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
</span><span class='line'>                             <span class="ss">:stride</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">1</span><span class="p">]</span>
</span><span class='line'>                             <span class="ss">:num-filter</span>
</span><span class='line'>                             <span class="p">(</span><span class="nb">* </span><span class="mi">4</span> <span class="nv">ndf</span><span class="p">)</span> <span class="ss">:no-bias</span> <span class="nv">true</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/batch-norm</span> <span class="s">&quot;gbn1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:fix-gamma</span> <span class="nv">true</span> <span class="ss">:eps</span> <span class="nv">eps</span><span class="p">})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;gact1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;relu&quot;</span><span class="p">})</span>
</span><span class='line'>  
</span><span class='line'>  <span class="nv">...</span>
</span><span class='line'>  
</span></code></pre></td></tr></table></div></figure>


<p>There is a variable for the <code>data</code> coming in, but this time it is a random noise vector. Another interesting point that is is using a <code>deconvolution</code> layer instead of a <code>convolution</code> layer. The generator is basically the inverse of the discriminator. It starts with a random noise vector, but that is translated up through the layers until it is expanded to a image output.</p>

<p>Next, we iterate through all of our training images in our <code>flan-iter</code> with <code>reduce-batches</code>. Here is just an excerpt where we get a random noise vector and have the generator run the data through and produce the output image:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">mx-io/reduce-batches</span>
</span><span class='line'>       <span class="nv">flan-iter</span>
</span><span class='line'>       <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">n</span> <span class="nv">batch</span><span class="p">]</span>
</span><span class='line'>         <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">rbatch</span> <span class="p">(</span><span class="nf">mx-io/next</span> <span class="nv">rand-noise-iter</span><span class="p">)</span>
</span><span class='line'>               <span class="nv">dbatch</span> <span class="p">(</span><span class="nf">mapv</span> <span class="nv">normalize-rgb-ndarray</span> <span class="p">(</span><span class="nf">mx-io/batch-data</span> <span class="nv">batch</span><span class="p">))</span>
</span><span class='line'>               <span class="nv">out-g</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">mod-g</span>
</span><span class='line'>                         <span class="p">(</span><span class="nf">m/forward</span> <span class="nv">rbatch</span><span class="p">)</span>
</span><span class='line'>                         <span class="p">(</span><span class="nf">m/outputs</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>The whole code is <a href="https://github.com/gigasquid/mxnet-gan-flan">here</a> for reference, but let&rsquo;s skip forward and run it and see what happens.</p>

<p><img src="http://gigasquid.github.io/images/gout-96-0.jpg" alt="" /></p>

<p>FLANS!! Well, they could be flans if you squint a bit.</p>

<p>Now that we have them kinda working for a small image size 28x28, let&rsquo;s biggerize it.</p>

<h2>Turn on the Oven and Bake</h2>

<p>Turning up the size to 128x128 requires some alterations in the layers&#8217; parameters to make sure that it processes and generates the correct size, but other than that we are good to go.</p>

<p>Here comes the fun part, watching it train and learn:</p>

<h3>Epoch 0</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-0-0.jpg" alt="" /></p>

<p>In the beginning there was nothing but random noise.</p>

<h3>Epoch 10</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-10-0.jpg" alt="" /></p>

<p>It&rsquo;s beginning to learn colors! Red, yellow, brown seem to be important to flans.</p>

<h3>Epoch 23</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-23-0.jpg" alt="" /></p>

<p>It&rsquo;s learning shapes! It has learned that flans seem to be blob shaped.</p>

<h3>Epoch 33</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-33-0.jpg" alt="" /></p>

<p>It is moving into its surreal phase. Salvidor Dali would be proud of these flans.</p>

<h3>Epoch 45</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-45.jpg" alt="" /></p>

<p>Things take a weird turn. Does that flan have eyes?</p>

<h3>Epoch 68</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-128-68-0.jpg" alt="" /></p>

<p>Even worse. Are those demonic flans? Should we even continue down this path?</p>

<p>Answer: Yes - <strong>the training must go on..</strong></p>

<h3>Epoch 161</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-161-0.jpg" alt="" /></p>

<p>Big moment here. It looks like something that could possibly be edible.</p>

<h3>Epoch 170</h3>

<p><img src="http://gigasquid.github.io/images/flan-random-170-0.jpg" alt="" /></p>

<p>Ick! Green Flans! No one is going to want that.</p>

<h3>Epoch 195</h3>

<p><img src="http://gigasquid.github.io/images/explore-195.jpg" alt="" /></p>

<p>We&rsquo;ve achieved maximum flan, (for the time being).</p>

<h2>Explore</h2>

<p>If you are interested in playing around with the pretrained model, you can check it out <a href="https://github.com/gigasquid/mxnet-gan-flan/blob/master/src/mxnet_gan_flan/gan.clj#L355">here with the pretrained function</a>.
It will load up the trained model and generate flans for you to explore and bring to your dinner parties.</p>

<p>Wrapping up, training GANs is a <em>lot</em> of fun. With MXNet, you can bring the fun with you to Clojure.</p>

<p>Want more, check out this Clojure Conj video -  <a href="https://www.youtube.com/watch?v=yzfnlcHtwiY">Can You GAN?</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet - the Module API]]></title>
    <link href="http://gigasquid.github.io/blog/2018/07/05/clojure-mxnet-the-module-api/"/>
    <updated>2018-07-05T19:39:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2018/07/05/clojure-mxnet-the-module-api</id>
    <content type="html"><![CDATA[<p><img src="https://cdn-images-1.medium.com/max/800/1*OoqsrMD7JzXAvRUGx_8_fg.jpeg"></p>

<p>This is an introduction to the high level Clojure API for deep learning library <a href="http://mxnet.incubator.apache.org/">MXNet</a>.</p>

<p>The module API provides an intermediate and high-level interface for performing computation with neural networks in MXNet.</p>

<p>To follow along with this documentation, you can use this namespace to with the needed requires:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">docs.module</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">clojure.java.io</span> <span class="ss">:as</span> <span class="nv">io</span><span class="p">]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">clojure.java.shell</span> <span class="ss">:refer</span> <span class="p">[</span><span class="nv">sh</span><span class="p">]]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.eval-metric</span> <span class="ss">:as</span> <span class="nv">eval-metric</span><span class="p">]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.io</span> <span class="ss">:as</span> <span class="nv">mx-io</span><span class="p">]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.module</span> <span class="ss">:as</span> <span class="nv">m</span><span class="p">]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.symbol</span> <span class="ss">:as</span> <span class="nv">sym</span><span class="p">]</span>
</span><span class='line'>            <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.ndarray</span> <span class="ss">:as</span> <span class="nv">ndarray</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Prepare the Data</h2>

<p>In this example, we are going to use the MNIST data set. If you have cloned the MXNet repo and <code>cd contrib/clojure-package</code>, we can run some helper scripts to download the data for us.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">data-dir</span> <span class="s">&quot;data/&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nb">when-not </span><span class="p">(</span><span class="nf">.exists</span> <span class="p">(</span><span class="nf">io/file</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)))</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">sh</span> <span class="s">&quot;../../scripts/get_mnist_data.sh&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>MXNet provides function in the <code>io</code> namespace to load the MNIST datasets into training and test data iterators that we can use with our module.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">train-data</span> <span class="p">(</span><span class="nf">mx-io/mnist-iter</span> <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                   <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                   <span class="ss">:label-name</span> <span class="s">&quot;softmax_label&quot;</span>
</span><span class='line'>                                   <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>                                   <span class="ss">:batch-size</span> <span class="mi">10</span>
</span><span class='line'>                                   <span class="ss">:shuffle</span> <span class="nv">true</span>
</span><span class='line'>                                   <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>                                   <span class="ss">:silent</span> <span class="nv">false</span>
</span><span class='line'>                                   <span class="ss">:seed</span> <span class="mi">10</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">test-data</span> <span class="p">(</span><span class="nf">mx-io/mnist-iter</span> <span class="p">{</span><span class="ss">:image</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                  <span class="ss">:label</span> <span class="p">(</span><span class="nb">str </span><span class="nv">data-dir</span> <span class="s">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span>
</span><span class='line'>                                  <span class="ss">:input-shape</span> <span class="p">[</span><span class="mi">784</span><span class="p">]</span>
</span><span class='line'>                                  <span class="ss">:batch-size</span> <span class="mi">10</span>
</span><span class='line'>                                  <span class="ss">:flat</span> <span class="nv">true</span>
</span><span class='line'>                                  <span class="ss">:silent</span> <span class="nv">false</span><span class="p">}))</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Preparing a Module for Computation</h2>

<p>To construct a module, we need to have a symbol as input. This symbol takes input data in the first layer and then has subsequent layers of fully connected and relu activation layers, ending up in a softmax layer for output.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">data</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;data&quot;</span><span class="p">)</span>
</span><span class='line'>      <span class="nv">fc1</span> <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">128</span><span class="p">})</span>
</span><span class='line'>      <span class="nv">act1</span> <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;relu1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">fc1</span> <span class="ss">:act-type</span> <span class="s">&quot;relu&quot;</span><span class="p">})</span>
</span><span class='line'>      <span class="nv">fc2</span> <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">act1</span> <span class="ss">:num-hidden</span> <span class="mi">64</span><span class="p">})</span>
</span><span class='line'>      <span class="nv">act2</span> <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;relu2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">fc2</span> <span class="ss">:act-type</span> <span class="s">&quot;relu&quot;</span><span class="p">})</span>
</span><span class='line'>      <span class="nv">fc3</span> <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc3&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">act2</span> <span class="ss">:num-hidden</span> <span class="mi">10</span><span class="p">})</span>
</span><span class='line'>      <span class="nv">out</span> <span class="p">(</span><span class="nf">sym/softmax-output</span> <span class="s">&quot;softmax&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">fc3</span><span class="p">})]</span>
</span><span class='line'>  <span class="nv">out</span><span class="p">)</span>
</span><span class='line'>  <span class="c1">;=&gt;#object[org.apache.mxnet.Symbol 0x1f43a406 &quot;org.apache.mxnet.Symbol@1f43a406&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can also write this with the <code>as-&gt;</code> threading macro.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">out</span> <span class="p">(</span><span class="nf">as-&gt;</span> <span class="p">(</span><span class="nf">sym/variable</span> <span class="s">&quot;data&quot;</span><span class="p">)</span> <span class="nv">data</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">128</span><span class="p">})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;relu1&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;relu&quot;</span><span class="p">})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">64</span><span class="p">})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/activation</span> <span class="s">&quot;relu2&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:act-type</span> <span class="s">&quot;relu&quot;</span><span class="p">})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/fully-connected</span> <span class="s">&quot;fc3&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span> <span class="ss">:num-hidden</span> <span class="mi">10</span><span class="p">})</span>
</span><span class='line'>           <span class="p">(</span><span class="nf">sym/softmax-output</span> <span class="s">&quot;softmax&quot;</span> <span class="p">{</span><span class="ss">:data</span> <span class="nv">data</span><span class="p">})))</span>
</span><span class='line'><span class="c1">;=&gt; #&#39;tutorial.module/out</span>
</span></code></pre></td></tr></table></div></figure>


<p>By default, <code>context</code> is the CPU. If you need data parallelization, you can specify a GPU context or an array of GPU contexts like this <code>(m/module out {:contexts [(context/gpu)]})</code></p>

<p>Before you can compute with a module, you need to call <code>bind</code> to allocate the device memory and <code>init-params</code> or <code>set-params</code> to initialize the parameters. If you simply want to fit a module, you don’t need to call <code>bind</code> and <code>init-params</code> explicitly, because the <code>fit</code> function automatically calls them if they are needed.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">mod</span> <span class="p">(</span><span class="nf">m/module</span> <span class="nv">out</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">-&gt; </span><span class="nv">mod</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/bind</span> <span class="p">{</span><span class="ss">:data-shapes</span> <span class="p">(</span><span class="nf">mx-io/provide-data</span> <span class="nv">train-data</span><span class="p">)</span>
</span><span class='line'>               <span class="ss">:label-shapes</span> <span class="p">(</span><span class="nf">mx-io/provide-label</span> <span class="nv">train-data</span><span class="p">)})</span>
</span><span class='line'>      <span class="p">(</span><span class="nf">m/init-params</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now you can compute with the module using functions like <code>forward</code>, <code>backward</code>, etc.</p>

<h2>Training and Predicting</h2>

<p>Modules provide high-level APIs for training, predicting, and evaluating. To fit a module, call the <code>fit</code> function with some data iterators:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">mod</span> <span class="p">(</span><span class="nf">m/fit</span> <span class="p">(</span><span class="nf">m/module</span> <span class="nv">out</span><span class="p">)</span> <span class="p">{</span><span class="ss">:train-data</span> <span class="nv">train-data</span> <span class="ss">:eval-data</span> <span class="nv">test-data</span> <span class="ss">:num-epoch</span> <span class="mi">1</span><span class="p">}))</span>
</span><span class='line'><span class="c1">;; Epoch  0  Train- [accuracy 0.12521666]</span>
</span><span class='line'><span class="c1">;; Epoch  0  Time cost- 8392</span>
</span><span class='line'><span class="c1">;; Epoch  0  Validation-  [accuracy 0.2227]</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can pass in batch-end callbacks using batch-end-callback and epoch-end callbacks using epoch-end-callback in the <code>fit-params</code>. You can also set parameters using functions like in the fit-params like optimizer and eval-metric. To learn more about the fit-params, see the fit-param function options. To predict with a module, call <code>predict</code> with a DataIter:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">results</span> <span class="p">(</span><span class="nf">m/predict</span> <span class="nv">mod</span> <span class="p">{</span><span class="ss">:eval-data</span> <span class="nv">test-data</span><span class="p">}))</span>
</span><span class='line'><span class="p">(</span><span class="nb">first </span><span class="nv">results</span><span class="p">)</span> <span class="c1">;=&gt;#object[org.apache.mxnet.NDArray 0x3540b6d3 &quot;org.apache.mxnet.NDArray@a48686ec&quot;]</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="p">(</span><span class="nb">first </span><span class="nv">results</span><span class="p">)))</span> <span class="c1">;=&gt;0.08261358</span>
</span></code></pre></td></tr></table></div></figure>


<p>The module collects and returns all of the prediction results. For more details about the format of the return values, see the documentation for the <code>predict</code> function.</p>

<p>When prediction results might be too large to fit in memory, use the <code>predict-every-batch</code> API.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">preds</span> <span class="p">(</span><span class="nf">m/predict-every-batch</span> <span class="nv">mod</span> <span class="p">{</span><span class="ss">:eval-data</span> <span class="nv">test-data</span><span class="p">})]</span>
</span><span class='line'>  <span class="p">(</span><span class="nf">mx-io/reduce-batches</span> <span class="nv">test-data</span>
</span><span class='line'>                        <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">i</span> <span class="nv">batch</span><span class="p">]</span>
</span><span class='line'>                          <span class="p">(</span><span class="nb">println </span><span class="p">(</span><span class="nb">str </span><span class="s">&quot;pred is &quot;</span> <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nb">get </span><span class="nv">preds</span> <span class="nv">i</span><span class="p">))))</span>
</span><span class='line'>                          <span class="p">(</span><span class="nb">println </span><span class="p">(</span><span class="nb">str </span><span class="s">&quot;label is &quot;</span> <span class="p">(</span><span class="nf">mx-io/batch-label</span> <span class="nv">batch</span><span class="p">)))</span>
</span><span class='line'>                          <span class="c1">;;; do something</span>
</span><span class='line'>                          <span class="p">(</span><span class="nb">inc </span><span class="nv">i</span><span class="p">))))</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you need to evaluate on a test set and don’t need the prediction output, call the <code>score</code> function with a data iterator and an eval metric:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">m/score</span> <span class="nv">mod</span> <span class="p">{</span><span class="ss">:eval-data</span> <span class="nv">test-data</span> <span class="ss">:eval-metric</span> <span class="p">(</span><span class="nf">eval-metric/accuracy</span><span class="p">)})</span> <span class="c1">;=&gt;[&quot;accuracy&quot; 0.2227]</span>
</span></code></pre></td></tr></table></div></figure>


<p>This runs predictions on each batch in the provided data iterator and computes the evaluation score using the provided eval metric. The evaluation results are stored in metric so that you can query later.</p>

<h2>Saving and Loading</h2>

<p>To save the module parameters in each training epoch, use a <code>checkpoint</code> function:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">save-prefix</span> <span class="s">&quot;my-model&quot;</span><span class="p">]</span>
</span><span class='line'>  <span class="p">(</span><span class="nb">doseq </span><span class="p">[</span><span class="nv">epoch-num</span> <span class="p">(</span><span class="nb">range </span><span class="mi">3</span><span class="p">)]</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">mx-io/do-batches</span> <span class="nv">train-data</span> <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">batch</span>
</span><span class='line'>                                          <span class="c1">;; do something</span>
</span><span class='line'><span class="p">]))</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">m/save-checkpoint</span> <span class="nv">mod</span> <span class="p">{</span><span class="ss">:prefix</span> <span class="nv">save-prefix</span> <span class="ss">:epoch</span> <span class="nv">epoch-num</span> <span class="ss">:save-opt-states</span> <span class="nv">true</span><span class="p">})))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved checkpoint to my-model-0000.params</span>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved optimizer state to my-model-0000.states</span>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved checkpoint to my-model-0001.params</span>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved optimizer state to my-model-0001.states</span>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved checkpoint to my-model-0002.params</span>
</span><span class='line'><span class="c1">;; INFO  org.apache.mxnet.module.Module: Saved optimizer state to my-model-0002.states</span>
</span></code></pre></td></tr></table></div></figure>


<p>To load the saved module parameters, call the <code>load-checkpoint</code> function:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">new-mod</span> <span class="p">(</span><span class="nf">m/load-checkpoint</span> <span class="p">{</span><span class="ss">:prefix</span> <span class="s">&quot;my-model&quot;</span> <span class="ss">:epoch</span> <span class="mi">1</span> <span class="ss">:load-optimizer-states</span> <span class="nv">true</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'><span class="nv">new-mod</span> <span class="c1">;=&gt; #object[org.apache.mxnet.module.Module 0x5304d0f4 &quot;org.apache.mxnet.module.Module@5304d0f4&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>To initialize parameters, Bind the symbols to construct executors first with bind function. Then, initialize the parameters and auxiliary states by calling <code>init-params</code> function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nb">-&gt; </span><span class="nv">new-mod</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">m/bind</span> <span class="p">{</span><span class="ss">:data-shapes</span> <span class="p">(</span><span class="nf">mx-io/provide-data</span> <span class="nv">train-data</span><span class="p">)</span> <span class="ss">:label-shapes</span> <span class="p">(</span><span class="nf">mx-io/provide-label</span> <span class="nv">train-data</span><span class="p">)})</span>
</span><span class='line'>    <span class="p">(</span><span class="nf">m/init-params</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>To get current parameters, use <code>params</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">let </span><span class="p">[[</span><span class="nv">arg-params</span> <span class="nv">aux-params</span><span class="p">]</span> <span class="p">(</span><span class="nf">m/params</span> <span class="nv">new-mod</span><span class="p">)]</span>
</span><span class='line'>  <span class="p">{</span><span class="ss">:arg-params</span> <span class="nv">arg-params</span>
</span><span class='line'>   <span class="ss">:aux-params</span> <span class="nv">aux-params</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'><span class="c1">;; {:arg-params</span>
</span><span class='line'><span class="c1">;;  {&quot;fc3_bias&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x39adc3b0 &quot;org.apache.mxnet.NDArray@49caf426&quot;],</span>
</span><span class='line'><span class="c1">;;   &quot;fc2_weight&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x25baf623 &quot;org.apache.mxnet.NDArray@a6c8f9ac&quot;],</span>
</span><span class='line'><span class="c1">;;   &quot;fc1_bias&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x6e089973 &quot;org.apache.mxnet.NDArray@9f91d6eb&quot;],</span>
</span><span class='line'><span class="c1">;;   &quot;fc3_weight&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x756fd109 &quot;org.apache.mxnet.NDArray@2dd0fe3c&quot;],</span>
</span><span class='line'><span class="c1">;;   &quot;fc2_bias&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x1dc69c8b &quot;org.apache.mxnet.NDArray@d128f73d&quot;],</span>
</span><span class='line'><span class="c1">;;   &quot;fc1_weight&quot;</span>
</span><span class='line'><span class="c1">;;   #object[org.apache.mxnet.NDArray 0x20abc769 &quot;org.apache.mxnet.NDArray@b8e1c5e8&quot;]},</span>
</span><span class='line'><span class="c1">;;  :aux-params {}}</span>
</span></code></pre></td></tr></table></div></figure>


<p>To assign parameter and aux state values, use <code>set-params</code> function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">m/set-params</span> <span class="nv">new-mod</span> <span class="p">{</span><span class="ss">:arg-params</span> <span class="p">(</span><span class="nf">m/arg-params</span> <span class="nv">new-mod</span><span class="p">)</span> <span class="ss">:aux-params</span> <span class="p">(</span><span class="nf">m/aux-params</span> <span class="nv">new-mod</span><span class="p">)})</span>
</span><span class='line'><span class="c1">;=&gt; #object[org.apache.mxnet.module.Module 0x5304d0f4 &quot;org.apache.mxnet.module.Module@5304d0f4&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>To resume training from a saved checkpoint, instead of calling <code>set-params</code>, directly call <code>fit</code>, passing the loaded parameters, so that <code>fit</code> knows to start from those parameters instead of initializing randomly</p>

<p>Create fit-params, and then use it to set <code>begin-epoch</code> so that <code>fit</code> knows to resume from a saved epoch.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="c1">;; reset the training data before calling fit or you will get an error</span>
</span><span class='line'><span class="p">(</span><span class="nf">mx-io/reset</span> <span class="nv">train-data</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">mx-io/reset</span> <span class="nv">test-data</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">(</span><span class="nf">m/fit</span> <span class="nv">new-mod</span> <span class="p">{</span><span class="ss">:train-data</span> <span class="nv">train-data</span> <span class="ss">:eval-data</span> <span class="nv">test-data</span> <span class="ss">:num-epoch</span> <span class="mi">2</span>
</span><span class='line'>                <span class="ss">:fit-params</span> <span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">m/fit-params</span> <span class="p">{</span><span class="ss">:begin-epoch</span> <span class="mi">1</span><span class="p">}))})</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you are interested in checking out MXNet and exploring on your own, check out the main page <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package">here</a> with instructions on how to install and other information.</p>

<h3>See other blog posts about MXNet</h3>

<ul>
<li><a href="http://gigasquidsoftware.com/blog/2018/06/03/meet-clojure-mxnet-ndarray/">Clojure MXNet - NDArray</a></li>
<li><a href="http://gigasquidsoftware.com/blog/2018/07/01/clojure-mxnet-joins-the-apache-mxnet-project/">Clojure MXNet Joins Apache MXNet</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure MXNet Joins the Apache MXNet Project]]></title>
    <link href="http://gigasquid.github.io/blog/2018/07/01/clojure-mxnet-joins-the-apache-mxnet-project/"/>
    <updated>2018-07-01T10:44:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2018/07/01/clojure-mxnet-joins-the-apache-mxnet-project</id>
    <content type="html"><![CDATA[<p><img src="https://cdn-images-1.medium.com/max/800/1*OoqsrMD7JzXAvRUGx_8_fg.jpeg"></p>

<p>I&rsquo;m delighted to share the news that the Clojure package for <a href="https://mxnet.apache.org/">MXNet</a> has now joined the main Apache MXNet project. A big thank you to the efforts of everyone involved to make this possible. Having it as part of the main project is a great place for growth and collaboration that will benefit both MXNet and the Clojure community.</p>

<h2>Invitation to Join and Contribute</h2>

<p>The Clojure package has been brought in as a <em>contrib</em> <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package">clojure-package</a>. It is still very new and will go through a period of feedback, stabilization, and improvement before it graduates out of contrib.</p>

<p>We welcome contributors and people getting involved to make it better.</p>

<p>Are you interested in Deep Learning and Clojure? Great - Join us!</p>

<p>There are a few ways to get involved.</p>

<ul>
<li>Check out the current state of the Clojure package some contribution needs here <a href="https://cwiki.apache.org/confluence/display/MXNET/Clojure+Package+Contribution+Needs">https://cwiki.apache.org/confluence/display/MXNET/Clojure+Package+Contribution+Needs</a></li>
<li>Join the Clojurian Slack #mxnet channel</li>
<li>Join the <a href="https://lists.apache.org/list.html?dev@mxnet.apache.org">MXNet dev mailing list</a> by sending an email to <code>dev-subscribe@mxnet.apache.org.</code>.</li>
<li>Join the MXNET Slack channel - You have to join the MXnet dev mailing list first, but after that says you would like to join the slack and someone will add you.</li>
<li>Join the <a href="https://discuss.mxnet.io/">MXNet Discussion Forum</a></li>
</ul>


<h3>Want to Learn More?</h3>

<p>There are lots of examples in the package to check out, but a good place to start are the tutorials here <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package/examples/tutorial">https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package/examples/tutorial</a></p>

<p>There is a blog walkthough here as well - <a href="http://gigasquidsoftware.com/blog/2018/07/05/clojure-mxnet-the-module-api/">Clojure MXNet Module API</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meet Clojure MXNet - NDArray]]></title>
    <link href="http://gigasquid.github.io/blog/2018/06/03/meet-clojure-mxnet-ndarray/"/>
    <updated>2018-06-03T16:13:00-04:00</updated>
    <id>http://gigasquid.github.io/blog/2018/06/03/meet-clojure-mxnet-ndarray</id>
    <content type="html"><![CDATA[<p><img src="https://cdn-images-1.medium.com/max/800/1*OoqsrMD7JzXAvRUGx_8_fg.jpeg"></p>

<p>This is the beginning of a series of blog posts to get to know the <a href="https://mxnet.apache.org/">Apache MXNet</a> Deep Learning project and the new Clojure language binding <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package">clojure-package</a></p>

<p>MXNet is a first class, modern deep learning library that AWS has officially picked as its chosen library. It supports multiple languages on a first class basis and is incubating as an Apache project.</p>

<p>The motivation for creating a Clojure package is to be able to open the deep learning library to the Clojure ecosystem and build bridges for future development and innovation for the community. It provides all the needed tools including low level and high level apis, dynamic graphs, and things like GAN and natural language support.</p>

<p>So let&rsquo;s get on with our introduction with one of the basic building blocks of MXNet, the <code>NDArray</code>.</p>

<h2>Meet NDArray</h2>

<p>The <code>NDArray</code> is the tensor data structure in MXNet. Let&rsquo;s start of by creating one. First we need to require the <code>ndarray</code> namespace:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="kd">ns </span><span class="nv">tutorial.ndarray</span>
</span><span class='line'>  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">org.apache.clojure-mxnet.ndarray</span> <span class="ss">:as</span> <span class="nv">ndarray</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now let&rsquo;s create an all zero array of dimension 100 x 50</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/zeros</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">50</span><span class="p">])</span>
</span><span class='line'><span class="c1">;=&gt; #object[org.apache.mxnet.NDArray 0x3e396d0 &quot;org.apache.mxnet.NDArray@aeea40b6&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can check the shape of this by using <code>shape-vec</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/shape-vec</span> <span class="p">(</span><span class="nf">ndarray/zeros</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">50</span><span class="p">]))</span>
</span><span class='line'><span class="c1">;=&gt; [100 50]</span>
</span></code></pre></td></tr></table></div></figure>


<p>There is also a quick way to create an ndarray of ones with the <code>ones</code> function:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/ones</span> <span class="p">[</span><span class="mi">256</span> <span class="mi">32</span> <span class="mi">128</span> <span class="mi">1</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>Ones and zeros are nice, but what an array with specific contents? There is an <code>array</code> function for that. Specific the contents of the array first and the shape second:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">c</span> <span class="p">(</span><span class="nf">ndarray/array</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span> <span class="mi">3</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/shape-vec</span> <span class="nv">c</span><span class="p">)</span>  <span class="c1">;=&gt; [2 3]</span>
</span></code></pre></td></tr></table></div></figure>


<p>To convert it back to a vector format, we can use the <code>-&gt;vec</code> function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="nv">c</span><span class="p">)</span>
</span><span class='line'><span class="c1">;=&gt; [1.0 2.0 3.0 4.0 5.0 6.0]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now that we know how to create NDArrays, we can get to do something interesting like operations on them.</p>

<h3>Operations</h3>

<p>There are all the standard arithmetic operations:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">a</span> <span class="p">(</span><span class="nf">ndarray/ones</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">5</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">b</span> <span class="p">(</span><span class="nf">ndarray/ones</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">5</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="nb">-&gt; </span><span class="p">(</span><span class="nf">ndarray/+</span> <span class="nv">a</span> <span class="nv">b</span><span class="p">)</span> <span class="p">(</span><span class="nf">ndarray/-&gt;vec</span><span class="p">))</span>
</span><span class='line'><span class="c1">;=&gt;  [2.0 2.0 2.0 2.0 2.0]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the original ndarrays are unchanged.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="nv">a</span><span class="p">)</span> <span class="c1">;=&gt; [1.0 1.0 1.0 1.0 1.0]</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="nv">b</span><span class="p">)</span> <span class="c1">;=&gt; [1.0 1.0 1.0 1.0 1.0]</span>
</span></code></pre></td></tr></table></div></figure>


<p>But, we can change that if we use the inplace operators:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/+=</span> <span class="nv">a</span> <span class="nv">b</span><span class="p">)</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="nv">a</span><span class="p">)</span> <span class="c1">;=&gt;  [2.0 2.0 2.0 2.0 2.0]</span>
</span></code></pre></td></tr></table></div></figure>


<p>There are many more operations, but just to give you a taste, we&rsquo;ll take a look a the <code>dot</code> product operation:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">arr1</span> <span class="p">(</span><span class="nf">ndarray/array</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">arr2</span> <span class="p">(</span><span class="nf">ndarray/array</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span> <span class="mi">1</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="k">def </span><span class="nv">res</span> <span class="p">(</span><span class="nf">ndarray/dot</span> <span class="nv">arr1</span> <span class="nv">arr2</span><span class="p">))</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/shape-vec</span> <span class="nv">res</span><span class="p">)</span> <span class="c1">;=&gt; [1 1]</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/-&gt;vec</span> <span class="nv">res</span><span class="p">)</span> <span class="c1">;=&gt; [11.0]</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you are curious about the other operators available in NDArray API check out the <a href="https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html">MXNet project documentation page</a></p>

<p>Now that we have ndarrays and can do calculations on them, we might want to save and load them.</p>

<h3>Saving and Loading</h3>

<p>You can save ndarrays with a name as a map like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/save</span> <span class="s">&quot;filename&quot;</span> <span class="p">{</span><span class="s">&quot;arr1&quot;</span> <span class="nv">arr1</span> <span class="s">&quot;arr2&quot;</span> <span class="nv">arr2</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>To load them, you just specify the filename and the map is returned.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">ndarray/load</span> <span class="s">&quot;filename&quot;</span><span class="p">)</span>
</span><span class='line'><span class="c1">;=&gt; {&quot;arr1&quot; #object[org.apache.mxnet.NDArray 0x1b629ff4 &quot;org.apache.mxnet.NDArray@63da08cb&quot;]</span>
</span><span class='line'><span class="c1">;=&gt;  &quot;arr2&quot; #object[org.apache.mxnet.NDArray 0x25d994e3 &quot;org.apache.mxnet.NDArray@5bbaf2c3&quot;]}</span>
</span></code></pre></td></tr></table></div></figure>


<p>One more cool thing, we can even due our operations on the cpu or gpu.</p>

<h3>Multi-Device Support</h3>

<p>When creating an <code>ndarray</code> you can use a context argument to specify the device. To do this, we will need the help of the <code>context</code> namespace.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="nf">require</span> <span class="o">&#39;</span><span class="p">[</span><span class="nv">org.apache.clojure-mxnet.context</span> <span class="ss">:as</span> <span class="nv">context</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>By default, the <code>ndarray</code> is created on the cpu context.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">cpu-a</span> <span class="p">(</span><span class="nf">ndarray/zeros</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">200</span><span class="p">]))</span>
</span><span class='line'><span class="p">(</span><span class="nf">ndarray/context</span> <span class="nv">cpu-a</span><span class="p">)</span>
</span><span class='line'><span class="c1">;=&gt; #object[ml.dmlc.mxnet.Context 0x3f376123 &quot;cpu(0)&quot;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>But we can specify the gpu instead, (if we have a gpu enabled build).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='clojure'><span class='line'><span></span><span class="p">(</span><span class="k">def </span><span class="nv">gpu-b</span> <span class="p">(</span><span class="nf">ndarray/zeros</span> <span class="p">[</span><span class="mi">100</span> <span class="mi">200</span><span class="p">]</span> <span class="p">{</span><span class="ss">:ctx</span> <span class="p">(</span><span class="nf">context/gpu</span> <span class="mi">0</span><span class="p">)}))</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Note: Operations among different contexts are currently not allowed, but there is a <code>copy-to</code> function that can help copy the content from one device to another and then continue on with the computation.</em></p>

<h2>Wrap up</h2>

<p>I hope you&rsquo;ve enjoyed the brief introduction to the MXNet library, there is much more to explore in future posts. If you are interested in giving it a try, there are native jars for OSX cpu and Linux cpu/gpu available and the code for the ndarray tutorial can be found <a href="https://github.com/apache/incubator-mxnet/tree/master/contrib/clojure-package/examples/tutorial">here</a></p>

<p><em>Please remember that the library is in a experimential state, so if you encounter any problems or have any other feedback, please log an issue so bugs and rough edges can be fixed :).</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Staying Technical]]></title>
    <link href="http://gigasquid.github.io/blog/2018/03/04/on-staying-technical/"/>
    <updated>2018-03-04T11:03:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2018/03/04/on-staying-technical</id>
    <content type="html"><![CDATA[<p>I was 10 years into my career when I met her. I could count the number of other women programmers I had worked with on one hand and none of them had young children at home like me. She was not only incredibly experienced and competent, but also had a son in college. I was curious about her career path so I asked her one day at lunch why she was still programming and hadn’t become a manager instead.</p>

<p>She smiled at me kindly and replied, &ldquo;I’ve worked very hard to stay exactly where I am&rdquo;,  and I was enlightened.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cats and Dogs With Cortex Redux]]></title>
    <link href="http://gigasquid.github.io/blog/2017/11/07/cats-and-dogs-with-cortex-redux/"/>
    <updated>2017-11-07T18:51:00-05:00</updated>
    <id>http://gigasquid.github.io/blog/2017/11/07/cats-and-dogs-with-cortex-redux</id>
    <content type="html"><![CDATA[<p>I wrote a <a href="http://gigasquidsoftware.com/blog/2016/12/27/deep-learning-in-clojure-with-cortex/">blog post</a> a while back about using a Clojure machine learning library called <a href="https://github.com/thinktopic/cortex">Cortex</a> to do the Kaggle Cats and Dogs classification challenge.</p>

<p>I wanted to revisit it for a few reasons. The first one is that the Cortex library has progressed and improved considerably over the last year. It&rsquo;s still not at version 1.0, but it my eyes, it&rsquo;s really starting to shine. The second reason is that they recently published an <a href="https://github.com/thinktopic/cortex/tree/master/examples/resnet-retrain">example</a> of using the RESNET50 model, (I&rsquo;ll explain later on), to do fine-tuning or transfer learning. The third reason, is that there is a great new plugin for leiningen the supports using <a href="https://github.com/didiercrunch/lein-jupyter">Jupyter notebooks with Clojure projects</a>. These notebooks are a great way of doing walkthroughs and tutorials.</p>

<p>Putting all these things together, I felt like I was finally at a stage where I could somewhat replicate the first lesson in the <a href="https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogs_cats_redux.ipynb">Practical Deep Learning Course for Coders</a> with Cats and Dogs - although this time all in Clojure!</p>

<h2>Where to Start?</h2>

<p><img src="http://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg"></p>

<p>In the last blog post, we created our deep learning network and trained the data on scaled down images (like 50x50) from scratch. This time we are much smarter.</p>

<p>We are still of course going to have to get a hold of all the training data from <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data">Kaggle Cats vs Dogs Challenge</a>. The big difference is this time, we are just going to have to train our model for <em>1 epoch</em>. What&rsquo;s more, the results will be way better than before.</p>

<p>How is this possible? We are going to use an already trained model, RESNET50. This model has already been painstakingly trained with a gigantic network that is 50 layers deep on the ImageNet challenge. That&rsquo;s a challenge that has models try to classify a 1000 different categories. The theory is that the inner layers of the network have already learned about the features that make up cats and dogs, all we would need to do is peel off the final layer of the network and graft on a new layers that just learns the final classification for our 2 categories of cats and dogs. This is called <em>transfer learning</em> or <em>retraining</em>.</p>

<h2>Plan of Action</h2>

<ul>
<li>Get all the cats and dogs pictures in the right directory format for training</li>
<li>Train the model with all but the last layer in the RESNET model. The last layer we are going to replace with our own layer that will finetune it to classify only cats and dogs</li>
<li>Run the test data and come up with a spreadsheet of results to submit to Kaggle.</li>
</ul>


<h3>Getting all the data pictures in the right format</h3>

<p>This is the generally the most time consuming step of most deep learning. I&rsquo;ll spare you the gritty details but we want to get all the pictures from the <code>train.zip</code> into the format</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-data
</span><span class='line'>  -cats-dogs-training
</span><span class='line'>      -cat
</span><span class='line'>          1110.png
</span><span class='line'>          ...
</span><span class='line'>      -dog
</span><span class='line'>          12416.png
</span><span class='line'>          ...
</span><span class='line'>  -cats-dogs-testing
</span><span class='line'>      -cat
</span><span class='line'>          11.png
</span><span class='line'>          ...
</span><span class='line'>      -dog
</span><span class='line'>          12.png
</span><span class='line'>          ...</span></code></pre></td></tr></table></div></figure>


<p>The image sizes must also all be resized to match the input of the RESNET50. That means they all have to be 224x224.</p>

<h3>Train the model</h3>

<p>The cortex functions allow you to load the resnet50 model, remove the last layer, freeze all the other layers so that they will not be retrained, and add new layers.</p>

<p>I was surprised that I could actually train the model with all the images at 224x244 with the huge RESNET50 model. I built the uberjar and ran it which helped the performance.</p>

<p><code>lein uberjar</code></p>

<p><code>java -jar target/cats-dogs-cortex-redux.jar</code></p>

<p>Training one epoch took me approximately 6 minutes. Not bad, especially considering that&rsquo;s all the training I really needed to do.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Loss for epoch 1: (current) 0.05875186542016347 (best) null
</span><span class='line'>Saving network to trained-network.nippy</span></code></pre></td></tr></table></div></figure>


<p>The key point is that it saved the fine tuned network to trained-network.nippy</p>

<h3>Run the Kaggle test results and submit the results</h3>

<p>You will need to do a bit more setup for this. First, you need to get the Kaggle test images for classification. There are 12500 of these in the test.zip file from the site. Under the data directory, create a new directory called kaggle-test. Now unzip the contents of test.zip inside that folder. The full directory with all the test images should now be:</p>

<p><code>data/kaggle-test/test</code></p>

<p>This step takes a long time and you might have to tweak the batch size again depending on your memory. There are 12500 predications to be made. The main logic for this is in function called <code>(kaggle-results batch-size)</code>. It will take a long time to run. It will print the results as it goes along to the kaggle-results.csv file. If you want to check progress you can do wc -l kaggle-results.csv</p>

<p>For me locally, with <code>(cats-dogs/kaggle-results 100)</code> it took me 28 minutes locally.</p>

<h3>Compare the results</h3>

<p><img src="http://c1.staticflickr.com/5/4518/26477015609_1af781b8da_b.jpg"></p>

<p>My one epoch of fine tuning beat my best results of going through the Practical Deep Learning exercise with the fine tuning the VGG16 model. Not bad at all.</p>

<h2>Summary</h2>

<p>For those of you that are interested in checking out the code, it&rsquo;s out there on <a href="https://github.com/gigasquid/cats-dogs-cortex-redux">github</a></p>

<p>Even more exciting, there is a <a href="https://github.com/gigasquid/cats-dogs-cortex-redux/blob/master/Cats%20and%20Dogs%20in%20Cortex%20(Redux).ipynb">walkthrough in a jupyter notebook</a> with a lein-jupyter plugin.</p>

<p>The Deep Learning world in Clojure is an exciting place to be and gaining tools and traction more and more.</p>
]]></content>
  </entry>
  
</feed>
