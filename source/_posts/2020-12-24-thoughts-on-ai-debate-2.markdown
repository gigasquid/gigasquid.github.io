---
layout: post
title: "Thoughts on AI Debate 2"
date: 2020-12-24 10:59
comments: true
categories: 
- All
- AI
- Deep Learning
---

![](https://montrealartificialintelligence.com/aidebate2mosaic1440x720v8.jpg)

## AI Debate 2 from Montreal.AI

I had the pleasure of watching the second AI debate from Montreal.AI last night. The first AI debate occurred last year between [Yoshua Bengio](https://yoshuabengio.org/) and [Gary Marcus](https://en.wikipedia.org/wiki/Gary_Marcus) entitled [“The Best Way Forward for AI”](https://montrealartificialintelligence.com/aidebate.html) in which Yoshua argued that Deep Learning could achieve General AI through its own paradigm, while Marcus argued that Deep Learning alone was not sufficient and needed a hybrid approach involving symbolics and inspiration from other disciplines.  


<br>


This interdisciplinary thread of Gary’s linked the two programs. The second AI debate was entitled [“Moving AI Forward: An Interdisciplinary Approach”](https://montrealartificialintelligence.com/aidebate2.html) and reflected a broad panel that explored themes on architecture, neuroscience and psychology, and trust/ethics. The second program was not really a debate, but more of a showcase of ideas in the form of 3 minute presentations from the panelists and discussion around topics with Marcus serving as a capable moderator.

<br>


The program aired Wednesday night and was 3 hours long. I watched it live with an unavoidable break in the middle to fetch dinner for my family, but the whole recording is up now on the [website](https://montrealartificialintelligence.com/aidebate2.html). Some of the highlights for me were thoughts around System 1 and System 2,  reinforcement learning, and the properties of evolution.

<br>

There was much discussion around System 1 and System 2 in relation to AI. One of the author’s of the recently published paper [“Thinking Fast and Slow in AI”](https://arxiv.org/pdf/2010.06002.pdf), [Francesca Rossi](https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Francesca.Rossi2) was a panelist as well as [Danny Kahneman](https://en.wikipedia.org/wiki/Daniel_Kahneman) the author of “Thinking Fast and Slow”. Applying the abstraction of these sysems to AI with Deep Learning being System 1 is very appealing, however as Kahneman pointed out in his talk, this abstraction is leaky at its heart as the human System 1 encompasses much more than current AI system 1, (like a model of the world). It is interesting to think of one of the differences in human System 1 and System 2 in relation to one being fast and concurrent while the other is slower and sequential and laden with attention. Why is this so? Is this a constraint and design feature that we should bring to our AI design?

<br>

[Richard Sutton](http://www.incompleteideas.net/) gave a thought provoking talk on how reinforcement learning is the first fully implemented computational theory of intelligence. He pointed to [Marr’s three levels](https://apsc450computationalneuroscience.wordpress.com/marrs-three-levels-of-inquiry/)  at which any information processing machine must be understood: hardware implementation, representation/algorithm, and finally the high level theory. That is: what is the goal of the computation? What logic can the strategy be carried out? AI has made great strides due to this computational theory. However, it is only one theory. We need more. I personally think that innovation and exploration in this area could lead to an exciting future in AI.

<br>

Evolution is a fundamental force that drives humans and the world around us. [Ken Stanely](https://www.cs.ucf.edu/~kstanley/) reminded us that while computers dominate at solving problems, humans still rule at open-ended innovation over the millenia. The underlying properties of evolution still elude our deep understanding. Studying the core nature of this powerful phenomena is a very important area of research.

<br>

The last question of the evening to all the panelists was the greatest Christmas gift of all - “Where do you want AI to go?”. The diversity of the answers reflected the broad hopes shared by many that will light the way to come. I’ll paraphrase some of the ones here:

- Want to understand fundamental laws and principles and use them to better the human condition.
- Understand the different varieties of intelligence.
- Want an intelligent and superfriendly apprentice. To understand self by emulating.
- To move beyond GPT-3 remixing to really assisting creativity for humanity.
- Hope that AI will amplify us and our abilities.
- Use AI to help people understand what bias they have.
- That humans will still have something to add after AI have mastered a domain
- To understand the brain in the most simple and beautiful way.
- Gain a better clarity and understanding of our own values by deciding which to endow our AI with.
- Want the costs and benefits of AI to be distributed globally and economically.

<br>

Thanks again Montreal.AI for putting together such a great program and sharing it with the community. I look forward to next year.

<br>

Merry Christmas everyone!

